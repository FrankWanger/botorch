<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>BoTorch · Bayesian Optimization in PyTorch</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Bayesian Optimization in PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="BoTorch · Bayesian Optimization in PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://botorch.org/v/0.9.3/"/><meta property="og:description" content="Bayesian Optimization in PyTorch"/><meta property="og:image" content="https://botorch.org/v/0.9.3/img/botorch.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://botorch.org/v/0.9.3/img/botorch.png"/><link rel="shortcut icon" href="/v/0.9.3/img/botorch.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-CXN3PGE3CC"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'G-CXN3PGE3CC');
            </script><link rel="stylesheet" href="/v/0.9.3/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/v/0.9.3/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/v/0.9.3/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/v/0.9.3/js/scrollSpy.js"></script><link rel="stylesheet" href="/v/0.9.3/css/main.css"/><script src="/v/0.9.3/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/v/0.9.3/"><img class="logo" src="/v/0.9.3/img/botorch_logo_lockup_white.png" alt="BoTorch"/><h2 class="headerTitleWithLogo">BoTorch</h2></a><a href="/v/0.9.3/versions"><h3>0.9.3</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/v/0.9.3/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/v/0.9.3/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/v/0.9.3/api/" target="_self">API Reference</a></li><li class=""><a href="/v/0.9.3/docs/papers" target="_self">Papers</a></li><li class=""><a href="https://github.com/pytorch/botorch" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./" src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<h1>Source code for botorch.acquisition.utils</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">"""</span>
<span class="sd">Utilities for acquisition functions.</span>
<span class="sd">"""</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">botorch.acquisition.objective</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">IdentityMCObjective</span><span class="p">,</span>
    <span class="n">MCAcquisitionObjective</span><span class="p">,</span>
    <span class="n">PosteriorTransform</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">botorch.exceptions.errors</span> <span class="kn">import</span> <span class="n">DeprecationError</span><span class="p">,</span> <span class="n">UnsupportedError</span>
<span class="kn">from</span> <span class="nn">botorch.models.fully_bayesian</span> <span class="kn">import</span> <span class="n">MCMC_DIM</span>
<span class="kn">from</span> <span class="nn">botorch.models.model</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">botorch.sampling.base</span> <span class="kn">import</span> <span class="n">MCSampler</span>
<span class="kn">from</span> <span class="nn">botorch.sampling.get_sampler</span> <span class="kn">import</span> <span class="n">get_sampler</span>
<span class="kn">from</span> <span class="nn">botorch.sampling.pathwise</span> <span class="kn">import</span> <span class="n">draw_matheron_paths</span>
<span class="kn">from</span> <span class="nn">botorch.utils.objective</span> <span class="kn">import</span> <span class="n">compute_feasibility_indicator</span>
<span class="kn">from</span> <span class="nn">botorch.utils.sampling</span> <span class="kn">import</span> <span class="n">optimize_posterior_samples</span>
<span class="kn">from</span> <span class="nn">botorch.utils.transforms</span> <span class="kn">import</span> <span class="n">is_fully_bayesian</span><span class="p">,</span> <span class="n">normalize_indices</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>


<div class="viewcode-block" id="get_acquisition_function"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.get_acquisition_function">[docs]</a><span class="k">def</span> <span class="nf">get_acquisition_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="n">DeprecationError</span><span class="p">(</span>
        <span class="s2">"`get_acquisition_function` has been moved to `botorch.acquisition.factory`."</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="compute_best_feasible_objective"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.compute_best_feasible_objective">[docs]</a><span class="k">def</span> <span class="nf">compute_best_feasible_objective</span><span class="p">(</span>
    <span class="n">samples</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">obj</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]],</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Model</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">X_baseline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">infeasible_obj</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Computes the largest `obj` value that is feasible under the `constraints`. If</span>
<span class="sd">    `constraints` is None, returns the best unconstrained objective value.</span>

<span class="sd">    When no feasible observations exist and `infeasible_obj` is not `None`, returns</span>
<span class="sd">    `infeasible_obj` (potentially reshaped). When no feasible observations exist and</span>
<span class="sd">    `infeasible_obj` is `None`, uses `model`, `objective`, `posterior_transform`, and</span>
<span class="sd">    `X_baseline` to infer and return an `infeasible_obj` `M` s.t. `M &lt; min_x f(x)`.</span>

<span class="sd">    Args:</span>
<span class="sd">        samples: `(sample_shape) x batch_shape x q x m`-dim posterior samples.</span>
<span class="sd">        obj: A `(sample_shape) x batch_shape x q`-dim Tensor of MC objective values.</span>
<span class="sd">        constraints: A list of constraint callables which map posterior samples to</span>
<span class="sd">            a scalar. The associated constraint is considered satisfied if this</span>
<span class="sd">            scalar is less than zero.</span>
<span class="sd">        model: A Model, only required when there are no feasible observations.</span>
<span class="sd">        objective: An MCAcquisitionObjective, only optionally used when there are no</span>
<span class="sd">            feasible observations.</span>
<span class="sd">        posterior_transform: A PosteriorTransform, only optionally used when there are</span>
<span class="sd">            no feasible observations.</span>
<span class="sd">        X_baseline: A `batch_shape x d`-dim Tensor of baseline points, only required</span>
<span class="sd">            when there are no feasible observations.</span>
<span class="sd">        infeasible_obj: A Tensor to be returned when no feasible points exist.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `(sample_shape) x batch_shape x 1`-dim Tensor of best feasible objectives.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">constraints</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># unconstrained case</span>
        <span class="c1"># we don't need to differentiate through X_baseline for now, so taking</span>
        <span class="c1"># the regular max over the n points to get best_f is fine</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">is_feasible</span> <span class="o">=</span> <span class="n">compute_feasibility_indicator</span><span class="p">(</span>
        <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="n">samples</span>
    <span class="p">)</span>  <span class="c1"># sample_shape x batch_shape x q</span>

    <span class="k">if</span> <span class="n">is_feasible</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
        <span class="n">infeasible_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">inf</span>

    <span class="k">elif</span> <span class="n">infeasible_obj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">infeasible_value</span> <span class="o">=</span> <span class="n">infeasible_obj</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"Must specify `model` when no feasible observation exists."</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">X_baseline</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"Must specify `X_baseline` when no feasible observation exists."</span>
            <span class="p">)</span>
        <span class="n">infeasible_value</span> <span class="o">=</span> <span class="n">_estimate_objective_lower_bound</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
            <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X_baseline</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">obj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">is_feasible</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">infeasible_value</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_estimate_objective_lower_bound</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">],</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">],</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Estimates a lower bound on the objective values by evaluating the model at convex</span>
<span class="sd">    combinations of `X`, returning the 6-sigma lower bound of the computed statistics.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: A fitted model.</span>
<span class="sd">        objective: An MCAcquisitionObjective with `m` outputs.</span>
<span class="sd">        posterior_transform: A PosteriorTransform.</span>
<span class="sd">        X: A `n x d`-dim Tensor of design points from which to draw convex combinations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `m`-dimensional Tensor of lower bounds of the objectives.</span>
<span class="sd">    """</span>
    <span class="n">convex_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
        <span class="mi">32</span><span class="p">,</span>
        <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">weights_sum</span> <span class="o">=</span> <span class="n">convex_weights</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">convex_weights</span> <span class="o">=</span> <span class="n">convex_weights</span> <span class="o">/</span> <span class="n">weights_sum</span>
    <span class="c1"># infeasible cost M is such that -M &lt; min_x f(x), thus</span>
    <span class="c1"># 0 &lt; min_x f(x) - (-M), so we should take -M as a lower</span>
    <span class="c1"># bound on the best feasible objective</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">get_infeasible_cost</span><span class="p">(</span>
        <span class="n">X</span><span class="o">=</span><span class="n">convex_weights</span> <span class="o">@</span> <span class="n">X</span><span class="p">,</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">,</span>
    <span class="p">)</span>


<div class="viewcode-block" id="get_infeasible_cost"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.get_infeasible_cost">[docs]</a><span class="k">def</span> <span class="nf">get_infeasible_cost</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]],</span> <span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""Get infeasible cost for a model and objective.</span>

<span class="sd">    For each outcome, computes an infeasible cost `M` such that</span>
<span class="sd">    `-M &lt; min_x f(x)` almost always, so that feasible points are preferred.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `n x d` Tensor of `n` design points to use in evaluating the</span>
<span class="sd">            minimum. These points should cover the design space well. The more</span>
<span class="sd">            points the better the estimate, at the expense of added computation.</span>
<span class="sd">        model: A fitted botorch model with `m` outcomes.</span>
<span class="sd">        objective: The objective with which to evaluate the model output.</span>
<span class="sd">        posterior_transform: A PosteriorTransform (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">        An `m`-dim tensor of infeasible cost values.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; model = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">        &gt;&gt;&gt; objective = lambda Y: Y[..., -1] ** 2</span>
<span class="sd">        &gt;&gt;&gt; M = get_infeasible_cost(train_X, model, obj)</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

        <span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">posterior</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">)</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">posterior</span><span class="o">.</span><span class="n">mean</span> <span class="o">-</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">posterior</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(),</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">lb</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="n">posterior</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
        <span class="n">lb</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Take outcome-wise min. Looping in to handle batched models.</span>
    <span class="k">while</span> <span class="n">lb</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">lb</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">lb</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span></div>


<div class="viewcode-block" id="prune_inferior_points"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.prune_inferior_points">[docs]</a><span class="k">def</span> <span class="nf">prune_inferior_points</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCAcquisitionObjective</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">constraints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
    <span class="n">max_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MCSampler</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">marginalize_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""Prune points from an input tensor that are unlikely to be the best point.</span>

<span class="sd">    Given a model, an objective, and an input tensor `X`, this function returns</span>
<span class="sd">    the subset of points in `X` that have some probability of being the best</span>
<span class="sd">    point under the objective. This function uses sampling to estimate the</span>
<span class="sd">    probabilities, the higher the number of points `n` in `X` the higher the</span>
<span class="sd">    number of samples `num_samples` should be to obtain accurate estimates.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: A fitted model. Batched models are currently not supported.</span>
<span class="sd">        X: An input tensor of shape `n x d`. Batched inputs are currently not</span>
<span class="sd">            supported.</span>
<span class="sd">        objective: The objective under which to evaluate the posterior.</span>
<span class="sd">        posterior_transform: A PosteriorTransform (optional).</span>
<span class="sd">        constraints: A list of constraint callables which map a Tensor of posterior</span>
<span class="sd">            samples of dimension `sample_shape x batch-shape x q x m`-dim to a</span>
<span class="sd">            `sample_shape x batch-shape x q`-dim Tensor. The associated constraints</span>
<span class="sd">            are satisfied if `constraint(samples) &lt; 0`.</span>
<span class="sd">        num_samples: The number of samples used to compute empirical</span>
<span class="sd">            probabilities of being the best point.</span>
<span class="sd">        max_frac: The maximum fraction of points to retain. Must satisfy</span>
<span class="sd">            `0 &lt; max_frac &lt;= 1`. Ensures that the number of elements in the</span>
<span class="sd">            returned tensor does not exceed `ceil(max_frac * n)`.</span>
<span class="sd">        sampler: If provided, will use this customized sampler instead of</span>
<span class="sd">            automatically constructing one with `num_samples`.</span>
<span class="sd">        marginalize_dim: A batch dimension that should be marginalized.</span>
<span class="sd">            For example, this is useful when using a batched fully Bayesian</span>
<span class="sd">            model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `n' x d` with subset of points in `X`, where</span>

<span class="sd">            n' = min(N_nz, ceil(max_frac * n))</span>

<span class="sd">        with `N_nz` the number of points in `X` that have non-zero (empirical,</span>
<span class="sd">        under `num_samples` samples) probability of being the best point.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">marginalize_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">is_fully_bayesian</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
        <span class="c1"># TODO: Properly deal with marginalizing fully Bayesian models</span>
        <span class="n">marginalize_dim</span> <span class="o">=</span> <span class="n">MCMC_DIM</span>

    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># TODO: support batched inputs (req. dealing with ragged tensors)</span>
        <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
            <span class="s2">"Batched inputs `X` are currently unsupported by prune_inferior_points"</span>
        <span class="p">)</span>
    <span class="n">max_points</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">max_frac</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">max_points</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">max_points</span> <span class="o">&gt;</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"max_frac must take values in (0, 1], is </span><span class="si">{</span><span class="n">max_frac</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">posterior_transform</span><span class="o">=</span><span class="n">posterior_transform</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sampler</span> <span class="o">=</span> <span class="n">get_sampler</span><span class="p">(</span>
            <span class="n">posterior</span><span class="o">=</span><span class="n">posterior</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_samples</span><span class="p">])</span>
        <span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">objective</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">objective</span> <span class="o">=</span> <span class="n">IdentityMCObjective</span><span class="p">()</span>
    <span class="n">obj_vals</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">obj_vals</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">obj_vals</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="n">marginalize_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">marginalize_dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># we do this again in compute_feasibility_indicator, but that will</span>
                <span class="c1"># have no effect since marginalize_dim will be non-negative</span>
                <span class="n">marginalize_dim</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="mi">1</span> <span class="o">+</span> <span class="n">normalize_indices</span><span class="p">([</span><span class="n">marginalize_dim</span><span class="p">],</span> <span class="n">d</span><span class="o">=</span><span class="n">obj_vals</span><span class="o">.</span><span class="n">ndim</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="n">obj_vals</span> <span class="o">=</span> <span class="n">obj_vals</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">marginalize_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># TODO: support batched inputs (req. dealing with ragged tensors)</span>
            <span class="k">raise</span> <span class="n">UnsupportedError</span><span class="p">(</span>
                <span class="s2">"Models with multiple batch dims are currently unsupported by"</span>
                <span class="s2">" prune_inferior_points."</span>
            <span class="p">)</span>
    <span class="n">infeas</span> <span class="o">=</span> <span class="o">~</span><span class="n">compute_feasibility_indicator</span><span class="p">(</span>
        <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span>
        <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
        <span class="n">marginalize_dim</span><span class="o">=</span><span class="n">marginalize_dim</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">infeas</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="c1"># set infeasible points to worse than worst objective</span>
        <span class="c1"># across all samples</span>
        <span class="n">obj_vals</span><span class="p">[</span><span class="n">infeas</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj_vals</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">is_best</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">obj_vals</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">idcs</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">is_best</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">idcs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_points</span><span class="p">:</span>
        <span class="n">counts</span><span class="p">,</span> <span class="n">order_idcs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">idcs</span> <span class="o">=</span> <span class="n">order_idcs</span><span class="p">[:</span><span class="n">max_points</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="n">idcs</span><span class="p">]</span></div>


<div class="viewcode-block" id="project_to_target_fidelity"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.project_to_target_fidelity">[docs]</a><span class="k">def</span> <span class="nf">project_to_target_fidelity</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">target_fidelities</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""Project `X` onto the target set of fidelities.</span>

<span class="sd">    This function assumes that the set of feasible fidelities is a box, so</span>
<span class="sd">    projecting here just means setting each fidelity parameter to its target</span>
<span class="sd">    value.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `batch_shape x q x d`-dim Tensor of with `q` `d`-dim design points</span>
<span class="sd">            for each t-batch.</span>
<span class="sd">        target_fidelities: A dictionary mapping a subset of columns of `X` (the</span>
<span class="sd">            fidelity parameters) to their respective target fidelity value. If</span>
<span class="sd">            omitted, assumes that the last column of X is the fidelity parameter</span>
<span class="sd">            with a target value of 1.0.</span>

<span class="sd">    Return:</span>
<span class="sd">        A `batch_shape x q x d`-dim Tensor `X_proj` with fidelity parameters</span>
<span class="sd">            projected to the provided fidelity values.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">target_fidelities</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">target_fidelities</span> <span class="o">=</span> <span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># normalize to positive indices</span>
    <span class="n">tfs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span> <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">d</span> <span class="o">+</span> <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">target_fidelities</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="c1"># here we're looping through the feature dimension of X - this could be</span>
    <span class="c1"># slow for large `d`, we should optimize this for that case</span>
    <span class="n">X_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
        <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tfs</span> <span class="k">else</span> <span class="n">tfs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">ones</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">X_proj</span></div>


<div class="viewcode-block" id="expand_trace_observations"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.expand_trace_observations">[docs]</a><span class="k">def</span> <span class="nf">expand_trace_observations</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">fidelity_dims</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">num_trace_obs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""Expand `X` with trace observations.</span>

<span class="sd">    Expand a tensor of inputs with "trace observations" that are obtained during</span>
<span class="sd">    the evaluation of the candidate set. This is used in multi-fidelity</span>
<span class="sd">    optimization. It can be though of as augmenting the `q`-batch with additional</span>
<span class="sd">    points that are the expected trace observations.</span>

<span class="sd">    Let `f_i` be the `i`-th fidelity parameter. Then this functions assumes that</span>
<span class="sd">    for each element of the q-batch, besides the fidelity `f_i`, we will observe</span>
<span class="sd">    additonal fidelities `f_i1, ..., f_iK`, where `K = num_trace_obs`, during</span>
<span class="sd">    evaluation of the candidate set `X`. Specifically, this function assumes</span>
<span class="sd">    that `f_ij = (K-j) / (num_trace_obs + 1) * f_i` for all `i`. That is, the</span>
<span class="sd">    expansion is performed in parallel for all fidelities (it does not expand</span>
<span class="sd">    out all possible combinations).</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `batch_shape x q x d`-dim Tensor of with `q` `d`-dim design points</span>
<span class="sd">            (incl. the fidelity parameters) for each t-batch.</span>
<span class="sd">        fidelity_dims: The indices of the fidelity parameters. If omitted,</span>
<span class="sd">            assumes that the last column of X contains the fidelity parameters.</span>
<span class="sd">        num_trace_obs: The number of trace observations to use.</span>

<span class="sd">    Return:</span>
<span class="sd">        A `batch_shape x (q + num_trace_obs x q) x d` Tensor `X_expanded` that</span>
<span class="sd">            expands `X` with trace observations.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">num_trace_obs</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># No need to expand if we don't use trace observations</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="k">if</span> <span class="n">fidelity_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fidelity_dims</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># The general strategy in the following is to expand `X` to the desired</span>
    <span class="c1"># shape, and then multiply it (point-wise) with a tensor of scaling factors</span>
    <span class="n">reps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span> <span class="o">+</span> <span class="n">num_trace_obs</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">X_expanded</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="n">reps</span><span class="p">)</span>  <span class="c1"># batch_shape x (q + num_trace_obs x q) x d</span>
    <span class="n">scale_fac</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">X_expanded</span><span class="p">)</span>
    <span class="n">s_pad</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_trace_obs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># tensor of  num_trace_obs scaling factors equally space between 1-s_pad and s_pad</span>
    <span class="n">sf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">s_pad</span><span class="p">,</span> <span class="n">s_pad</span><span class="p">,</span> <span class="n">num_trace_obs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="c1"># repeat each element q times</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">sf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">sf</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>  <span class="c1"># num_trace_obs * q</span>
    <span class="c1"># now expand this to num_trace_obs x q x num_fidelities</span>
    <span class="n">sf</span> <span class="o">=</span> <span class="n">sf</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">X_expanded</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">q</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">fidelity_dims</span><span class="p">))</span>
    <span class="c1"># change relevant entries of the scaling tensor</span>
    <span class="n">scale_fac</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">q</span><span class="p">:,</span> <span class="n">fidelity_dims</span><span class="p">]</span> <span class="o">=</span> <span class="n">sf</span>
    <span class="k">return</span> <span class="n">scale_fac</span> <span class="o">*</span> <span class="n">X_expanded</span></div>


<div class="viewcode-block" id="project_to_sample_points"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.project_to_sample_points">[docs]</a><span class="k">def</span> <span class="nf">project_to_sample_points</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">sample_points</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""Augment `X` with sample points at which to take weighted average.</span>

<span class="sd">    Args:</span>
<span class="sd">        X: A `batch_shape x 1 x d`-dim Tensor of with one d`-dim design points</span>
<span class="sd">            for each t-batch.</span>
<span class="sd">        sample_points: `p x d'`-dim Tensor (`d' &lt; d`) of `d'`-dim sample points at</span>
<span class="sd">            which to compute the expectation. The `d'`-dims refer to the trailing</span>
<span class="sd">            columns of X.</span>
<span class="sd">    Returns:</span>
<span class="sd">        A `batch_shape x p x d` Tensor where the q-batch includes the `p` sample points.</span>
<span class="sd">    """</span>
    <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">d_prime</span> <span class="o">=</span> <span class="n">sample_points</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">X_new</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">batch_shape</span><span class="p">),</span> <span class="n">p</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># batch_shape x p x d</span>
    <span class="n">X_new</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="n">d_prime</span><span class="p">:]</span> <span class="o">=</span> <span class="n">sample_points</span>
    <span class="k">return</span> <span class="n">X_new</span></div>


<div class="viewcode-block" id="get_optimal_samples"><a class="viewcode-back" href="../../../acquisition.html#botorch.acquisition.utils.get_optimal_samples">[docs]</a><span class="k">def</span> <span class="nf">get_optimal_samples</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Model</span><span class="p">,</span>
    <span class="n">bounds</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">num_optima</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">raw_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_restarts</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""Draws sample paths from the posterior and maximizes the samples using GD.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (Model): The model from which samples are drawn.</span>
<span class="sd">        bounds: (Tensor): Bounds of the search space. If the model inputs are</span>
<span class="sd">            normalized, the bounds should be normalized as well.</span>
<span class="sd">        num_optima (int): The number of paths to be drawn and optimized.</span>
<span class="sd">        raw_samples (int, optional): The number of candidates randomly sample.</span>
<span class="sd">            Defaults to 1024.</span>
<span class="sd">        num_restarts (int, optional): The number of candidates to do gradient-based</span>
<span class="sd">            optimization on. Defaults to 20.</span>
<span class="sd">        maximize: Whether to maximize or minimize the samples.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Tuple[Tensor, Tensor]: The optimal input locations and corresponding</span>
<span class="sd">        outputs, x* and f*.</span>

<span class="sd">    """</span>
    <span class="n">paths</span> <span class="o">=</span> <span class="n">draw_matheron_paths</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">num_optima</span><span class="p">]))</span>
    <span class="n">optimal_inputs</span><span class="p">,</span> <span class="n">optimal_outputs</span> <span class="o">=</span> <span class="n">optimize_posterior_samples</span><span class="p">(</span>
        <span class="n">paths</span><span class="p">,</span>
        <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span>
        <span class="n">raw_samples</span><span class="o">=</span><span class="n">raw_samples</span><span class="p">,</span>
        <span class="n">num_restarts</span><span class="o">=</span><span class="n">num_restarts</span><span class="p">,</span>
        <span class="n">maximize</span><span class="o">=</span><span class="n">maximize</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">optimal_inputs</span><span class="p">,</span> <span class="n">optimal_outputs</span></div>
</pre></div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">BoTorch</a></h1>
<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../../../index.html">Documentation overview</a><ul>
<li><a href="../../index.html">Module code</a><ul>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../../../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q" spellcheck="false" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/v/0.9.3/" class="nav-home"><img src="/v/0.9.3/img/botorch.png" alt="BoTorch" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/v/0.9.3/docs/introduction">Introduction</a><a href="/v/0.9.3/docs/getting_started">Getting Started</a><a href="/v/0.9.3/tutorials/">Tutorials</a><a href="/v/0.9.3/api/">API Reference</a><a href="https://arxiv.org/abs/1910.06403">Paper</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/botorch" data-count-href="https://github.com/pytorch/botorch/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star BoTorch on GitHub">botorch</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/v/0.9.3/img/oss_logo.png" alt="Meta Open Source" width="300" height="25"/></a><section class="copyright"> Copyright © 2023 Meta Platforms, Inc</section><script>
            (function() {
              var BAD_BASE = '/botorch/';
              if (window.location.origin !== 'https://botorch.org') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://botorch.org/v/0.9.3/' + newPathname;
                
              }
            })();
          </script></footer></div></body></html>