<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>BoTorch · Bayesian Optimization in PyTorch</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Bayesian Optimization in PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="BoTorch · Bayesian Optimization in PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://botorch.org/v/0.8.0/"/><meta property="og:description" content="Bayesian Optimization in PyTorch"/><meta property="og:image" content="https://botorch.org/v/0.8.0/img/botorch.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://botorch.org/v/0.8.0/img/botorch.png"/><link rel="shortcut icon" href="/v/0.8.0/img/botorch.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-139570076-2', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/v/0.8.0/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/v/0.8.0/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/v/0.8.0/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/v/0.8.0/js/scrollSpy.js"></script><link rel="stylesheet" href="/v/0.8.0/css/main.css"/><script src="/v/0.8.0/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/v/0.8.0/"><img class="logo" src="/v/0.8.0/img/botorch_logo_lockup_white.png" alt="BoTorch"/><h2 class="headerTitleWithLogo">BoTorch</h2></a><a href="/v/0.8.0/versions"><h3>0.8.0</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/v/0.8.0/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/v/0.8.0/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/v/0.8.0/api/" target="_self">API Reference</a></li><li class=""><a href="/v/0.8.0/docs/papers" target="_self">Papers</a></li><li class=""><a href="https://github.com/pytorch/botorch" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./" src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<section id="module-botorch.optim">
<span id="botorch-optim"></span><h1>botorch.optim<a class="headerlink" href="#module-botorch.optim" title="Permalink to this heading">¶</a></h1>
<section id="optimization">
<h2>Optimization<a class="headerlink" href="#optimization" title="Permalink to this heading">¶</a></h2>
<section id="module-botorch.optim.core">
<span id="core"></span><h3>Core<a class="headerlink" href="#module-botorch.optim.core" title="Permalink to this heading">¶</a></h3>
<p>Core abstractions and generic optimizers.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">OptimizationStatus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#OptimizationStatus"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.OptimizationStatus" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></p>
<p>An enumeration.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.RUNNING">
<span class="sig-name descname"><span class="pre">RUNNING</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.RUNNING" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.SUCCESS">
<span class="sig-name descname"><span class="pre">SUCCESS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">2</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.SUCCESS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.FAILURE">
<span class="sig-name descname"><span class="pre">FAILURE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">3</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.FAILURE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.STOPPED">
<span class="sig-name descname"><span class="pre">STOPPED</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">4</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.STOPPED" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">OptimizationResult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'int'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'Union[float,</span> <span class="pre">int]'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">status</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'OptimizationStatus'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">runtime</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'Optional[float]'</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'Optional[str]'</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#OptimizationResult"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.OptimizationResult" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>step</strong> (<em>int</em>) – </p></li>
<li><p><strong>fval</strong> (<em>Union</em><em>[</em><em>float</em><em>, </em><em>int</em><em>]</em>) – </p></li>
<li><p><strong>status</strong> (<a class="reference internal" href="#botorch.optim.core.OptimizationStatus" title="botorch.optim.core.OptimizationStatus"><em>OptimizationStatus</em></a>) – </p></li>
<li><p><strong>runtime</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – </p></li>
<li><p><strong>message</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.step">
<span class="sig-name descname"><span class="pre">step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.fval">
<span class="sig-name descname"><span class="pre">fval</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.fval" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.status">
<span class="sig-name descname"><span class="pre">status</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#botorch.optim.core.OptimizationStatus" title="botorch.optim.core.OptimizationStatus"><span class="pre">OptimizationStatus</span></a></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.status" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.runtime">
<span class="sig-name descname"><span class="pre">runtime</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.runtime" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.message">
<span class="sig-name descname"><span class="pre">message</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.message" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.core.scipy_minimize">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">scipy_minimize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'L-BFGS-B'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#scipy_minimize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.scipy_minimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Generic scipy.optimize.minimize-based optimization routine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> (<em>Union</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Optional</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>]</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.closures.core.NdarrayOptimizationClosure" title="botorch.optim.closures.core.NdarrayOptimizationClosure"><em>NdarrayOptimizationClosure</em></a><em>]</em>) – Callable that returns a tensor and an iterable of gradient tensors or
NdarrayOptimizationClosure instance.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A dictionary mapping parameter names to lower and upper bounds.</p></li>
<li><p><strong>callback</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em>) – A callable taking <cite>parameters</cite> and an OptimizationResult as arguments.</p></li>
<li><p><strong>x0</strong> (<em>Optional</em><em>[</em><em>ndarray</em><em>]</em>) – An optional initialization vector passed to scipy.optimize.minimize.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Solver type, passed along to scipy.minimize.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – Dictionary of solver options, passed along to scipy.minimize.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An OptimizationResult summarizing the final state of the run.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.core.torch_minimize">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">torch_minimize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_limit=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criterion=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#torch_minimize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.torch_minimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Generic torch.optim-based optimization routine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Optional</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>]</em><em>]</em>) – Callable that returns a tensor and an iterable of gradient tensors.
Responsible for setting relevant parameters’ <cite>grad</cite> attributes.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em><em>]</em>) – An optional dictionary of bounds for elements of <cite>parameters</cite>.</p></li>
<li><p><strong>callback</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em>) – A callable taking <cite>parameters</cite> and an OptimizationResult as arguments.</p></li>
<li><p><strong>step_limit</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Integer specifying a maximum number of optimization steps.
One of <cite>step_limit</cite> or <cite>stopping_criterion</cite> must be passed.</p></li>
<li><p><strong>stopping_criterion</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>bool</em><em>]</em><em>]</em>) – A StoppingCriterion for the optimization loop.</p></li>
<li><p><strong>optimizer</strong> (<em>Union</em><em>[</em><em>Optimizer</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>Optimizer</em><em>]</em><em>]</em>) – A <cite>torch.optim.Optimizer</cite> instance or a factory that takes
a list of parameters and returns an <cite>Optimizer</cite> instance.</p></li>
<li><p><strong>scheduler</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>_LRScheduler</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Optimizer</em><em>]</em><em>, </em><em>_LRScheduler</em><em>]</em><em>]</em><em>]</em>) – A <cite>torch.optim.lr_scheduler._LRScheduler</cite> instance or a factory
that takes a <cite>Optimizer</cite> instance and returns a <cite>_LRSchedule</cite> instance.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An OptimizationResult summarizing the final state of the run.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.optimize">
<span id="acquisition-function-optimization"></span><h3>Acquisition Function Optimization<a class="headerlink" href="#module-botorch.optim.optimize" title="Permalink to this heading">¶</a></h3>
<p>Methods for optimizing acquisition functions.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequential</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a set of candidates via multi-start optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Union</em><em>[</em><em>bool</em><em>, </em><em>float</em><em>, </em><em>int</em><em>, </em><em>str</em><em>]</em><em>]</em><em>]</em>) – Options for candidate generation.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>equality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Callable</em><em>]</em><em>]</em>) – A list of callables with that represent
non-linear inequality constraints of the form <cite>callable(x) &gt;= 0</cite>. Each
callable is expected to take a <cite>(num_restarts) x q x d</cite>-dim tensor as an
input and return a <cite>(num_restarts) x q</cite>-dim tensor with the constraint
values. The constraints will later be passed to SLSQP. You need to pass in
<cite>batch_initial_conditions</cite> in this case. Using non-linear inequality
constraints also requires that <cite>batch_limit</cite> is set to 1, which will be
done automatically if not specified in <cite>options</cite>.</p></li>
<li><p><strong>fixed_features</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – A tensor to specify the initial conditions. Set
this if you do not want to use default initialization strategy.</p></li>
<li><p><strong>return_best_only</strong> (<em>bool</em>) – If False, outputs the solutions corresponding to all
random restart initializations of the optimization.</p></li>
<li><p><strong>sequential</strong> (<em>bool</em>) – If False, uses joint optimization, otherwise uses sequential
optimization.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – Additonal keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>(num_restarts) x q x d</cite>-dim tensor of generated candidates.</p></li>
<li><dl class="simple">
<dt>a tensor of associated acquisition values. If <cite>sequential=False</cite>,</dt><dd><p>this is a <cite>(num_restarts)</cite>-dim tensor of joint acquisition values
(with explicit restart dimension if <cite>return_best_only=False</cite>). If
<cite>sequential=True</cite>, this is a <cite>q</cite>-dim tensor of expected acquisition
values conditional on having observed candidates <cite>0,1,…,i-1</cite>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate `q=2` candidates jointly using 20 random restarts</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and 512 raw samples</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidates</span><span class="p">,</span> <span class="n">acq_value</span> <span class="o">=</span> <span class="n">optimize_acqf</span><span class="p">(</span><span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; generate `q=3` candidates sequentially using 15 random restarts
&gt;&gt;&gt; # and 256 raw samples
&gt;&gt;&gt; qEI = qExpectedImprovement(model, best_f=0.2)
&gt;&gt;&gt; bounds = torch.tensor([[0.], [1.]])
&gt;&gt;&gt; candidates, acq_value_list = optimize_acqf(
&gt;&gt;&gt;     qEI, bounds, 3, 15, 256, sequential=True
&gt;&gt;&gt; )
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_cyclic">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_cyclic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cyclic_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_cyclic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_cyclic" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a set of <cite>q</cite> candidates via cyclic optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Union</em><em>[</em><em>bool</em><em>, </em><em>float</em><em>, </em><em>int</em><em>, </em><em>str</em><em>]</em><em>]</em><em>]</em>) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>fixed_features</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – A tensor to specify the initial conditions.
If no initial conditions are provided, the default initialization will
be used.</p></li>
<li><p><strong>cyclic_options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Union</em><em>[</em><em>bool</em><em>, </em><em>float</em><em>, </em><em>int</em><em>, </em><em>str</em><em>]</em><em>]</em><em>]</em>) – Options for stopping criterion for outer cyclic optimization.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>equality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><dl class="simple">
<dt>a <cite>q</cite>-dim tensor of expected acquisition values, where the value at</dt><dd><p>index <cite>i</cite> is the acquisition value conditional on having observed
all candidates except candidate <cite>i</cite>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate `q=3` candidates cyclically using 15 random restarts</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 256 raw samples, and 4 cycles</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidates</span><span class="p">,</span> <span class="n">acq_value_list</span> <span class="o">=</span> <span class="n">optimize_acqf_cyclic</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">cyclic_options</span><span class="o">=</span><span class="p">{</span><span class="s2">"maxiter"</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_list">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a list of candidates from a list of acquisition functions.</p>
<p>The acquisition functions are optimized in sequence, with previous candidates
set as <cite>X_pending</cite>. This is also known as sequential greedy optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function_list</strong> (<em>List</em><em>[</em><em>AcquisitionFunction</em><em>]</em>) – A list of acquisition functions.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Union</em><em>[</em><em>bool</em><em>, </em><em>float</em><em>, </em><em>int</em><em>, </em><em>str</em><em>]</em><em>]</em><em>]</em>) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>fixed_features</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>fixed_features_list</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – A list of maps <cite>{feature_index: value}</cite>. The i-th
item represents the fixed_feature for the i-th optimization. If
<cite>fixed_features_list</cite> is provided, <cite>optimize_acqf_mixed</cite> is invoked.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>inequality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>equality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><dl class="simple">
<dt>a <cite>q</cite>-dim tensor of expected acquisition values, where the value at</dt><dd><p>index <cite>i</cite> is the acquisition value conditional on having observed
all candidates except candidate <cite>i</cite>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_mixed">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_mixed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_mixed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_mixed" title="Permalink to this definition">¶</a></dt>
<dd><p>Optimize over a list of fixed_features and returns the best solution.</p>
<p>This is useful for optimizing over mixed continuous and discrete domains.
For q &gt; 1 this function always performs sequential greedy optimization (with
proper conditioning on generated candidates).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>fixed_features_list</strong> (<em>List</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) – A list of maps <cite>{feature_index: value}</cite>. The i-th
item represents the fixed_feature for the i-th optimization.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Union</em><em>[</em><em>bool</em><em>, </em><em>float</em><em>, </em><em>int</em><em>, </em><em>str</em><em>]</em><em>]</em><em>]</em>) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>post_processing_func</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – A tensor to specify the initial conditions. Set
this if you do not want to use default initialization strategy.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>equality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>an associated acquisition value.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_discrete">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_discrete</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">choices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unique</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_discrete"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_discrete" title="Permalink to this definition">¶</a></dt>
<dd><p>Optimize over a discrete set of points using batch evaluation.</p>
<p>For <cite>q &gt; 1</cite> this function generates candidates by means of sequential
conditioning (rather than joint optimization), since for all but the
smalles number of choices the set <cite>choices^q</cite> of discrete points to
evaluate quickly explodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>choices</strong> (<em>Tensor</em>) – A <cite>num_choices x d</cite> tensor of possible choices.</p></li>
<li><p><strong>max_batch_size</strong> (<em>int</em>) – The maximum number of choices to evaluate in batch.
A large limit can cause excessive memory usage if the model has
a large training set.</p></li>
<li><p><strong>unique</strong> (<em>bool</em>) – If True return unique choices, o/w choices may be repeated
(only relevant if <cite>q &gt; 1</cite>).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A three-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>an associated acquisition value.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_discrete_local_search">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_discrete_local_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_choices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_avoid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unique</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_discrete_local_search"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_discrete_local_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Optimize acquisition function over a lattice.</p>
<p>This is useful when d is large and enumeration of the search space
isn’t possible. For q &gt; 1 this function always performs sequential
greedy optimization (with proper conditioning on generated candidates).</p>
<p>NOTE: While this method supports arbitrary lattices, it has only been
thoroughly tested for {0, 1}^d. Consider it to be in alpha stage for
the more general case.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction</p></li>
<li><p><strong>discrete_choices</strong> (<em>List</em><em>[</em><em>Tensor</em><em>]</em>) – A list of possible discrete choices for each dimension.
Each element in the list is expected to be a torch tensor.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>X_avoid</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – An <cite>n x d</cite> tensor of candidates that we aren’t allowed to pick.</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Optional</em><em>[</em><em>Tensor</em><em>]</em>) – A tensor of size <cite>n x 1 x d</cite> to specify the
initial conditions. Set this if you do not want to use default
initialization strategy.</p></li>
<li><p><strong>max_batch_size</strong> (<em>int</em>) – The maximum number of choices to evaluate in batch.
A large limit can cause excessive memory usage if the model has
a large training set.</p></li>
<li><p><strong>unique</strong> (<em>bool</em>) – If True return unique choices, o/w choices may be repeated
(only relevant if <cite>q &gt; 1</cite>).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>an associated acquisition value.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.fit">
<span id="model-fitting-optimization"></span><h3>Model Fitting Optimization<a class="headerlink" href="#module-botorch.optim.fit" title="Permalink to this heading">¶</a></h3>
<p>Tools for model fitting.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.fit.fit_gpytorch_mll_scipy">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.fit.</span></span><span class="sig-name descname"><span class="pre">fit_gpytorch_mll_scipy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'L-BFGS-B'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/fit.html#fit_gpytorch_mll_scipy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.fit.fit_gpytorch_mll_scipy" title="Permalink to this definition">¶</a></dt>
<dd><p>Generic scipy.optimized-based fitting routine for GPyTorch MLLs.</p>
<p>The model and likelihood in mll must already be in train mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – MarginalLogLikelihood to be maximized.</p></li>
<li><p><strong>parameters</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – Optional dictionary of parameters to be optimized. Defaults
to all parameters of <cite>mll</cite> that require gradients.</p></li>
<li><p><strong>bounds</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A dictionary of user-specified bounds for <cite>parameters</cite>. Used to update
default parameter bounds obtained from <cite>mll</cite>.</p></li>
<li><p><strong>closure</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Optional</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – Callable that returns a tensor and an iterable of gradient tensors.
Responsible for setting the <cite>grad</cite> attributes of <cite>parameters</cite>. If no closure
is provided, one will be obtained by calling <cite>get_loss_closure_with_grads</cite>.</p></li>
<li><p><strong>closure_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – Keyword arguments passed to <cite>closure</cite>.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Solver type, passed along to scipy.minimize.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – Dictionary of solver options, passed along to scipy.minimize.</p></li>
<li><p><strong>callback</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em>) – Optional callback taking <cite>parameters</cite> and an OptimizationResult as its
sole arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The final OptimizationResult.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.fit.fit_gpytorch_mll_torch">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.fit.</span></span><span class="sig-name descname"><span class="pre">fit_gpytorch_mll_torch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_limit=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criterion=&lt;botorch.optim.utils.common._TDefault</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/fit.html#fit_gpytorch_mll_torch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.fit.fit_gpytorch_mll_torch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generic torch.optim-based fitting routine for GPyTorch MLLs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – MarginalLogLikelihood to be maximized.</p></li>
<li><p><strong>parameters</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – Optional dictionary of parameters to be optimized. Defaults
to all parameters of <cite>mll</cite> that require gradients.</p></li>
<li><p><strong>bounds</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A dictionary of user-specified bounds for <cite>parameters</cite>. Used to update
default parameter bounds obtained from <cite>mll</cite>.</p></li>
<li><p><strong>closure</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Optional</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>]</em><em>]</em><em>]</em>) – Callable that returns a tensor and an iterable of gradient tensors.
Responsible for setting the <cite>grad</cite> attributes of <cite>parameters</cite>. If no closure
is provided, one will be obtained by calling <cite>get_loss_closure_with_grads</cite>.</p></li>
<li><p><strong>closure_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – Keyword arguments passed to <cite>closure</cite>.</p></li>
<li><p><strong>step_limit</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Optional upper bound on the number of optimization steps.</p></li>
<li><p><strong>stopping_criterion</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>bool</em><em>]</em><em>]</em>) – A StoppingCriterion for the optimization loop.</p></li>
<li><p><strong>optimizer</strong> (<em>Union</em><em>[</em><em>Optimizer</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>...</em><em>]</em><em>, </em><em>Optimizer</em><em>]</em><em>]</em>) – A <cite>torch.optim.Optimizer</cite> instance or a factory that takes
a list of parameters and returns an <cite>Optimizer</cite> instance.</p></li>
<li><p><strong>scheduler</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>_LRScheduler</em><em>, </em><em>Callable</em><em>[</em><em>[</em><em>...</em><em>]</em><em>, </em><em>_LRScheduler</em><em>]</em><em>]</em><em>]</em>) – A <cite>torch.optim.lr_scheduler._LRScheduler</cite> instance or a factory
that takes an <cite>Optimizer</cite> instance and returns an <cite>_LRSchedule</cite>.</p></li>
<li><p><strong>callback</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em>) – Optional callback taking <cite>parameters</cite> and an OptimizationResult as its
sole arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The final OptimizationResult.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.fit.fit_gpytorch_scipy">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.fit.</span></span><span class="sig-name descname"><span class="pre">fit_gpytorch_scipy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method='L-BFGS-B'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">track_iterations=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approx_mll=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scipy_objective=&lt;function</span> <span class="pre">_scipy_objective_and_grad&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_to_array_func=&lt;function</span> <span class="pre">module_to_array&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_from_array_func=&lt;function</span> <span class="pre">set_params_with_array&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/fit.html#fit_gpytorch_scipy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.fit.fit_gpytorch_scipy" title="Permalink to this definition">¶</a></dt>
<dd><p>Legacy method for scipy-based fitting of gpytorch models.</p>
<p>The model and likelihood in mll must already be in train mode. This method requires
that the model has <cite>train_inputs</cite> and <cite>train_targets</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – MarginalLogLikelihood to be maximized.</p></li>
<li><p><strong>bounds</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A dictionary mapping parameter names to tuples of lower and upper
bounds.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Solver type, passed along to scipy.optimize.minimize.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – Dictionary of solver options, passed along to scipy.optimize.minimize.</p></li>
<li><p><strong>approx_mll</strong> (<em>bool</em>) – If True, use gpytorch’s approximate MLL computation. This is
disabled by default since the stochasticity is an issue for
determistic optimizers). Enabling this is only recommended when
working with large training data sets (n&gt;2000).</p></li>
<li><p><strong>track_iterations</strong> (<em>bool</em>) – </p></li>
<li><p><strong>scipy_objective</strong> (<em>Callable</em><em>[</em><em>[</em><em>ndarray</em><em>, </em><em>MarginalLogLikelihood</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#botorch.optim.utils.model_utils.TorchAttr" title="botorch.optim.utils.model_utils.TorchAttr"><em>TorchAttr</em></a><em>]</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em>, </em><em>ndarray</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>module_to_array_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Module</em><em>, </em><em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em><em>]</em><em>, </em><em>Optional</em><em>[</em><em>Set</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>ndarray</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#botorch.optim.utils.model_utils.TorchAttr" title="botorch.optim.utils.model_utils.TorchAttr"><em>TorchAttr</em></a><em>]</em><em>, </em><em>Optional</em><em>[</em><em>ndarray</em><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>module_from_array_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Module</em><em>, </em><em>ndarray</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#botorch.optim.utils.model_utils.TorchAttr" title="botorch.optim.utils.model_utils.TorchAttr"><em>TorchAttr</em></a><em>]</em><em>]</em><em>, </em><em>Module</em><em>]</em>) – </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>2-element tuple containing
- MarginalLogLikelihood with parameters optimized in-place.
- Dictionary with the following key/values:
“fopt”: Best mll value.
“wall_time”: Wall time of fitting.
“iterations”: List of OptimizationResult objects with information on each
iteration. If track_iterations is False, will be empty.
“OptimizeResult”: The result returned by <cite>scipy.optim.minimize</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>MarginalLogLikelihood</em>, <em>Dict</em>[str, <em>Union</em>[float, <em>List</em>[<a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a>]]]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.fit.fit_gpytorch_torch">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.fit.</span></span><span class="sig-name descname"><span class="pre">fit_gpytorch_torch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_cls=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">track_iterations=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approx_mll=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/fit.html#fit_gpytorch_torch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.fit.fit_gpytorch_torch" title="Permalink to this definition">¶</a></dt>
<dd><p>Legacy method for torch-based fitting of gpytorch models.</p>
<p>The model and likelihood in mll must already be in train mode.
Note: this method requires that the model has <cite>train_inputs</cite> and <cite>train_targets</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – MarginalLogLikelihood to be maximized.</p></li>
<li><p><strong>bounds</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em><em>]</em>) – An optional dictionary mapping parameter names to tuples
of lower and upper bounds. Bounds specified here take precedence
over bounds on the same parameters specified in the constraints
registered with the module.</p></li>
<li><p><strong>optimizer_cls</strong> (<em>Optimizer</em>) – Torch optimizer to use. Must not require a closure.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – options for model fitting. Relevant options will be passed to
the <cite>optimizer_cls</cite>. Additionally, options can include: “disp”
to specify whether to display model fitting diagnostics and “maxiter”
to specify the maximum number of iterations.</p></li>
<li><p><strong>track_iterations</strong> (<em>bool</em>) – </p></li>
<li><p><strong>approx_mll</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>2-element tuple containing
- mll with parameters optimized in-place.
- Dictionary with the following key/values:
“fopt”: Best mll value.
“wall_time”: Wall time of fitting.
“iterations”: List of OptimizationResult objects with information on each
iteration. If track_iterations is False, will be empty.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>MarginalLogLikelihood</em>, <em>Dict</em>[str, <em>Union</em>[float, <em>List</em>[<a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a>]]]]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span> <span class="o">=</span> <span class="n">SingleTaskGP</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">gp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fit_gpytorch_torch</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>
</section>
<section id="module-botorch.optim.initializers">
<span id="initialization-helpers"></span><h3>Initialization Helpers<a class="headerlink" href="#module-botorch.optim.initializers" title="Permalink to this heading">¶</a></h3>
<p>References</p>
<div class="citation-list" role="list">
<div class="citation" id="regis" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a href="#id1" role="doc-backlink">Regis</a><span class="fn-bracket">]</span></span>
<p>R. G. Regis, C. A. Shoemaker. Combining radial basis function
surrogates and dynamic coordinate search in high-dimensional
expensive black-box optimization, Engineering Optimization, 2013.</p>
</div>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_batch_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_batch_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_batch_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_batch_initial_conditions" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a batch of initial conditions for random-restart optimziation.</p>
<p>TODO: Support t-batches of initial conditions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – The acquisition function to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic. Note: if <cite>sample_around_best</cite> is True (the default is False),
then <cite>2 * raw_samples</cite> samples are used.</p></li>
<li><p><strong>fixed_features</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Union</em><em>[</em><em>bool</em><em>, </em><em>float</em><em>, </em><em>int</em><em>]</em><em>]</em><em>]</em>) – Options for initial condition generation. For valid options see
<cite>initialize_q_batch</cite> and <cite>initialize_q_batch_nonneg</cite>. If <cite>options</cite>
contains a <cite>nonnegative=True</cite> entry, then <cite>acq_function</cite> is
assumed to be non-negative (useful when using custom acquisition
functions). In addition, an “init_batch_limit” option can be passed
to specify the batch limit for the initialization. This is useful
for avoiding memory limits when computing the batch posterior over
raw samples.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>equality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x q x d</cite> tensor of initial conditions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_batch_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">500</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_one_shot_kg_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_one_shot_kg_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_one_shot_kg_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_one_shot_kg_initial_conditions" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a batch of smart initializations for qKnowledgeGradient.</p>
<p>This function generates initial conditions for optimizing one-shot KG using
the maximizer of the posterior objective. Intutively, the maximizer of the
fantasized posterior will often be close to a maximizer of the current
posterior. This function uses that fact to generate the initital conditions
for the fantasy points. Specifically, a fraction of <cite>1 - frac_random</cite> (see
options) is generated by sampling from the set of maximizers of the
posterior objective (obtained via random restart optimization) according to
a softmax transformation of their respective values. This means that this
initialization strategy internally solves an acquisition function
maximization problem. The remaining <cite>frac_random</cite> fantasy points as well as
all <cite>q</cite> candidate points are chosen according to the standard initialization
strategy in <cite>gen_batch_initial_conditions</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a>) – The qKnowledgeGradient instance to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of
task features.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>fixed_features</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Union</em><em>[</em><em>bool</em><em>, </em><em>float</em><em>, </em><em>int</em><em>]</em><em>]</em><em>]</em>) – Options for initial condition generation. These contain all
settings for the standard heuristic initialization from
<cite>gen_batch_initial_conditions</cite>. In addition, they contain
<cite>frac_random</cite> (the fraction of fully random fantasy points),
<cite>num_inner_restarts</cite> and <cite>raw_inner_samples</cite> (the number of random
restarts and raw samples for solving the posterior objective
maximization problem, respectively) and <cite>eta</cite> (temperature parameter
for sampling heuristic from posterior objective maximizers).</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>equality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x q’ x d</cite> tensor that can be used as initial conditions
for <cite>optimize_acqf()</cite>. Here <cite>q’ = q + num_fantasies</cite> is the total number
of points (candidate points plus fantasy points).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Optional</em>[<em>Tensor</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qKG</span> <span class="o">=</span> <span class="n">qKnowledgeGradient</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_fantasies</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_one_shot_kg_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qKG</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">"frac_random"</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">},</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_value_function_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_value_function_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_value_function_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_value_function_initial_conditions" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a batch of smart initializations for optimizing
the value function of qKnowledgeGradient.</p>
<p>This function generates initial conditions for optimizing the inner problem of
KG, i.e. its value function, using the maximizer of the posterior objective.
Intutively, the maximizer of the fantasized posterior will often be close to a
maximizer of the current posterior. This function uses that fact to generate the
initital conditions for the fantasy points. Specifically, a fraction of <cite>1 -
frac_random</cite> (see options) of raw samples is generated by sampling from the set of
maximizers of the posterior objective (obtained via random restart optimization)
according to a softmax transformation of their respective values. This means that
this initialization strategy internally solves an acquisition function
maximization problem. The remaining raw samples are generated using
<cite>draw_sobol_samples</cite>. All raw samples are then evaluated, and the initial
conditions are selected according to the standard initialization strategy in
‘initialize_q_batch’ individually for each inner problem.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – The value function instance to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of
task features.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>current_model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model of the KG acquisition function that was used to
generate the fantasy model of the value function.</p></li>
<li><p><strong>fixed_features</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Union</em><em>[</em><em>bool</em><em>, </em><em>float</em><em>, </em><em>int</em><em>]</em><em>]</em><em>]</em>) – Options for initial condition generation. These contain all
settings for the standard heuristic initialization from
<cite>gen_batch_initial_conditions</cite>. In addition, they contain
<cite>frac_random</cite> (the fraction of fully random fantasy points),
<cite>num_inner_restarts</cite> and <cite>raw_inner_samples</cite> (the number of random
restarts and raw samples for solving the posterior objective
maximization problem, respectively) and <cite>eta</cite> (temperature parameter
for sampling heuristic from posterior objective maximizers).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x batch_shape x q x d</cite> tensor that can be used as initial
conditions for <cite>optimize_acqf()</cite>. Here <cite>batch_shape</cite> is the batch shape
of value function model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fant_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fantasy_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fantasize</span><span class="p">(</span><span class="n">fant_X</span><span class="p">,</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_function</span> <span class="o">=</span> <span class="n">PosteriorMean</span><span class="p">(</span><span class="n">fantasy_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_value_function_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">value_function</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">"frac_random"</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">},</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.initialize_q_batch">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">initialize_q_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#initialize_q_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.initialize_q_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Heuristic for selecting initial conditions for candidate generation.</p>
<p>This heuristic selects points from <cite>X</cite> (without replacement) with probability
proportional to <cite>exp(eta * Z)</cite>, where <cite>Z = (Y - mean(Y)) / std(Y)</cite> and <cite>eta</cite>
is a temperature parameter.</p>
<p>When using an acquisiton function that is non-negative and possibly zero
over large areas of the feature space (e.g. qEI), you should use
<cite>initialize_q_batch_nonneg</cite> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x batch_shape x q x d</cite> tensor of <cite>b</cite> - <cite>batch_shape</cite> samples of
<cite>q</cite>-batches from a d`-dim feature space. Typically, these are generated
using qMC sampling.</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A tensor of <cite>b x batch_shape</cite> outcomes associated with the samples.
Typically, this is the value of the batch acquisition function to be
maximized.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The number of initial condition to be generated. Must be less than <cite>b</cite>.</p></li>
<li><p><strong>eta</strong> (<em>float</em>) – Temperature parameter for weighting samples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n x batch_shape x q x d</cite> tensor of <cite>n</cite> - <cite>batch_shape</cite> <cite>q</cite>-batch initial
conditions, where each batch of <cite>n x q x d</cite> samples is selected independently.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To get `n=10` starting points of q-batch size `q=3`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for model with `d=6`:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qUCB</span> <span class="o">=</span> <span class="n">qUpperConfidenceBound</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xrnd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">initialize_q_batch</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">,</span> <span class="n">qUCB</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.initialize_q_batch_nonneg">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">initialize_q_batch_nonneg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#initialize_q_batch_nonneg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.initialize_q_batch_nonneg" title="Permalink to this definition">¶</a></dt>
<dd><p>Heuristic for selecting initial conditions for non-neg. acquisition functions.</p>
<p>This function is similar to <cite>initialize_q_batch</cite>, but designed specifically
for acquisition functions that are non-negative and possibly zero over
large areas of the feature space (e.g. qEI). All samples for which
<cite>Y &lt; alpha * max(Y)</cite> will be ignored (assuming that <cite>Y</cite> contains at least
one positive value).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x q x d</cite> tensor of <cite>b</cite> samples of <cite>q</cite>-batches from a <cite>d</cite>-dim.
feature space. Typically, these are generated using qMC.</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A tensor of <cite>b</cite> outcomes associated with the samples. Typically, this
is the value of the batch acquisition function to be maximized.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The number of initial condition to be generated. Must be less than <cite>b</cite>.</p></li>
<li><p><strong>eta</strong> (<em>float</em>) – Temperature parameter for weighting samples.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – The threshold (as a fraction of the maximum observed value) under
which to ignore samples. All input samples for which
<cite>Y &lt; alpha * max(Y)</cite> will be ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n x q x d</cite> tensor of <cite>n</cite> <cite>q</cite>-batch initial conditions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To get `n=10` starting points of q-batch size `q=3`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for model with `d=6`:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xrnd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">initialize_q_batch</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">,</span> <span class="n">qEI</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.sample_points_around_best">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">sample_points_around_best</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_discrete_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_pct</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subset_sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob_perturb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#sample_points_around_best"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.sample_points_around_best" title="Permalink to this definition">¶</a></dt>
<dd><p>Find best points and sample nearby points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – The acquisition function.</p></li>
<li><p><strong>n_discrete_points</strong> (<em>int</em>) – The number of points to sample.</p></li>
<li><p><strong>sigma</strong> (<em>float</em>) – The standard deviation of the additive gaussian noise for
perturbing the best points.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite>-dim tensor containing the bounds.</p></li>
<li><p><strong>best_pct</strong> (<em>float</em>) – The percentage of best points to perturb.</p></li>
<li><p><strong>subset_sigma</strong> (<em>float</em>) – The standard deviation of the additive gaussian
noise for perturbing a subset of dimensions of the best points.</p></li>
<li><p><strong>prob_perturb</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – The probability of perturbing each dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>An optional <cite>n_discrete_points x d</cite>-dim tensor containing the</dt><dd><p>sampled points. This is None if no baseline points are found.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Optional</em>[<em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.sample_truncated_normal_perturbations">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">sample_truncated_normal_perturbations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_discrete_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qmc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#sample_truncated_normal_perturbations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.sample_truncated_normal_perturbations" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample points around <cite>X</cite>.</p>
<p>Sample perturbed points around <cite>X</cite> such that the added perturbations
are sampled from N(0, sigma^2 I) and truncated to be within [0,1]^d.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>n x d</cite>-dim tensor starting points.</p></li>
<li><p><strong>n_discrete_points</strong> (<em>int</em>) – The number of points to sample.</p></li>
<li><p><strong>sigma</strong> (<em>float</em>) – The standard deviation of the additive gaussian noise for
perturbing the points.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite>-dim tensor containing the bounds.</p></li>
<li><p><strong>qmc</strong> (<em>bool</em>) – A boolean indicating whether to use qmc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n_discrete_points x d</cite>-dim tensor containing the sampled points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.sample_perturbed_subset_dims">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">sample_perturbed_subset_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_discrete_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qmc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob_perturb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#sample_perturbed_subset_dims"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.sample_perturbed_subset_dims" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample around <cite>X</cite> by perturbing a subset of the dimensions.</p>
<p>By default, dimensions are perturbed with probability equal to
<cite>min(20 / d, 1)</cite>. As shown in <a class="reference internal" href="#regis" id="id1"><span>[Regis]</span></a>, perturbing a small number
of dimensions can be beneificial. The perturbations are sampled
from N(0, sigma^2 I) and truncated to be within [0,1]^d.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>n x d</cite>-dim tensor starting points. <cite>X</cite>
must be normalized to be within <cite>[0, 1]^d</cite>.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – The bounds to sample perturbed values from</p></li>
<li><p><strong>n_discrete_points</strong> (<em>int</em>) – The number of points to sample.</p></li>
<li><p><strong>sigma</strong> (<em>float</em>) – The standard deviation of the additive gaussian noise for
perturbing the points.</p></li>
<li><p><strong>qmc</strong> (<em>bool</em>) – A boolean indicating whether to use qmc.</p></li>
<li><p><strong>prob_perturb</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – The probability of perturbing each dimension. If omitted,
defaults to <cite>min(20 / d, 1)</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n_discrete_points x d</cite>-dim tensor containing the sampled points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.stopping">
<span id="stopping-criteria"></span><h3>Stopping Criteria<a class="headerlink" href="#module-botorch.optim.stopping" title="Permalink to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.stopping.ExpMAStoppingCriterion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.stopping.</span></span><span class="sig-name descname"><span class="pre">ExpMAStoppingCriterion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_window</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/stopping.html#ExpMAStoppingCriterion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.stopping.ExpMAStoppingCriterion" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">StoppingCriterion</span></code></p>
<p>Exponential moving average stopping criterion.</p>
<p>Computes an exponentially weighted moving average over window length <cite>n_window</cite>
and checks whether the relative decrease in this moving average between steps
is less than a provided tolerance level. That is, in iteration <cite>i</cite>, it computes</p>
<blockquote>
<div><p>v[i,j] := fvals[i - n_window + j] * w[j]</p>
</div></blockquote>
<p>for all <cite>j = 0, …, n_window</cite>, where <cite>w[j] = exp(-eta * (1 - j / n_window))</cite>.
Letting <cite>ma[i] := sum_j(v[i,j])</cite>, the criterion evaluates to <cite>True</cite> whenever</p>
<blockquote>
<div><p>(ma[i-1] - ma[i]) / abs(ma[i-1]) &lt; rel_tol (if minimize=True)
(ma[i] - ma[i-1]) / abs(ma[i-1]) &lt; rel_tol (if minimize=False)</p>
</div></blockquote>
<p>Exponential moving average stopping criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>maxiter</strong> (<em>int</em>) – Maximum number of iterations.</p></li>
<li><p><strong>minimize</strong> (<em>bool</em>) – If True, assume minimization.</p></li>
<li><p><strong>n_window</strong> (<em>int</em>) – The size of the exponential moving average window.</p></li>
<li><p><strong>eta</strong> (<em>float</em>) – The exponential decay factor in the weights.</p></li>
<li><p><strong>rel_tol</strong> (<em>float</em>) – Relative tolerance for termination.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.stopping.ExpMAStoppingCriterion.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fvals</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/stopping.html#ExpMAStoppingCriterion.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.stopping.ExpMAStoppingCriterion.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the stopping criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>fvals</strong> (<em>Tensor</em>) – tensor containing function values for the current iteration. If
<cite>fvals</cite> contains more than one element, then the stopping criterion is
evaluated element-wise and True is returned if the stopping criterion is
true for all elements.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
<p>TODO: add support for utilizing gradient information</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Stopping indicator (if True, stop the optimziation).</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>fvals</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>
</section>
<section id="closures">
<h2>Closures<a class="headerlink" href="#closures" title="Permalink to this heading">¶</a></h2>
<section id="id2">
<h3>Core<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h3>
<span class="target" id="module-botorch.optim.closures.core"></span><p>Core methods for building closures in torch and interfacing with numpy.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.closures.core.ForwardBackwardClosure">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.core.</span></span><span class="sig-name descname"><span class="pre">ForwardBackwardClosure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backward=&lt;function</span> <span class="pre">Tensor.backward&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reducer=&lt;built-in</span> <span class="pre">method</span> <span class="pre">sum</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_manager=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/core.html#ForwardBackwardClosure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.core.ForwardBackwardClosure" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Wrapper for fused forward and backward closures.</p>
<p>Initializes a ForwardBackwardClosure instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> – Callable that returns a tensor.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors whose <cite>grad</cite> fields are to be returned.</p></li>
<li><p><strong>backward</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>None</em><em>]</em>) – Callable that takes the (reduced) output of <cite>forward</cite> and sets the
<cite>grad</cite> attributes of tensors in <cite>parameters</cite>.</p></li>
<li><p><strong>reducer</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – Optional callable used to reduce the output of the forward pass.</p></li>
<li><p><strong>callback</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Optional</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em>) – Optional callable that takes the reduced output of <cite>forward</cite> and
the gradients of <cite>parameters</cite> as positional arguments.</p></li>
<li><p><strong>context_manager</strong> (<em>Callable</em>) – A ContextManager used to wrap each forward-backward call.
When passed as <cite>None</cite>, <cite>context_manager</cite> defaults to a <cite>zero_grad_ctx</cite>
that zeroes the gradients of <cite>parameters</cite> upon entry.</p></li>
<li><p><strong>forward</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.closures.core.NdarrayOptimizationClosure">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.core.</span></span><span class="sig-name descname"><span class="pre">NdarrayOptimizationClosure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_array=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_tensor=&lt;built-in</span> <span class="pre">method</span> <span class="pre">as_tensor</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_state=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">set_state=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill_value=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent=True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/core.html#NdarrayOptimizationClosure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.core.NdarrayOptimizationClosure" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Adds stateful behavior and a numpy.ndarray-typed API to a closure with an
expected return type Tuple[Tensor, Union[Tensor, Sequence[Optional[Tensor]]]].</p>
<p>Initializes a NdarrayOptimizationClosure instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Optional</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A ForwardBackwardClosure instance.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors representing the closure’s state.
Expected to correspond with the first <cite>len(parameters)</cite> optional
gradient tensors returned by <cite>closure</cite>.</p></li>
<li><p><strong>as_array</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>ndarray</em><em>]</em>) – Callable used to convert tensors to ndarrays.</p></li>
<li><p><strong>as_tensor</strong> (<em>Callable</em><em>[</em><em>[</em><em>ndarray</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – Callable used to convert ndarrays to tensors.</p></li>
<li><p><strong>get_state</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>ndarray</em><em>]</em>) – Callable that returns the closure’s state as an ndarray. When
passed as <cite>None</cite>, defaults to calling <cite>get_tensors_as_ndarray_1d</cite>
on <cite>closure.parameters</cite> while passing <cite>as_array</cite> (if given by the user).</p></li>
<li><p><strong>set_state</strong> (<em>Callable</em><em>[</em><em>[</em><em>ndarray</em><em>]</em><em>, </em><em>None</em><em>]</em>) – Callable that takes a 1-dimensional ndarray and sets the
closure’s state. When passed as <cite>None</cite>, <cite>set_state</cite> defaults to
calling <cite>set_tensors_from_ndarray_1d</cite> with <cite>closure.parameters</cite> and
a given ndarray while passing <cite>as_tensor</cite>.</p></li>
<li><p><strong>fill_value</strong> (<em>float</em>) – Fill value for parameters whose gradients are None. In most
cases, <cite>fill_value</cite> should either be zero or NaN.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>) – Boolean specifying whether an ndarray should be retained
as a persistent buffer for gradients.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.closures.core.NdarrayOptimizationClosure.state">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">state</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></em><a class="headerlink" href="#botorch.optim.closures.core.NdarrayOptimizationClosure.state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
<section id="module-botorch.optim.closures.model_closures">
<span id="model-fitting-closures"></span><h3>Model Fitting Closures<a class="headerlink" href="#module-botorch.optim.closures.model_closures" title="Permalink to this heading">¶</a></h3>
<p>Utilities for building model-based closures.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.closures.model_closures.get_loss_closure">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.model_closures.</span></span><span class="sig-name descname"><span class="pre">get_loss_closure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/model_closures.html#get_loss_closure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.model_closures.get_loss_closure" title="Permalink to this definition">¶</a></dt>
<dd><p>Public API for GetLossClosure dispatcher.</p>
<p>This method, and the dispatcher that powers it, acts as a clearing house
for factory functions that define how <cite>mll</cite> is evaluated.</p>
<p>Users may specify custom evaluation routines by registering a factory function
with GetLossClosure. These factories should be registered using the type signature</p>
<blockquote>
<div><p><cite>Type[MarginalLogLikeLihood], Type[Likelihood], Type[Model], Type[DataLoader]</cite>.</p>
</div></blockquote>
<p>The final argument, Type[DataLoader], is optional. Evaluation routines that obtain
training data from, e.g., <cite>mll.model</cite> should register this argument as <cite>type(None)</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – A MarginalLogLikelihood instance whose negative defines the loss.</p></li>
<li><p><strong>data_loader</strong> (<em>Optional</em><em>[</em><em>DataLoader</em><em>]</em>) – An optional DataLoader instance for cases where training
data is passed in rather than obtained from <cite>mll.model</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A closure that takes zero positional arguments and returns the negated
value of <cite>mll</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[], <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.closures.model_closures.get_loss_closure_with_grads">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.model_closures.</span></span><span class="sig-name descname"><span class="pre">get_loss_closure_with_grads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backward=&lt;function</span> <span class="pre">Tensor.backward&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reducer=&lt;method</span> <span class="pre">'sum'</span> <span class="pre">of</span> <span class="pre">'torch._C._TensorBase'</span> <span class="pre">objects&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_manager=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/model_closures.html#get_loss_closure_with_grads"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.model_closures.get_loss_closure_with_grads" title="Permalink to this definition">¶</a></dt>
<dd><p>Public API for GetLossClosureWithGrads dispatcher.</p>
<p>In most cases, this method simply adds a backward pass to a loss closure obtained by
calling <cite>get_loss_closure</cite>. For further details, see <cite>get_loss_closure</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – A MarginalLogLikelihood instance whose negative defines the loss.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors whose <cite>grad</cite> fields are to be returned.</p></li>
<li><p><strong>reducer</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – Optional callable used to reduce the output of the forward pass.</p></li>
<li><p><strong>data_loader</strong> (<em>Optional</em><em>[</em><em>DataLoader</em><em>]</em>) – An optional DataLoader instance for cases where training
data is passed in rather than obtained from <cite>mll.model</cite>.</p></li>
<li><p><strong>context_manager</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>]</em>) – An optional ContextManager used to wrap each forward-backward
pass. Defaults to a <cite>zero_grad_ctx</cite> that zeroes the gradients of
<cite>parameters</cite> upon entry. None may be passed as an alias for <cite>nullcontext</cite>.</p></li>
<li><p><strong>backward</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>None</em><em>]</em>) – </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A closure that takes zero positional arguments and returns the reduced and
negated value of <cite>mll</cite> along with the gradients of <cite>parameters</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[], <em>Tuple</em>[<em>Tensor</em>, <em>Tuple</em>[<em>Tensor</em>, …]]]</p>
</dd>
</dl>
</dd></dl>
</section>
</section>
<section id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Permalink to this heading">¶</a></h2>
<section id="module-botorch.optim.utils.common">
<span id="general-optimization-utilities"></span><h3>General Optimization Utilities<a class="headerlink" href="#module-botorch.optim.utils.common" title="Permalink to this heading">¶</a></h3>
<p>General-purpose optimization utilities.</p>
</section>
<section id="module-botorch.optim.utils.acquisition_utils">
<span id="acquisition-optimization-utilities"></span><h3>Acquisition Optimization Utilities<a class="headerlink" href="#module-botorch.optim.utils.acquisition_utils" title="Permalink to this heading">¶</a></h3>
<p>Utilities for maximizing acquisition functions.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.acquisition_utils.columnwise_clamp">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.acquisition_utils.</span></span><span class="sig-name descname"><span class="pre">columnwise_clamp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_on_violation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/acquisition_utils.html#columnwise_clamp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.acquisition_utils.columnwise_clamp" title="Permalink to this definition">¶</a></dt>
<dd><p>Clamp values of a Tensor in column-wise fashion (with support for t-batches).</p>
<p>This function is useful in conjunction with optimizers from the torch.optim
package, which don’t natively handle constraints. If you apply this after
a gradient step you can be fancy and call it “projected gradient descent”.
This funtion is also useful for post-processing candidates generated by the
scipy optimizer that satisfy bounds only up to numerical accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – The <cite>b x n x d</cite> input tensor. If 2-dimensional, <cite>b</cite> is assumed to be 1.</p></li>
<li><p><strong>lower</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – The column-wise lower bounds. If scalar, apply bound to all columns.</p></li>
<li><p><strong>upper</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – The column-wise upper bounds. If scalar, apply bound to all columns.</p></li>
<li><p><strong>raise_on_violation</strong> (<em>bool</em>) – If <cite>True</cite>, raise an exception when the elments in <cite>X</cite>
are out of the specified bounds (up to numerical accuracy). This is
useful for post-processing candidates generated by optimizers that
satisfy imposed bounds only up to numerical accuracy.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The clamped tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.acquisition_utils.fix_features">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.acquisition_utils.</span></span><span class="sig-name descname"><span class="pre">fix_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/acquisition_utils.html#fix_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.acquisition_utils.fix_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Fix feature values in a Tensor.</p>
<p>The fixed features will have zero gradient in downstream calculations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – input Tensor with shape <cite>… x p</cite>, where <cite>p</cite> is the number of features</p></li>
<li><p><strong>fixed_features</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em>) – A dictionary with keys as column indices and values
equal to what the feature should be set to in <cite>X</cite>. If the value is
None, that column is just considered fixed. Keys should be in the
range <cite>[0, p - 1]</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The tensor X with fixed features.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.acquisition_utils.get_X_baseline">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.acquisition_utils.</span></span><span class="sig-name descname"><span class="pre">get_X_baseline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/acquisition_utils.html#get_X_baseline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.acquisition_utils.get_X_baseline" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract X_baseline from an acquisition function.</p>
<p>This tries to find the baseline set of points. First, this checks if the
acquisition function has an <cite>X_baseline</cite> attribute. If it does not,
then this method attempts to use the model’s <cite>train_inputs</cite> as <cite>X_baseline</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – The acquisition function.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Optional</em>[<em>Tensor</em>]</p>
</dd>
</dl>
<dl class="simple">
<dt>Returns</dt><dd><dl class="simple">
<dt>An optional <cite>n x d</cite>-dim tensor of baseline points. This is None if no</dt><dd><p>baseline points are found.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.utils.model_utils">
<span id="model-fitting-utilities"></span><h3>Model Fitting Utilities<a class="headerlink" href="#module-botorch.optim.utils.model_utils" title="Permalink to this heading">¶</a></h3>
<p>Utilities for fitting and manipulating models.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">TorchAttr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#TorchAttr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
<p>Create new instance of TorchAttr(shape, dtype, device)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>Size</em>) – </p></li>
<li><p><strong>dtype</strong> (<em>dtype</em>) – </p></li>
<li><p><strong>device</strong> (<em>device</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr.shape">
<span class="sig-name descname"><span class="pre">shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr.dtype">
<span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dtype</span></em><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr.dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr.device">
<span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">device</span></em><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr.device" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_data_loader">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_data_loader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_data_loader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_data_loader" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>GPyTorchModel</em>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – </p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>DataLoader</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_parameters">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method for obtaining a module’s parameters and their respective ranges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – The target module from which parameters are to be extracted.</p></li>
<li><p><strong>requires_grad</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – Optional Boolean used to filter parameters based on whether
or not their require_grad attribute matches the user provided value.</p></li>
<li><p><strong>name_filter</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>str</em><em>]</em><em>, </em><em>bool</em><em>]</em><em>]</em>) – Optional Boolean function used to filter parameters by name.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary of parameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[str, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_parameters_and_bounds">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_parameters_and_bounds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-inf,</span> <span class="pre">inf)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_parameters_and_bounds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_parameters_and_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method for obtaining a module’s parameters and their respective ranges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – The target module from which parameters are to be extracted.</p></li>
<li><p><strong>name_filter</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>str</em><em>]</em><em>, </em><em>bool</em><em>]</em><em>]</em>) – Optional Boolean function used to filter parameters by name.</p></li>
<li><p><strong>requires_grad</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – Optional Boolean used to filter parameters based on whether
or not their require_grad attribute matches the user provided value.</p></li>
<li><p><strong>default_bounds</strong> (<em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em>) – Default lower and upper bounds for constrained parameters
with <cite>None</cite> typed bounds.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary of parameters and a dictionary of parameter bounds.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Dict</em>[str, <em>Tensor</em>], <em>Dict</em>[str, <em>Tuple</em>[<em>Optional</em>[float], <em>Optional</em>[float]]]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_name_filter">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_name_filter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patterns</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_name_filter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_name_filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a binary function that filters strings (or iterables whose first
element is a string) according to a bank of excluded patterns. Typically, used
in conjunction with generators such as <cite>module.named_parameters()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>patterns</strong> (<em>Iterator</em><em>[</em><em>Union</em><em>[</em><em>Pattern</em><em>, </em><em>str</em><em>]</em><em>]</em>) – A collection of regular expressions or strings that
define the set of names to be excluded.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A binary function indicating whether or not an item should be filtered.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Callable[[Union[str, Tuple[str, Any, …]]], bool]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.sample_all_priors">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">sample_all_priors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#sample_all_priors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.sample_all_priors" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample from hyperparameter priors (in-place).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>GPyTorchModel</em>) – A GPyTorchModel.</p></li>
<li><p><strong>max_retries</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.allclose_mll">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">allclose_mll</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_a</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform_b</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rtol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#allclose_mll"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.allclose_mll" title="Permalink to this definition">¶</a></dt>
<dd><p>Convenience method for testing whether the log likelihoods produced by different
MarginalLogLikelihood instances, when evaluated on their respective models’ training
sets, are allclose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>MarginalLogLikelihood</em>) – A MarginalLogLikelihood instance.</p></li>
<li><p><strong>b</strong> (<em>MarginalLogLikelihood</em>) – A second MarginalLogLikelihood instance.</p></li>
<li><p><strong>transform_a</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – Optional callable used to post-transform log likelihoods under <cite>a</cite>.</p></li>
<li><p><strong>transform_b</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – Optional callable used to post-transform log likelihoods under <cite>b</cite>.</p></li>
<li><p><strong>rtol</strong> (<em>float</em>) – Relative tolerance.</p></li>
<li><p><strong>atol</strong> (<em>float</em>) – Absolute tolerance.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Boolean result of the allclose test.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.utils.numpy_utils">
<span id="numpy-torch-conversion-tools"></span><h3>Numpy - Torch Conversion Tools<a class="headerlink" href="#module-botorch.optim.utils.numpy_utils" title="Permalink to this heading">¶</a></h3>
<p>Utilities for interfacing Numpy and Torch.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.as_ndarray">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">as_ndarray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#as_ndarray"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.as_ndarray" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper for going from torch.Tensor to numpy.ndarray.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>Tensor</em>) – Tensor to be converted to ndarray.</p></li>
<li><p><strong>dtype</strong> (<em>Optional</em><em>[</em><em>dtype</em><em>]</em>) – Optional numpy.dtype for the converted tensor.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em>) – Boolean indicating whether memory should be shared if possible.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An ndarray with the same data as <cite>values</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.get_tensors_as_ndarray_1d">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">get_tensors_as_ndarray_1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_array=&lt;function</span> <span class="pre">as_ndarray&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#get_tensors_as_ndarray_1d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.get_tensors_as_ndarray_1d" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors</strong> (<em>Union</em><em>[</em><em>Iterator</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>out</strong> (<em>Optional</em><em>[</em><em>ndarray</em><em>]</em>) – </p></li>
<li><p><strong>dtype</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>dtype</em><em>, </em><em>str</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>as_array</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>ndarray</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.set_tensors_from_ndarray_1d">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">set_tensors_from_ndarray_1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_tensor=&lt;built-in</span> <span class="pre">method</span> <span class="pre">as_tensor</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#set_tensors_from_ndarray_1d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.set_tensors_from_ndarray_1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the values of one more tensors based off of a vector of assignments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors</strong> (<em>Union</em><em>[</em><em>Iterator</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>array</strong> (<em>ndarray</em>) – </p></li>
<li><p><strong>as_tensor</strong> (<em>Callable</em><em>[</em><em>[</em><em>ndarray</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.get_bounds_as_ndarray">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">get_bounds_as_ndarray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#get_bounds_as_ndarray"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.get_bounds_as_ndarray" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method for extracting a module’s parameters and their respective
ranges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – The target module from which parameters are to be extracted.</p></li>
<li><p><strong>name_filter</strong> – Optional Boolean function used to filter parameters by name.</p></li>
<li><p><strong>requires_grad</strong> – Optional Boolean used to filter parameters based on whether
or not their require_grad attribute matches the user provided value.</p></li>
<li><p><strong>default_bounds</strong> – Default lower and upper bounds for constrained parameters
with <cite>None</cite> typed bounds.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
<li><p><strong>bounds</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary of parameters and a dictionary of parameter bounds.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Optional</em>[<em>ndarray</em>]</p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.numpy_converter">
<span id="numpy-torch-conversion-tools-old"></span><h3>Numpy - Torch Conversion Tools (OLD)<a class="headerlink" href="#module-botorch.optim.numpy_converter" title="Permalink to this heading">¶</a></h3>
<p>A converter that simplifies using numpy-based optimizers with generic torch
<cite>nn.Module</cite> classes. This enables using a <cite>scipy.optim.minimize</cite> optimizer
for optimizing module parameters.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.numpy_converter.module_to_array">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.numpy_converter.</span></span><span class="sig-name descname"><span class="pre">module_to_array</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/numpy_converter.html#module_to_array"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.numpy_converter.module_to_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract named parameters from a module into a numpy array.</p>
<p>Only extracts parameters with requires_grad, since it is meant for optimizing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – A module with parameters. May specify parameter constraints in
a <cite>named_parameters_and_constraints</cite> method.</p></li>
<li><p><strong>bounds</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>, </em><em>Optional</em><em>[</em><em>float</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A dictionary mapping parameter names t lower and upper bounds.
of lower and upper bounds. Bounds specified here take precedence
over bounds on the same parameters specified in the constraints
registered with the module.</p></li>
<li><p><strong>exclude</strong> (<em>Optional</em><em>[</em><em>Set</em><em>[</em><em>str</em><em>]</em><em>]</em>) – A list of parameter names that are to be excluded from extraction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>3-element tuple containing
- The parameter values as a numpy array.
- An ordered dictionary with the name and tensor attributes of each
parameter.
- A <cite>2 x n_params</cite> numpy array with lower and upper bounds if at least
one constraint is finite, and None otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Dict</em>[str, <a class="reference internal" href="#botorch.optim.utils.model_utils.TorchAttr" title="botorch.optim.utils.model_utils.TorchAttr"><em>TorchAttr</em></a>], <em>Optional</em>[<em>ndarray</em>]]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameter_array</span><span class="p">,</span> <span class="n">property_dict</span><span class="p">,</span> <span class="n">bounds_out</span> <span class="o">=</span> <span class="n">module_to_array</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.numpy_converter.set_params_with_array">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.numpy_converter.</span></span><span class="sig-name descname"><span class="pre">set_params_with_array</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">property_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/numpy_converter.html#set_params_with_array"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.numpy_converter.set_params_with_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Set module parameters with values from numpy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – Module with parameters to be set</p></li>
<li><p><strong>x</strong> (<em>ndarray</em>) – Numpy array with parameter values</p></li>
<li><p><strong>property_dict</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#botorch.optim.utils.model_utils.TorchAttr" title="botorch.optim.utils.model_utils.TorchAttr"><em>TorchAttr</em></a><em>]</em>) – Dictionary of parameter names and torch attributes as
returned by module_to_array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>module with parameters updated in-place.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameter_array</span><span class="p">,</span> <span class="n">property_dict</span><span class="p">,</span> <span class="n">bounds_out</span> <span class="o">=</span> <span class="n">module_to_array</span><span class="p">(</span><span class="n">mll</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameter_array</span> <span class="o">+=</span> <span class="mf">0.1</span>  <span class="c1"># perturb parameters (for example only)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mll</span> <span class="o">=</span> <span class="n">set_params_with_array</span><span class="p">(</span><span class="n">mll</span><span class="p">,</span> <span class="n">parameter_array</span><span class="p">,</span>  <span class="n">property_dict</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</section>
<section id="module-botorch.optim.parameter_constraints">
<span id="parameter-constraint-utilities"></span><h3>Parameter Constraint Utilities<a class="headerlink" href="#module-botorch.optim.parameter_constraints" title="Permalink to this heading">¶</a></h3>
<p>Utility functions for constrained optimization.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.make_scipy_bounds">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">make_scipy_bounds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_bounds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_bounds" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a scipy Bounds object for optimziation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – <cite>… x d</cite> tensor</p></li>
<li><p><strong>lower_bounds</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – Lower bounds on each column (last dimension) of <cite>X</cite>. If
this is a single float, then all columns have the same bound.</p></li>
<li><p><strong>upper_bounds</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – Lower bounds on each column (last dimension) of <cite>X</cite>. If
this is a single float, then all columns have the same bound.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A scipy <cite>Bounds</cite> object if either lower_bounds or upper_bounds is not
None, and None otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Optional</em>[<em>Bounds</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scipy_bounds</span> <span class="o">=</span> <span class="n">make_scipy_bounds</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.make_scipy_linear_constraints">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">make_scipy_linear_constraints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shapeX</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_linear_constraints"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_linear_constraints" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate scipy constraints from torch representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shapeX</strong> (<em>Size</em>) – The shape of the torch.Tensor to optimize over (i.e. <cite>b x q x d</cite>)</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>, where
<cite>indices</cite> is a single-dimensional index tensor (long dtype) containing
indices into the last dimension of <cite>X</cite>, <cite>coefficients</cite> is a
single-dimensional tensor of coefficients of the same length, and
rhs is a scalar.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) == rhs</cite> (with <cite>indices</cite>
and <cite>coefficients</cite> of the same form as in <cite>inequality_constraints</cite>).</p></li>
<li><p><strong>inequality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>equality_constraints</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of dictionaries containing callables for constraint function
values and Jacobians and a string indicating the associated constraint
type (“eq”, “ineq”), as expected by <cite>scipy.minimize</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>Dict</em>[str, <em>Union</em>[str, <em>Callable</em>[[<em>ndarray</em>], float], <em>Callable</em>[[<em>ndarray</em>], <em>ndarray</em>]]]]</p>
</dd>
</dl>
<p>This function assumes that constraints are the same for each input batch,
and broadcasts the constraints accordingly to the input batch shape. This
function does support constraints across elements of a q-batch if the
indices are a 2-d Tensor.</p>
<p class="rubric">Example</p>
<p>The following will enforce that <cite>x[1] + 0.5 x[3] &gt;= -0.1</cite> for each <cite>x</cite>
in both elements of the q-batch, and each of the 3 t-batches:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">constraints</span> <span class="o">=</span> <span class="n">make_scipy_linear_constraints</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
<p>The following will enforce that <cite>x[0, 1] + 0.5 x[1, 3] &gt;= -0.1</cite> where
x[0, :] is the first element of the q-batch and x[1, :] is the second
element of the q-batch, for each of the 3 t-batches:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">constraints</span> <span class="o">=</span> <span class="n">make_scipy_linear_constraints</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.eval_lin_constraint">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">eval_lin_constraint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flat_idxr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeffs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#eval_lin_constraint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.eval_lin_constraint" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate a single linear constraint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The input array.</p></li>
<li><p><strong>flat_idxr</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The indices in <cite>x</cite> to consider.</p></li>
<li><p><strong>coeffs</strong> (<em>ndarray</em>) – The coefficients corresponding to the indices.</p></li>
<li><p><strong>rhs</strong> (<em>float</em>) – The right-hand-side of the constraint.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>sum_i (coeffs[i] * x[i]) - rhs</cite></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The evaluted constraint</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.lin_constraint_jac">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">lin_constraint_jac</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flat_idxr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeffs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#lin_constraint_jac"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.lin_constraint_jac" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the Jacobian associated with a linear constraint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The input array.</p></li>
<li><p><strong>flat_idxr</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The indices for the elements of x that appear in the constraint.</p></li>
<li><p><strong>coeffs</strong> (<em>ndarray</em>) – The coefficients corresponding to the indices.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – number of elements</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Jacobian.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.make_scipy_nonlinear_inequality_constraints">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">make_scipy_nonlinear_inequality_constraints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f_np_wrapper</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_nonlinear_inequality_constraints"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_nonlinear_inequality_constraints" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate Scipy nonlinear inequality constraints from callables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>List</em><em>[</em><em>Callable</em><em>]</em>) – List of callables for the nonlinear
inequality constraints. Each callable represents a constraint of the
form &gt;= 0 and takes a torch tensor of size (p x q x dim) and returns a
torch tensor of size (p x q).</p></li>
<li><p><strong>f_np_wrapper</strong> (<em>Callable</em>) – A wrapper function that given a constraint evaluates the value
and gradient (using autograd) of a numpy input and returns both the
objective and the gradient.</p></li>
<li><p><strong>x0</strong> (<em>Tensor</em>) – The starting point for SLSQP. We return this starting point in (rare)
cases where SLSQP fails and thus require it to be feasible.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of dictionaries containing callables for constraint function
values and Jacobians and a string indicating the associated constraint
type (“eq”, “ineq”), as expected by <cite>scipy.minimize</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>
</section>
</section>
</section>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">BoTorch</a></h1>
<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">botorch.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="index.html">Documentation overview</a><ul>
<li>Previous: <a href="posteriors.html" title="previous chapter">botorch.posteriors</a></li>
<li>Next: <a href="fit.html" title="next chapter">botorch.fit</a></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="search.html" class="search" method="get">
<input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q" spellcheck="false" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/v/0.8.0/" class="nav-home"><img src="/v/0.8.0/img/botorch.png" alt="BoTorch" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/v/0.8.0/docs/introduction">Introduction</a><a href="/v/0.8.0/docs/getting_started">Getting Started</a><a href="/v/0.8.0/tutorials/">Tutorials</a><a href="/v/0.8.0/api/">API Reference</a><a href="https://arxiv.org/abs/1910.06403">Paper</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/botorch" data-count-href="https://github.com/pytorch/botorch/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star BoTorch on GitHub">botorch</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/v/0.8.0/img/oss_logo.png" alt="Meta Open Source" width="300" height="25"/></a><section class="copyright"> Copyright © 2022 Meta Platforms, Inc</section><script>
            (function() {
              var BAD_BASE = '/botorch/';
              if (window.location.origin !== 'https://botorch.org') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://botorch.org/v/0.8.0/' + newPathname;
                
              }
            })();
          </script></footer></div></body></html>