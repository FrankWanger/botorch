<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>BoTorch · Bayesian Optimization in PyTorch</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Bayesian Optimization in PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="BoTorch · Bayesian Optimization in PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://botorch.org/v/0.9.2/"/><meta property="og:description" content="Bayesian Optimization in PyTorch"/><meta property="og:image" content="https://botorch.org/v/0.9.2/img/botorch.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://botorch.org/v/0.9.2/img/botorch.png"/><link rel="shortcut icon" href="/v/0.9.2/img/botorch.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-CXN3PGE3CC"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'G-CXN3PGE3CC');
            </script><link rel="stylesheet" href="/v/0.9.2/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/v/0.9.2/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/v/0.9.2/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/v/0.9.2/js/scrollSpy.js"></script><link rel="stylesheet" href="/v/0.9.2/css/main.css"/><script src="/v/0.9.2/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/v/0.9.2/"><img class="logo" src="/v/0.9.2/img/botorch_logo_lockup_white.png" alt="BoTorch"/><h2 class="headerTitleWithLogo">BoTorch</h2></a><a href="/v/0.9.2/versions"><h3>0.9.2</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/v/0.9.2/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/v/0.9.2/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/v/0.9.2/api/" target="_self">API Reference</a></li><li class=""><a href="/v/0.9.2/docs/papers" target="_self">Papers</a></li><li class=""><a href="https://github.com/pytorch/botorch" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./" src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<h1>Source code for botorch.models.model</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the MIT license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="sa">r</span><span class="sd">"""Abstract base module for all BoTorch models.</span>

<span class="sd">This module contains `Model`, the abstract base class for all BoTorch models,</span>
<span class="sd">and `ModelList`, a container for a list of Models.</span>
<span class="sd">"""</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Hashable</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Mapping</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">TypeVar</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">botorch</span> <span class="kn">import</span> <span class="n">settings</span>
<span class="kn">from</span> <span class="nn">botorch.exceptions.errors</span> <span class="kn">import</span> <span class="n">BotorchTensorDimensionError</span><span class="p">,</span> <span class="n">InputDataError</span>
<span class="kn">from</span> <span class="nn">botorch.logging</span> <span class="kn">import</span> <span class="n">shape_to_str</span>
<span class="kn">from</span> <span class="nn">botorch.models.utils.assorted</span> <span class="kn">import</span> <span class="n">fantasize</span> <span class="k">as</span> <span class="n">fantasize_flag</span>
<span class="kn">from</span> <span class="nn">botorch.posteriors</span> <span class="kn">import</span> <span class="n">Posterior</span><span class="p">,</span> <span class="n">PosteriorList</span>
<span class="kn">from</span> <span class="nn">botorch.sampling.base</span> <span class="kn">import</span> <span class="n">MCSampler</span>
<span class="kn">from</span> <span class="nn">botorch.sampling.list_sampler</span> <span class="kn">import</span> <span class="n">ListSampler</span>
<span class="kn">from</span> <span class="nn">botorch.utils.datasets</span> <span class="kn">import</span> <span class="n">SupervisedDataset</span>
<span class="kn">from</span> <span class="nn">botorch.utils.transforms</span> <span class="kn">import</span> <span class="n">is_fully_bayesian</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Module</span><span class="p">,</span> <span class="n">ModuleDict</span><span class="p">,</span> <span class="n">ModuleList</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">botorch.acquisition.objective</span> <span class="kn">import</span> <span class="n">PosteriorTransform</span>  <span class="c1"># pragma: no cover</span>

<span class="n">TFantasizeMixin</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">"TFantasizeMixin"</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="s2">"FantasizeMixin"</span><span class="p">)</span>


<div class="viewcode-block" id="Model"><a class="viewcode-back" href="../../../models.html#botorch.models.model.Model">[docs]</a><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">Module</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""Abstract base class for BoTorch models.</span>

<span class="sd">    The `Model` base class cannot be used directly; it only defines an API for other</span>
<span class="sd">    BoTorch models.</span>

<span class="sd">    `Model` subclasses `torch.nn.Module`. While a `Module` is most typically</span>
<span class="sd">    encountered as a representation of a neural network layer, it can be used more</span>
<span class="sd">    generally: see</span>
<span class="sd">    `documentation &lt;https://pytorch.org/tutorials/beginner/examples_nn/polynomial_module.html&gt;`_</span>
<span class="sd">    on custom NN Modules.</span>

<span class="sd">    `Module` provides several pieces of useful functionality: A `Model`'s attributes of</span>
<span class="sd">    `Tensor` or `Module` type are automatically registered so they can be moved and/or</span>
<span class="sd">    cast with the `to` method, automatically differentiated, and used with CUDA.</span>

<span class="sd">    Args:</span>
<span class="sd">        _has_transformed_inputs: A boolean denoting whether `train_inputs` are currently</span>
<span class="sd">            stored as transformed or not.</span>
<span class="sd">        _original_train_inputs: A Tensor storing the original train inputs for use in</span>
<span class="sd">            `_revert_to_original_inputs`. Note that this is necessary since</span>
<span class="sd">            transform / untransform cycle introduces numerical errors which lead</span>
<span class="sd">            to upstream errors during training.</span>
<span class="sd">    """</span>  <span class="c1"># noqa: E501</span>

    <span class="n">_has_transformed_inputs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">_original_train_inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="Model.posterior"><a class="viewcode-back" href="../../../models.html#botorch.models.model.Model.posterior">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">output_indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PosteriorTransform</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Posterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Computes the posterior over model outputs at the provided points.</span>

<span class="sd">        Note: The input transforms should be applied here using</span>
<span class="sd">            `self.transform_inputs(X)` after the `self.eval()` call and before</span>
<span class="sd">            any `model.forward` or `model.likelihood` calls.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `b x q x d`-dim Tensor, where `d` is the dimension of the</span>
<span class="sd">                feature space, `q` is the number of points considered jointly,</span>
<span class="sd">                and `b` is the batch dimension.</span>
<span class="sd">            output_indices: A list of indices, corresponding to the outputs over</span>
<span class="sd">                which to compute the posterior (if the model is multi-output).</span>
<span class="sd">                Can be used to speed up computation if only a subset of the</span>
<span class="sd">                model's outputs are required for optimization. If omitted,</span>
<span class="sd">                computes the posterior over all model outputs.</span>
<span class="sd">            observation_noise: If True, add observation noise to the posterior.</span>
<span class="sd">            posterior_transform: An optional PosteriorTransform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Posterior` object, representing a batch of `b` joint distributions</span>
<span class="sd">            over `q` points and `m` outputs each.</span>
<span class="sd">        """</span>
        <span class="k">pass</span>  <span class="c1"># pragma: no cover</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""The batch shape of the model.</span>

<span class="sd">        This is a batch shape from an I/O perspective, independent of the internal</span>
<span class="sd">        representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).</span>
<span class="sd">        For a model with `m` outputs, a `test_batch_shape x q x d`-shaped input `X`</span>
<span class="sd">        to the `posterior` method returns a Posterior object over an output of</span>
<span class="sd">        shape `broadcast(test_batch_shape, model.batch_shape) x q x m`.</span>
<span class="sd">        """</span>
        <span class="n">cls_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">cls_name</span><span class="si">}</span><span class="s2"> does not define batch_shape property"</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""The number of outputs of the model."""</span>
        <span class="n">cls_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">cls_name</span><span class="si">}</span><span class="s2"> does not define num_outputs property"</span><span class="p">)</span>

<div class="viewcode-block" id="Model.subset_output"><a class="viewcode-back" href="../../../models.html#botorch.models.model.Model.subset_output">[docs]</a>    <span class="k">def</span> <span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Subset the model along the output dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: The output indices to subset the model to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Model` object of the same type and with the same parameters as</span>
<span class="sd">            the current model, subset to the specified output indices.</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="Model.condition_on_observations"><a class="viewcode-back" href="../../../models.html#botorch.models.model.Model.condition_on_observations">[docs]</a>    <span class="k">def</span> <span class="nf">condition_on_observations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Condition the model on new observations.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x n' x d`-dim Tensor, where `d` is the dimension of</span>
<span class="sd">                the feature space, `n'` is the number of points per batch, and</span>
<span class="sd">                `batch_shape` is the batch shape (must be compatible with the</span>
<span class="sd">                batch shape of the model).</span>
<span class="sd">            Y: A `batch_shape' x n' x m`-dim Tensor, where `m` is the number of</span>
<span class="sd">                model outputs, `n'` is the number of points per batch, and</span>
<span class="sd">                `batch_shape'` is the batch shape of the observations.</span>
<span class="sd">                `batch_shape'` must be broadcastable to `batch_shape` using</span>
<span class="sd">                standard broadcasting semantics. If `Y` has fewer batch dimensions</span>
<span class="sd">                than `X`, it is assumed that the missing batch dimensions are</span>
<span class="sd">                the same for all `Y`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Model` object of the same type, representing the original model</span>
<span class="sd">            conditioned on the new observations `(X, Y)` (and possibly noise</span>
<span class="sd">            observations passed in via kwargs).</span>
<span class="sd">        """</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"`condition_on_observations` not implemented for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">"</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="Model.construct_inputs"><a class="viewcode-back" href="../../../models.html#botorch.models.model.Model.construct_inputs">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">construct_inputs</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">training_data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">SupervisedDataset</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Hashable</span><span class="p">,</span> <span class="n">SupervisedDataset</span><span class="p">]],</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Construct `Model` keyword arguments from a dict of `SupervisedDataset`."""</span>
        <span class="kn">from</span> <span class="nn">botorch.models.utils.parse_training_data</span> <span class="kn">import</span> <span class="n">parse_training_data</span>

        <span class="k">return</span> <span class="n">parse_training_data</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Model.transform_inputs"><a class="viewcode-back" href="../../../models.html#botorch.models.model.Model.transform_inputs">[docs]</a>    <span class="k">def</span> <span class="nf">transform_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">input_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Transform inputs.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A tensor of inputs</span>
<span class="sd">            input_transform: A Module that performs the input transformation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A tensor of transformed inputs</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">input_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_transform</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">input_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">X</span></div>

    <span class="k">def</span> <span class="nf">_set_transformed_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Update training inputs with transformed inputs."""</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"input_transform"</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_transformed_inputs</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"train_inputs"</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_original_train_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">X_tf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_transform</span><span class="o">.</span><span class="n">preprocess_transform</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">set_train_data</span><span class="p">(</span><span class="n">X_tf</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_has_transformed_inputs</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">"Could not update `train_inputs` with transformed inputs "</span>
                    <span class="sa">f</span><span class="s2">"since </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not have a `train_inputs` "</span>
                    <span class="s2">"attribute. Make sure that the `input_transform` is applied to "</span>
                    <span class="s2">"both the train inputs and test inputs."</span><span class="p">,</span>
                    <span class="ne">RuntimeWarning</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_revert_to_original_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Revert training inputs back to original."""</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">"input_transform"</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_transformed_inputs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_train_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_train_inputs</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_has_transformed_inputs</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="Model.eval"><a class="viewcode-back" href="../../../models.html#botorch.models.model.Model.eval">[docs]</a>    <span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Puts the model in `eval` mode and sets the transformed inputs."""</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_transformed_inputs</span><span class="p">()</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span></div>

<div class="viewcode-block" id="Model.train"><a class="viewcode-back" href="../../../models.html#botorch.models.model.Model.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Put the model in `train` mode. Reverts to the original inputs if in `train`</span>
<span class="sd">        mode (`mode=True`) or sets transformed inputs if in `eval` mode (`mode=False`).</span>

<span class="sd">        Args:</span>
<span class="sd">            mode: A boolean denoting whether to put in `train` or `eval` mode.</span>
<span class="sd">                If `False`, model is put in `eval` mode.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">mode</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_revert_to_original_inputs</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_transformed_inputs</span><span class="p">()</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="FantasizeMixin"><a class="viewcode-back" href="../../../models.html#botorch.models.model.FantasizeMixin">[docs]</a><span class="k">class</span> <span class="nc">FantasizeMixin</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Mixin to add a `fantasize` method to a `Model`.</span>

<span class="sd">    Example:</span>
<span class="sd">        class BaseModel:</span>
<span class="sd">            def __init__(self, ...):</span>
<span class="sd">            def condition_on_observations(self, ...):</span>
<span class="sd">            def posterior(self, ...):</span>
<span class="sd">            def transform_inputs(self, ...):</span>

<span class="sd">        class ModelThatCanFantasize(BaseModel, FantasizeMixin):</span>
<span class="sd">            def __init__(self, args):</span>
<span class="sd">                super().__init__(args)</span>

<span class="sd">        model = ModelThatCanFantasize(...)</span>
<span class="sd">        model.fantasize(X)</span>
<span class="sd">    """</span>

<div class="viewcode-block" id="FantasizeMixin.condition_on_observations"><a class="viewcode-back" href="../../../models.html#botorch.models.model.FantasizeMixin.condition_on_observations">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">condition_on_observations</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">:</span> <span class="n">TFantasizeMixin</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TFantasizeMixin</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Classes that inherit from `FantasizeMixin` must implement</span>
<span class="sd">        a `condition_on_observations` method.</span>
<span class="sd">        """</span></div>

<div class="viewcode-block" id="FantasizeMixin.posterior"><a class="viewcode-back" href="../../../models.html#botorch.models.model.FantasizeMixin.posterior">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Posterior</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Classes that inherit from `FantasizeMixin` must implement</span>
<span class="sd">        a `posterior` method.</span>
<span class="sd">        """</span></div>

<div class="viewcode-block" id="FantasizeMixin.transform_inputs"><a class="viewcode-back" href="../../../models.html#botorch.models.model.FantasizeMixin.transform_inputs">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">transform_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">input_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Classes that inherit from `FantasizeMixin` must implement</span>
<span class="sd">        a `transform_inputs` method.</span>
<span class="sd">        """</span></div>

    <span class="c1"># When Python 3.11 arrives we can start annotating return types like</span>
    <span class="c1"># this as</span>
    <span class="c1"># 'Self', but at this point the verbose 'T...' syntax is needed.</span>
<div class="viewcode-block" id="FantasizeMixin.fantasize"><a class="viewcode-back" href="../../../models.html#botorch.models.model.FantasizeMixin.fantasize">[docs]</a>    <span class="k">def</span> <span class="nf">fantasize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">:</span> <span class="n">TFantasizeMixin</span><span class="p">,</span>
        <span class="c1"># TODO: see if any of these can be imported only if TYPE_CHECKING</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TFantasizeMixin</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Construct a fantasy model.</span>

<span class="sd">        Constructs a fantasy model in the following fashion:</span>
<span class="sd">        (1) compute the model posterior at `X` (including observation noise if</span>
<span class="sd">        `observation_noise=True`).</span>
<span class="sd">        (2) sample from this posterior (using `sampler`) to generate "fake"</span>
<span class="sd">        observations.</span>
<span class="sd">        (3) condition the model on the new fake observations.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x n' x d`-dim Tensor, where `d` is the dimension of</span>
<span class="sd">                the feature space, `n'` is the number of points per batch, and</span>
<span class="sd">                `batch_shape` is the batch shape (must be compatible with the</span>
<span class="sd">                batch shape of the model).</span>
<span class="sd">            sampler: The sampler used for sampling from the posterior at `X`.</span>
<span class="sd">            observation_noise: If True, include observation noise.</span>
<span class="sd">            kwargs: Will be passed to `model.condition_on_observations`</span>

<span class="sd">        Returns:</span>
<span class="sd">            The constructed fantasy model.</span>
<span class="sd">        """</span>
        <span class="c1"># if the inputs are empty, expand the inputs</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">sampler</span><span class="o">.</span><span class="n">sample_shape</span>
                <span class="o">+</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
                <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span>
                <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">])</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="n">X</span><span class="p">),</span>
                <span class="n">Y</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">output_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">propagate_grads</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"propagate_grads"</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">fantasize_flag</span><span class="p">():</span>
            <span class="k">with</span> <span class="n">settings</span><span class="o">.</span><span class="n">propagate_grads</span><span class="p">(</span><span class="n">propagate_grads</span><span class="p">):</span>
                <span class="n">post_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">observation_noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">)</span>
            <span class="n">Y_fantasized</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">post_X</span><span class="p">)</span>  <span class="c1"># num_fantasies x batch_shape x n' x m</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">condition_on_observations</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform_inputs</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">Y</span><span class="o">=</span><span class="n">Y_fantasized</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span></div></div>


<div class="viewcode-block" id="ModelList"><a class="viewcode-back" href="../../../models.html#botorch.models.model.ModelList">[docs]</a><span class="k">class</span> <span class="nc">ModelList</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""A multi-output Model represented by a list of independent models.</span>

<span class="sd">    All BoTorch models are acceptable as inputs. The cost of this flexibility is</span>
<span class="sd">    that `ModelList` does not support all methods that may be implemented by its</span>
<span class="sd">    component models. One use case for `ModelList` is combining a regression</span>
<span class="sd">    model and a deterministic model in one multi-output container model, e.g.</span>
<span class="sd">    for cost-aware or multi-objective optimization where one of the outcomes is</span>
<span class="sd">    a deterministic function of the inputs.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">models</span><span class="p">:</span> <span class="n">Model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            *models: A variable number of models.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; m_1 = SingleTaskGP(train_X, train_Y)</span>
<span class="sd">            &gt;&gt;&gt; m_2 = GenericDeterministicModel(lambda x: x.sum(dim=-1))</span>
<span class="sd">            &gt;&gt;&gt; m_12 = ModelList(m_1, m_2)</span>
<span class="sd">            &gt;&gt;&gt; m_12.posterior(test_X)</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">ModuleList</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_group_subset_indices</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Convert global subset indices to indices for the individual models.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: A list of indices to which the `ModelList` model is to be</span>
<span class="sd">                subset to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary mapping model indices to subset indices of the</span>
<span class="sd">                respective model in the `ModelList`.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">idcs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">))}</span>
        <span class="n">output_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">num_outputs</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">]</span>
        <span class="n">cum_output_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">output_sizes</span><span class="p">)</span>
        <span class="n">idcs</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span> <span class="o">%</span> <span class="n">cum_output_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">idcs</span><span class="p">]</span>
        <span class="n">group_indices</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">idcs</span><span class="p">:</span>
            <span class="n">grp_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">idx</span> <span class="o">&lt;</span> <span class="n">cum_output_sizes</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">sub_idx</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">output_sizes</span><span class="p">[:</span><span class="n">grp_idx</span><span class="p">]))</span>
            <span class="n">group_indices</span><span class="p">[</span><span class="n">grp_idx</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sub_idx</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">group_indices</span>

<div class="viewcode-block" id="ModelList.posterior"><a class="viewcode-back" href="../../../models.html#botorch.models.model.ModelList.posterior">[docs]</a>    <span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">output_indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">posterior_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">PosteriorList</span><span class="p">],</span> <span class="n">Posterior</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Posterior</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Computes the posterior over model outputs at the provided points.</span>

<span class="sd">        Note: The input transforms should be applied here using</span>
<span class="sd">            `self.transform_inputs(X)` after the `self.eval()` call and before</span>
<span class="sd">            any `model.forward` or `model.likelihood` calls.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `b x q x d`-dim Tensor, where `d` is the dimension of the</span>
<span class="sd">                feature space, `q` is the number of points considered jointly,</span>
<span class="sd">                and `b` is the batch dimension.</span>
<span class="sd">            output_indices: A list of indices, corresponding to the outputs over</span>
<span class="sd">                which to compute the posterior (if the model is multi-output).</span>
<span class="sd">                Can be used to speed up computation if only a subset of the</span>
<span class="sd">                model's outputs are required for optimization. If omitted,</span>
<span class="sd">                computes the posterior over all model outputs.</span>
<span class="sd">            observation_noise: If True, add the observation noise from the</span>
<span class="sd">                respective likelihoods to the posterior. If a Tensor of shape</span>
<span class="sd">                `(batch_shape) x q x m`, use it directly as the observation</span>
<span class="sd">                noise (with `observation_noise[...,i]` added to the posterior</span>
<span class="sd">                of the `i`-th model).</span>
<span class="sd">            posterior_transform: An optional PosteriorTransform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Posterior` object, representing a batch of `b` joint distributions</span>
<span class="sd">            over `q` points and `m` outputs each.</span>
<span class="sd">        """</span>
        <span class="n">group_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_group_subset_indices</span><span class="p">(</span><span class="n">idcs</span><span class="o">=</span><span class="n">output_indices</span><span class="p">)</span>
        <span class="n">posteriors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idcs</span> <span class="ow">in</span> <span class="n">group_indices</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observation_noise</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">idcs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">start_idx</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">num_outputs</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span>
                    <span class="n">end_idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">num_outputs</span>
                    <span class="n">idcs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">))</span>
                <span class="n">obs_noise</span> <span class="o">=</span> <span class="n">observation_noise</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idcs</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">obs_noise</span> <span class="o">=</span> <span class="n">observation_noise</span>
            <span class="n">posteriors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">posterior</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">output_indices</span><span class="o">=</span><span class="n">idcs</span><span class="p">,</span> <span class="n">observation_noise</span><span class="o">=</span><span class="n">obs_noise</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">PosteriorList</span><span class="p">(</span><span class="o">*</span><span class="n">posteriors</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">posterior_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="n">posterior_transform</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""The batch shape of the model.</span>

<span class="sd">        This is a batch shape from an I/O perspective, independent of the internal</span>
<span class="sd">        representation of the model (as e.g. in BatchedMultiOutputGPyTorchModel).</span>
<span class="sd">        For a model with `m` outputs, a `test_batch_shape x q x d`-shaped input `X`</span>
<span class="sd">        to the `posterior` method returns a Posterior object over an output of</span>
<span class="sd">        shape `broadcast(test_batch_shape, model.batch_shape) x q x m`.</span>
<span class="sd">        """</span>
        <span class="n">batch_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">batch_shape</span>
        <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">==</span> <span class="n">m</span><span class="o">.</span><span class="n">batch_shape</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
            <span class="k">return</span> <span class="n">batch_shape</span>
        <span class="c1"># TODO: Allow broadcasting of model batch shapes</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">"`</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.batch_shape` is only supported if all "</span>
            <span class="s2">"constituent models have the same `batch_shape`."</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""The number of outputs of the model.</span>

<span class="sd">        Equal to the sum of the number of outputs of the individual models</span>
<span class="sd">        in the ModelList.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">num_outputs</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">)</span>

<div class="viewcode-block" id="ModelList.subset_output"><a class="viewcode-back" href="../../../models.html#botorch.models.model.ModelList.subset_output">[docs]</a>    <span class="k">def</span> <span class="nf">subset_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idcs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Subset the model along the output dimension.</span>

<span class="sd">        Args:</span>
<span class="sd">            idcs: The output indices to subset the model to. Relative to the</span>
<span class="sd">                overall number of outputs of the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Model` (either a `ModelList` or one of the submodels) with</span>
<span class="sd">            the outputs subset to the indices in `idcs`.</span>

<span class="sd">        Internally, this drops (if single-output) or subsets (if multi-output)</span>
<span class="sd">        the constitutent models and returns them as a `ModelList`. If the</span>
<span class="sd">        result is a single (possibly subset) model from the list, returns this</span>
<span class="sd">        model (instead of forming a degenerate singe-model `ModelList`).</span>
<span class="sd">        For instance, if `m = ModelList(m1, m2)` with `m1` a two-output model</span>
<span class="sd">        and `m2` a single-output model, then `m.subset_output([1]) ` will return</span>
<span class="sd">        the model `m1` subset to its second output.</span>
<span class="sd">        """</span>
        <span class="n">group_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_group_subset_indices</span><span class="p">(</span><span class="n">idcs</span><span class="o">=</span><span class="n">idcs</span><span class="p">)</span>
        <span class="n">subset_models</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">grp_idx</span><span class="p">]</span><span class="o">.</span><span class="n">subset_output</span><span class="p">(</span><span class="n">idcs</span><span class="o">=</span><span class="n">sub_idcs</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">grp_idx</span><span class="p">,</span> <span class="n">sub_idcs</span> <span class="ow">in</span> <span class="n">group_indices</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">subset_models</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">subset_models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">*</span><span class="n">subset_models</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModelList.transform_inputs"><a class="viewcode-back" href="../../../models.html#botorch.models.model.ModelList.transform_inputs">[docs]</a>    <span class="k">def</span> <span class="nf">transform_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Individually transform the inputs for each model.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A tensor of inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of tensors of transformed inputs.</span>
<span class="sd">        """</span>
        <span class="n">transformed_X_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">transformed_X_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">input_transform</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="n">transformed_X_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">transformed_X_list</span></div>

<div class="viewcode-block" id="ModelList.load_state_dict"><a class="viewcode-back" href="../../../models.html#botorch.models.model.ModelList.load_state_dict">[docs]</a>    <span class="k">def</span> <span class="nf">load_state_dict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Initialize the fully Bayesian models before loading the state dict."""</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">is_fully_bayesian</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
                <span class="n">filtered_dict</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">k</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">"models.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">."</span><span class="p">,</span> <span class="s2">""</span><span class="p">):</span> <span class="n">v</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="sa">f</span><span class="s2">"models.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
                <span class="p">}</span>
                <span class="n">m</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">filtered_dict</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModelList.fantasize"><a class="viewcode-back" href="../../../models.html#botorch.models.model.ModelList.fantasize">[docs]</a>    <span class="k">def</span> <span class="nf">fantasize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">MCSampler</span><span class="p">,</span>
        <span class="n">observation_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">evaluation_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Model</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Construct a fantasy model.</span>

<span class="sd">        Constructs a fantasy model in the following fashion:</span>
<span class="sd">        (1) compute the model posterior at `X` (including observation noise if</span>
<span class="sd">        `observation_noise=True`).</span>
<span class="sd">        (2) sample from this posterior (using `sampler`) to generate "fake"</span>
<span class="sd">        observations.</span>
<span class="sd">        (3) condition the model on the new fake observations.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: A `batch_shape x n' x d`-dim Tensor, where `d` is the dimension of</span>
<span class="sd">                the feature space, `n'` is the number of points per batch, and</span>
<span class="sd">                `batch_shape` is the batch shape (must be compatible with the</span>
<span class="sd">                batch shape of the model).</span>
<span class="sd">            sampler: The sampler used for sampling from the posterior at `X`. If</span>
<span class="sd">                evaluation_mask is not None, this must be a `ListSampler`.</span>
<span class="sd">            observation_noise: If True, include observation noise.</span>
<span class="sd">            evaluation_mask: A `n' x m`-dim tensor of booleans indicating which</span>
<span class="sd">                outputs should be fantasized for a given design. This uses the same</span>
<span class="sd">                evaluation mask for all batches.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The constructed fantasy model.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">evaluation_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">evaluation_mask</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">evaluation_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>
                <span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="n">BotorchTensorDimensionError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">"Expected evaluation_mask of shape `</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> "</span>
                    <span class="sa">f</span><span class="s2">"x </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="si">}</span><span class="s2">`, but got "</span>
                    <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">shape_to_str</span><span class="p">(</span><span class="n">evaluation_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2">."</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="n">ListSampler</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Decoupled fantasization requires a list of samplers."</span><span class="p">)</span>

        <span class="n">fant_models</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">X_i</span> <span class="o">=</span> <span class="n">X</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">):</span>
            <span class="c1"># get the inputs to fantasize at for output i</span>
            <span class="k">if</span> <span class="n">evaluation_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">mask_i</span> <span class="o">=</span> <span class="n">evaluation_mask</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
                <span class="n">X_i</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">mask_i</span><span class="p">,</span> <span class="p">:]</span>
                <span class="c1"># TODO (T158701749): implement a QMC DecoupledSampler that draws all</span>
                <span class="c1"># samples from a single Sobol sequence or consider requiring that the</span>
                <span class="c1"># sampling is IID to ensure good coverage.</span>
                <span class="n">sampler_i</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">samplers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sampler_i</span> <span class="o">=</span> <span class="n">sampler</span>
            <span class="n">fant_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">fantasize</span><span class="p">(</span>
                <span class="n">X</span><span class="o">=</span><span class="n">X_i</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="n">sampler_i</span><span class="p">,</span>
                <span class="n">observation_noise</span><span class="o">=</span><span class="n">observation_noise</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">fant_models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fant_model</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">*</span><span class="n">fant_models</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ModelDict"><a class="viewcode-back" href="../../../models.html#botorch.models.model.ModelDict">[docs]</a><span class="k">class</span> <span class="nc">ModelDict</span><span class="p">(</span><span class="n">ModuleDict</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">"""A lightweight container mapping model names to models."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">models</span><span class="p">:</span> <span class="n">Model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">"""Initialize a `ModelDict`.</span>

<span class="sd">        Args:</span>
<span class="sd">            models: An arbitrary number of models. Each model can be any type</span>
<span class="sd">                of BoTorch `Model`, including multi-output models and `ModelList`.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Model</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="n">InputDataError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Expected all models to be a BoTorch `Model`. Got </span><span class="si">{</span><span class="n">models</span><span class="si">}</span><span class="s2">."</span>
            <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">modules</span><span class="o">=</span><span class="n">models</span><span class="p">)</span></div>
</pre></div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">BoTorch</a></h1>
<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">botorch.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../../../index.html">Documentation overview</a><ul>
<li><a href="../../index.html">Module code</a><ul>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../../../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q" spellcheck="false" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/v/0.9.2/" class="nav-home"><img src="/v/0.9.2/img/botorch.png" alt="BoTorch" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/v/0.9.2/docs/introduction">Introduction</a><a href="/v/0.9.2/docs/getting_started">Getting Started</a><a href="/v/0.9.2/tutorials/">Tutorials</a><a href="/v/0.9.2/api/">API Reference</a><a href="https://arxiv.org/abs/1910.06403">Paper</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/botorch" data-count-href="https://github.com/pytorch/botorch/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star BoTorch on GitHub">botorch</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/v/0.9.2/img/oss_logo.png" alt="Meta Open Source" width="300" height="25"/></a><section class="copyright"> Copyright © 2023 Meta Platforms, Inc</section><script>
            (function() {
              var BAD_BASE = '/botorch/';
              if (window.location.origin !== 'https://botorch.org') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://botorch.org/v/0.9.2/' + newPathname;
                
              }
            })();
          </script></footer></div></body></html>