<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>BoTorch · Bayesian Optimization in PyTorch</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Bayesian Optimization in PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="BoTorch · Bayesian Optimization in PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://botorch.org/v/0.11.0/"/><meta property="og:description" content="Bayesian Optimization in PyTorch"/><meta property="og:image" content="https://botorch.org/v/0.11.0/img/botorch.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://botorch.org/v/0.11.0/img/botorch.png"/><link rel="shortcut icon" href="/v/0.11.0/img/botorch.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-CXN3PGE3CC"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'G-CXN3PGE3CC');
            </script><link rel="stylesheet" href="/v/0.11.0/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/v/0.11.0/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/v/0.11.0/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/v/0.11.0/js/scrollSpy.js"></script><link rel="stylesheet" href="/v/0.11.0/css/main.css"/><script src="/v/0.11.0/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/v/0.11.0/"><img class="logo" src="/v/0.11.0/img/botorch_logo_lockup_white.png" alt="BoTorch"/><h2 class="headerTitleWithLogo">BoTorch</h2></a><a href="/v/0.11.0/versions"><h3>0.11.0</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/v/0.11.0/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/v/0.11.0/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/v/0.11.0/api/" target="_self">API Reference</a></li><li class=""><a href="/v/0.11.0/docs/papers" target="_self">Papers</a></li><li class=""><a href="https://github.com/pytorch/botorch" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./" src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<section id="module-botorch.optim">
<span id="botorch-optim"></span><h1>botorch.optim<a class="headerlink" href="#module-botorch.optim" title="Link to this heading">¶</a></h1>
<section id="optimization">
<h2>Optimization<a class="headerlink" href="#optimization" title="Link to this heading">¶</a></h2>
<section id="module-botorch.optim.core">
<span id="core"></span><h3>Core<a class="headerlink" href="#module-botorch.optim.core" title="Link to this heading">¶</a></h3>
<p>Core abstractions and generic optimizers.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">OptimizationStatus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#OptimizationStatus"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.OptimizationStatus" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></p>
<p>An enumeration.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.RUNNING">
<span class="sig-name descname"><span class="pre">RUNNING</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.RUNNING" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.SUCCESS">
<span class="sig-name descname"><span class="pre">SUCCESS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">2</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.SUCCESS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.FAILURE">
<span class="sig-name descname"><span class="pre">FAILURE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">3</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.FAILURE" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationStatus.STOPPED">
<span class="sig-name descname"><span class="pre">STOPPED</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">4</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationStatus.STOPPED" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">OptimizationResult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'int'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'Union[float,</span> <span class="pre">int]'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">status</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'OptimizationStatus'</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">runtime</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'Optional[float]'</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="s"><span class="pre">'Optional[str]'</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#OptimizationResult"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.OptimizationResult" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>step</strong> (<em>int</em>)</p></li>
<li><p><strong>fval</strong> (<em>float</em><em> | </em><em>int</em>)</p></li>
<li><p><strong>status</strong> (<a class="reference internal" href="#botorch.optim.core.OptimizationStatus" title="botorch.optim.core.OptimizationStatus"><em>OptimizationStatus</em></a>)</p></li>
<li><p><strong>runtime</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>message</strong> (<em>str</em><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.step">
<span class="sig-name descname"><span class="pre">step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.step" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.fval">
<span class="sig-name descname"><span class="pre">fval</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.fval" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.status">
<span class="sig-name descname"><span class="pre">status</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#botorch.optim.core.OptimizationStatus" title="botorch.optim.core.OptimizationStatus"><span class="pre">OptimizationStatus</span></a></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.status" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.runtime">
<span class="sig-name descname"><span class="pre">runtime</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.runtime" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.core.OptimizationResult.message">
<span class="sig-name descname"><span class="pre">message</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.core.OptimizationResult.message" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.core.scipy_minimize">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">scipy_minimize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'L-BFGS-B'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#scipy_minimize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.scipy_minimize" title="Link to this definition">¶</a></dt>
<dd><p>Generic scipy.optimize.minimize-based optimization routine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>] </em><em>| </em><a class="reference internal" href="#botorch.optim.closures.core.NdarrayOptimizationClosure" title="botorch.optim.closures.core.NdarrayOptimizationClosure"><em>NdarrayOptimizationClosure</em></a>) – Callable that returns a tensor and an iterable of gradient tensors or
NdarrayOptimizationClosure instance.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>None</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A dictionary mapping parameter names to lower and upper bounds.</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>] </em><em>| </em><em>None</em>) – A callable taking <cite>parameters</cite> and an OptimizationResult as arguments.</p></li>
<li><p><strong>x0</strong> (<em>ndarray</em><em> | </em><em>None</em>) – An optional initialization vector passed to scipy.optimize.minimize.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Solver type, passed along to scipy.minimize.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of solver options, passed along to scipy.minimize.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Timeout in seconds to wait before aborting the optimization loop
if not converged (will return the best found solution thus far).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An OptimizationResult summarizing the final state of the run.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.core.torch_minimize">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.core.</span></span><span class="sig-name descname"><span class="pre">torch_minimize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_limit=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criterion=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/core.html#torch_minimize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.core.torch_minimize" title="Link to this definition">¶</a></dt>
<dd><p>Generic torch.optim-based optimization routine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>]</em>) – Callable that returns a tensor and an iterable of gradient tensors.
Responsible for setting relevant parameters’ <cite>grad</cite> attributes.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>None</em><em>]</em><em>] </em><em>| </em><em>None</em>) – An optional dictionary of bounds for elements of <cite>parameters</cite>.</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>] </em><em>| </em><em>None</em>) – A callable taking <cite>parameters</cite> and an OptimizationResult as arguments.</p></li>
<li><p><strong>optimizer</strong> (<em>Optimizer</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>List</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>Optimizer</em><em>]</em>) – A <cite>torch.optim.Optimizer</cite> instance or a factory that takes
a list of parameters and returns an <cite>Optimizer</cite> instance.</p></li>
<li><p><strong>scheduler</strong> (<em>LRScheduler</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>Optimizer</em><em>]</em><em>, </em><em>LRScheduler</em><em>] </em><em>| </em><em>None</em>) – A <cite>torch.optim.lr_scheduler._LRScheduler</cite> instance or a factory
that takes a <cite>Optimizer</cite> instance and returns a <cite>_LRSchedule</cite> instance.</p></li>
<li><p><strong>step_limit</strong> (<em>int</em><em> | </em><em>None</em>) – Integer specifying a maximum number of optimization steps.
One of <cite>step_limit</cite>, <cite>stopping_criterion</cite>, or <cite>timeout_sec</cite> must be passed.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Timeout in seconds before terminating the optimization loop.
One of <cite>step_limit</cite>, <cite>stopping_criterion</cite>, or <cite>timeout_sec</cite> must be passed.</p></li>
<li><p><strong>stopping_criterion</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>bool</em><em>] </em><em>| </em><em>None</em>) – A StoppingCriterion for the optimization loop.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An OptimizationResult summarizing the final state of the run.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.optimize">
<span id="acquisition-function-optimization"></span><h3>Acquisition Function Optimization<a class="headerlink" href="#module-botorch.optim.optimize" title="Link to this heading">¶</a></h3>
<p>Methods for optimizing acquisition functions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">OptimizeAcqfInputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best_only</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequential</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_full_tree=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry_on_optimization_warning=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_gen_kwargs=&lt;factory&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#OptimizeAcqfInputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Container for inputs to <cite>optimize_acqf</cite>.</p>
<p>See docstring for <cite>optimize_acqf</cite> for explanation of parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>)</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>q</strong> (<em>int</em>)</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>)</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>fixed_features</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>return_best_only</strong> (<em>bool</em>)</p></li>
<li><p><strong>gen_candidates</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>AcquisitionFunction</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>sequential</strong> (<em>bool</em>)</p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>return_full_tree</strong> (<em>bool</em>)</p></li>
<li><p><strong>retry_on_optimization_warning</strong> (<em>bool</em>)</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>Dict</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.acq_function">
<span class="sig-name descname"><span class="pre">acq_function</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">AcquisitionFunction</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.acq_function" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.bounds">
<span class="sig-name descname"><span class="pre">bounds</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.bounds" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.q">
<span class="sig-name descname"><span class="pre">q</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.q" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.num_restarts">
<span class="sig-name descname"><span class="pre">num_restarts</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.num_restarts" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.raw_samples">
<span class="sig-name descname"><span class="pre">raw_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.raw_samples" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.options">
<span class="sig-name descname"><span class="pre">options</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.options" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.inequality_constraints">
<span class="sig-name descname"><span class="pre">inequality_constraints</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.inequality_constraints" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.equality_constraints">
<span class="sig-name descname"><span class="pre">equality_constraints</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.equality_constraints" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.nonlinear_inequality_constraints">
<span class="sig-name descname"><span class="pre">nonlinear_inequality_constraints</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.nonlinear_inequality_constraints" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.fixed_features">
<span class="sig-name descname"><span class="pre">fixed_features</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.fixed_features" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.post_processing_func">
<span class="sig-name descname"><span class="pre">post_processing_func</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.post_processing_func" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.batch_initial_conditions">
<span class="sig-name descname"><span class="pre">batch_initial_conditions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.batch_initial_conditions" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.return_best_only">
<span class="sig-name descname"><span class="pre">return_best_only</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.return_best_only" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.gen_candidates">
<span class="sig-name descname"><span class="pre">gen_candidates</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">AcquisitionFunction</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.gen_candidates" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.sequential">
<span class="sig-name descname"><span class="pre">sequential</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.sequential" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.ic_generator">
<span class="sig-name descname"><span class="pre">ic_generator</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><span class="pre">qKnowledgeGradient</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.ic_generator" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.timeout_sec">
<span class="sig-name descname"><span class="pre">timeout_sec</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.timeout_sec" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.return_full_tree">
<span class="sig-name descname"><span class="pre">return_full_tree</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.return_full_tree" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.retry_on_optimization_warning">
<span class="sig-name descname"><span class="pre">retry_on_optimization_warning</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.retry_on_optimization_warning" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.ic_gen_kwargs">
<span class="sig-name descname"><span class="pre">ic_gen_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.ic_gen_kwargs" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.full_tree">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">full_tree</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.full_tree" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.optimize.OptimizeAcqfInputs.get_ic_generator">
<span class="sig-name descname"><span class="pre">get_ic_generator</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#OptimizeAcqfInputs.get_ic_generator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.OptimizeAcqfInputs.get_ic_generator" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[<a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a>, <em>Tensor</em>, int, int, int, <em>Dict</em>[int, float] | None, <em>Dict</em>[str, bool | float | int] | None, <em>List</em>[<em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>, float]] | None, <em>List</em>[<em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>, float]] | None], <em>Tensor</em> | None]</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gen_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequential</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_full_tree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry_on_optimization_warning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">ic_gen_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf" title="Link to this definition">¶</a></dt>
<dd><p>Generate a set of candidates via multi-start optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>) – The number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>. <cite>indices</cite> and
<cite>coefficients</cite> should be torch tensors. See the docstring of
<cite>make_scipy_linear_constraints</cite> for an example. When q=1, or when
applying the same constraint to each candidate in the batch
(intra-point constraint), <cite>indices</cite> should be a 1-d tensor.
For inter-point constraints, in which the constraint is applied to the
whole batch of candidates, <cite>indices</cite> must be a 2-d tensor, where
in each row <cite>indices[i] =(k_i, l_i)</cite> the first index <cite>k_i</cite> corresponds
to the <cite>k_i</cite>-th element of the <cite>q</cite>-batch and the second index <cite>l_i</cite>
corresponds to the <cite>l_i</cite>-th feature of that element.</p></li>
<li><p><strong>equality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>. See the docstring of
<cite>make_scipy_linear_constraints</cite> for an example.</p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples representing the nonlinear
inequality constraints. The first element in the tuple is a callable
representing a constraint of the form <cite>callable(x) &gt;= 0</cite>. In case of an
intra-point constraint, <cite>callable()`takes in an one-dimensional tensor of
shape `d</cite> and returns a scalar. In case of an inter-point constraint,
<cite>callable()</cite> takes a two dimensional tensor of shape <cite>q x d</cite> and again
returns a scalar. The second element is a boolean, indicating if it is an
intra-point or inter-point constraint (<cite>True</cite> for intra-point. <cite>False</cite> for
inter-point). For more information on intra-point vs inter-point
constraints, see the docstring of the <cite>inequality_constraints</cite> argument to
<cite>optimize_acqf()</cite>. The constraints will later be passed to the scipy
solver. You need to pass in <cite>batch_initial_conditions</cite> in this case.
Using non-linear inequality constraints also requires that <cite>batch_limit</cite>
is set to 1, which will be done automatically if not specified in
<cite>options</cite>.</p></li>
<li><p><strong>fixed_features</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A tensor to specify the initial conditions. Set
this if you do not want to use default initialization strategy.</p></li>
<li><p><strong>return_best_only</strong> (<em>bool</em>) – If False, outputs the solutions corresponding to all
random restart initializations of the optimization.</p></li>
<li><p><strong>gen_candidates</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>AcquisitionFunction</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A callable for generating candidates (and their associated
acquisition values) given a tensor of initial conditions and an
acquisition function. Other common inputs include lower and upper bounds
and a dictionary of options, but refer to the documentation of specific
generation functions (e.g gen_candidates_scipy and gen_candidates_torch)
for method-specific inputs. Default: <cite>gen_candidates_scipy</cite></p></li>
<li><p><strong>sequential</strong> (<em>bool</em>) – If False, uses joint optimization, otherwise uses sequential
optimization.</p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Function for generating initial conditions. Not needed when
<cite>batch_initial_conditions</cite> are provided. Defaults to
<cite>gen_one_shot_kg_initial_conditions</cite> for <cite>qKnowledgeGradient</cite> acquisition
functions and <cite>gen_batch_initial_conditions</cite> otherwise. Must be specified
for nonlinear inequality constraints.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Max amount of time optimization can run for.</p></li>
<li><p><strong>return_full_tree</strong> (<em>bool</em>)</p></li>
<li><p><strong>retry_on_optimization_warning</strong> (<em>bool</em>) – Whether to retry candidate generation with a new
set of initial conditions when it fails with an <cite>OptimizationWarning</cite>.</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>Any</em>) – Additional keyword arguments passed to function specified by
<cite>ic_generator</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><dl class="simple">
<dt>A tensor of generated candidates. The shape is</dt><dd><p>– <cite>q x d</cite> if <cite>return_best_only</cite> is True (default)
– <cite>num_restarts x q x d</cite> if <cite>return_best_only</cite> is False</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>a tensor of associated acquisition values. If <cite>sequential=False</cite>,</dt><dd><p>this is a <cite>(num_restarts)</cite>-dim tensor of joint acquisition values
(with explicit restart dimension if <cite>return_best_only=False</cite>). If
<cite>sequential=True</cite>, this is a <cite>q</cite>-dim tensor of expected acquisition
values conditional on having observed candidates <cite>0,1,…,i-1</cite>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate `q=2` candidates jointly using 20 random restarts</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and 512 raw samples</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidates</span><span class="p">,</span> <span class="n">acq_value</span> <span class="o">=</span> <span class="n">optimize_acqf</span><span class="p">(</span><span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; generate `q=3` candidates sequentially using 15 random restarts
&gt;&gt;&gt; # and 256 raw samples
&gt;&gt;&gt; qEI = qExpectedImprovement(model, best_f=0.2)
&gt;&gt;&gt; bounds = torch.tensor([[0.], [1.]])
&gt;&gt;&gt; candidates, acq_value_list = optimize_acqf(
&gt;&gt;&gt;     qEI, bounds, 3, 15, 256, sequential=True
&gt;&gt;&gt; )
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_cyclic">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_cyclic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cyclic_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_full_tree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retry_on_optimization_warning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">ic_gen_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_cyclic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_cyclic" title="Link to this definition">¶</a></dt>
<dd><p>Generate a set of <cite>q</cite> candidates via cyclic optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>fixed_features</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A tensor to specify the initial conditions.
If no initial conditions are provided, the default initialization will
be used.</p></li>
<li><p><strong>cyclic_options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for stopping criterion for outer cyclic optimization.</p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Function for generating initial conditions. Not needed when
<cite>batch_initial_conditions</cite> are provided. Defaults to
<cite>gen_one_shot_kg_initial_conditions</cite> for <cite>qKnowledgeGradient</cite> acquisition
functions and <cite>gen_batch_initial_conditions</cite> otherwise. Must be specified
for nonlinear inequality constraints.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Max amount of time optimization can run for.</p></li>
<li><p><strong>return_full_tree</strong> (<em>bool</em>)</p></li>
<li><p><strong>retry_on_optimization_warning</strong> (<em>bool</em>) – Whether to retry candidate generation with a new
set of initial conditions when it fails with an <cite>OptimizationWarning</cite>.</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>Any</em>) – Additional keyword arguments passed to function specified by
<cite>ic_generator</cite></p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><dl class="simple">
<dt>a <cite>q</cite>-dim tensor of expected acquisition values, where the value at</dt><dd><p>index <cite>i</cite> is the acquisition value conditional on having observed
all candidates except candidate <cite>i</cite>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate `q=3` candidates cyclically using 15 random restarts</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 256 raw samples, and 4 cycles</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidates</span><span class="p">,</span> <span class="n">acq_value_list</span> <span class="o">=</span> <span class="n">optimize_acqf_cyclic</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">cyclic_options</span><span class="o">=</span><span class="p">{</span><span class="s2">"maxiter"</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_list">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_gen_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_list" title="Link to this definition">¶</a></dt>
<dd><p>Generate a list of candidates from a list of acquisition functions.</p>
<p>The acquisition functions are optimized in sequence, with previous candidates
set as <cite>X_pending</cite>. This is also known as sequential greedy optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function_list</strong> (<em>List</em><em>[</em><em>AcquisitionFunction</em><em>]</em>) – A list of acquisition functions.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples representing the nonlinear
inequality constraints. The first element in the tuple is a callable
representing a constraint of the form <cite>callable(x) &gt;= 0</cite>. In case of an
intra-point constraint, <cite>callable()`takes in an one-dimensional tensor of
shape `d</cite> and returns a scalar. In case of an inter-point constraint,
<cite>callable()</cite> takes a two dimensional tensor of shape <cite>q x d</cite> and again
returns a scalar. The second element is a boolean, indicating if it is an
intra-point or inter-point constraint (<cite>True</cite> for intra-point. <cite>False</cite> for
inter-point). For more information on intra-point vs inter-point
constraints, see the docstring of the <cite>inequality_constraints</cite> argument to
<cite>optimize_acqf()</cite>. The constraints will later be passed to the scipy
solver. You need to pass in <cite>batch_initial_conditions</cite> in this case.
Using non-linear inequality constraints also requires that <cite>batch_limit</cite>
is set to 1, which will be done automatically if not specified in
<cite>options</cite>.</p></li>
<li><p><strong>fixed_features</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>fixed_features_list</strong> (<em>List</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of maps <cite>{feature_index: value}</cite>. The i-th
item represents the fixed_feature for the i-th optimization. If
<cite>fixed_features_list</cite> is provided, <cite>optimize_acqf_mixed</cite> is invoked.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Function for generating initial conditions. Not needed when
<cite>batch_initial_conditions</cite> are provided. Defaults to
<cite>gen_one_shot_kg_initial_conditions</cite> for <cite>qKnowledgeGradient</cite> acquisition
functions and <cite>gen_batch_initial_conditions</cite> otherwise. Must be specified
for nonlinear inequality constraints.</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>Dict</em><em> | </em><em>None</em>) – Additional keyword arguments passed to function specified by
<cite>ic_generator</cite></p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><dl class="simple">
<dt>a <cite>q</cite>-dim tensor of expected acquisition values, where the value at</dt><dd><p>index <cite>i</cite> is the acquisition value conditional on having observed
all candidates except candidate <cite>i</cite>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_mixed">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_mixed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ic_gen_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_mixed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_mixed" title="Link to this definition">¶</a></dt>
<dd><p>Optimize over a list of fixed_features and returns the best solution.</p>
<p>This is useful for optimizing over mixed continuous and discrete domains.
For q &gt; 1 this function always performs sequential greedy optimization (with
proper conditioning on generated candidates).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>
(if inequality_constraints is provided, these bounds can be -inf and
+inf, respectively).</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>fixed_features_list</strong> (<em>List</em><em>[</em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>]</em><em>]</em>) – A list of maps <cite>{feature_index: value}</cite>. The i-th
item represents the fixed_feature for the i-th optimization.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite></p></li>
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples representing the nonlinear
inequality constraints. The first element in the tuple is a callable
representing a constraint of the form <cite>callable(x) &gt;= 0</cite>. In case of an
intra-point constraint, <cite>callable()`takes in an one-dimensional tensor of
shape `d</cite> and returns a scalar. In case of an inter-point constraint,
<cite>callable()</cite> takes a two dimensional tensor of shape <cite>q x d</cite> and again
returns a scalar. The second element is a boolean, indicating if it is an
intra-point or inter-point constraint (<cite>True</cite> for intra-point. <cite>False</cite> for
inter-point). For more information on intra-point vs inter-point
constraints, see the docstring of the <cite>inequality_constraints</cite> argument to
<cite>optimize_acqf()</cite>. The constraints will later be passed to the scipy
solver. You need to pass in <cite>batch_initial_conditions</cite> in this case.
Using non-linear inequality constraints also requires that <cite>batch_limit</cite>
is set to 1, which will be done automatically if not specified in
<cite>options</cite>.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – A function that post-processes an optimization
result appropriately (i.e., according to <cite>round-trip</cite>
transformations).</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A tensor to specify the initial conditions. Set
this if you do not want to use default initialization strategy.</p></li>
<li><p><strong>ic_generator</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a><em>, </em><em>Tensor</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>, </em><em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>, </em><em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em><em>]</em><em>, </em><em>Tensor</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Function for generating initial conditions. Not needed when
<cite>batch_initial_conditions</cite> are provided. Defaults to
<cite>gen_one_shot_kg_initial_conditions</cite> for <cite>qKnowledgeGradient</cite> acquisition
functions and <cite>gen_batch_initial_conditions</cite> otherwise. Must be specified
for nonlinear inequality constraints.</p></li>
<li><p><strong>ic_gen_kwargs</strong> (<em>Dict</em><em> | </em><em>None</em>) – Additional keyword arguments passed to function specified by
<cite>ic_generator</cite></p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – kwargs do nothing. This is provided so that the same arguments can
be passed to different acquisition functions without raising an error.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>an associated acquisition value.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_discrete">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_discrete</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">choices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unique</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_discrete"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_discrete" title="Link to this definition">¶</a></dt>
<dd><p>Optimize over a discrete set of points using batch evaluation.</p>
<p>For <cite>q &gt; 1</cite> this function generates candidates by means of sequential
conditioning (rather than joint optimization), since for all but the
smalles number of choices the set <cite>choices^q</cite> of discrete points to
evaluate quickly explodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>choices</strong> (<em>Tensor</em>) – A <cite>num_choices x d</cite> tensor of possible choices.</p></li>
<li><p><strong>max_batch_size</strong> (<em>int</em>) – The maximum number of choices to evaluate in batch.
A large limit can cause excessive memory usage if the model has
a large training set.</p></li>
<li><p><strong>unique</strong> (<em>bool</em>) – If True return unique choices, o/w choices may be repeated
(only relevant if <cite>q &gt; 1</cite>).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – kwargs do nothing. This is provided so that the same arguments can
be passed to different acquisition functions without raising an error.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>an associated acquisition value.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize.optimize_acqf_discrete_local_search">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_discrete_local_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_choices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_avoid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unique</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize.html#optimize_acqf_discrete_local_search"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize.optimize_acqf_discrete_local_search" title="Link to this definition">¶</a></dt>
<dd><p>Optimize acquisition function over a lattice.</p>
<p>This is useful when d is large and enumeration of the search space
isn’t possible. For q &gt; 1 this function always performs sequential
greedy optimization (with proper conditioning on generated candidates).</p>
<p>NOTE: While this method supports arbitrary lattices, it has only been
thoroughly tested for {0, 1}^d. Consider it to be in alpha stage for
the more general case.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction</p></li>
<li><p><strong>discrete_choices</strong> (<em>List</em><em>[</em><em>Tensor</em><em>]</em>) – A list of possible discrete choices for each dimension.
Each element in the list is expected to be a torch tensor.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – Number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – Number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite></p></li>
<li><p><strong>X_avoid</strong> (<em>Tensor</em><em> | </em><em>None</em>) – An <cite>n x d</cite> tensor of candidates that we aren’t allowed to pick.</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A tensor of size <cite>n x 1 x d</cite> to specify the
initial conditions. Set this if you do not want to use default
initialization strategy.</p></li>
<li><p><strong>max_batch_size</strong> (<em>int</em>) – The maximum number of choices to evaluate in batch.
A large limit can cause excessive memory usage if the model has
a large training set.</p></li>
<li><p><strong>unique</strong> (<em>bool</em>) – If True return unique choices, o/w choices may be repeated
(only relevant if <cite>q &gt; 1</cite>).</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>) – kwargs do nothing. This is provided so that the same arguments can
be passed to different acquisition functions without raising an error.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A two-element tuple containing</p>
<ul class="simple">
<li><p>a <cite>q x d</cite>-dim tensor of generated candidates.</p></li>
<li><p>an associated acquisition value.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.fit">
<span id="model-fitting-optimization"></span><h3>Model Fitting Optimization<a class="headerlink" href="#module-botorch.optim.fit" title="Link to this heading">¶</a></h3>
<p>Tools for model fitting.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.fit.fit_gpytorch_mll_scipy">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.fit.</span></span><span class="sig-name descname"><span class="pre">fit_gpytorch_mll_scipy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'L-BFGS-B'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/fit.html#fit_gpytorch_mll_scipy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.fit.fit_gpytorch_mll_scipy" title="Link to this definition">¶</a></dt>
<dd><p>Generic scipy.optimized-based fitting routine for GPyTorch MLLs.</p>
<p>The model and likelihood in mll must already be in train mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – MarginalLogLikelihood to be maximized.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Optional dictionary of parameters to be optimized. Defaults
to all parameters of <cite>mll</cite> that require gradients.</p></li>
<li><p><strong>bounds</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>None</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A dictionary of user-specified bounds for <cite>parameters</cite>. Used to update
default parameter bounds obtained from <cite>mll</cite>.</p></li>
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>] </em><em>| </em><em>None</em>) – Callable that returns a tensor and an iterable of gradient tensors.
Responsible for setting the <cite>grad</cite> attributes of <cite>parameters</cite>. If no closure
is provided, one will be obtained by calling <cite>get_loss_closure_with_grads</cite>.</p></li>
<li><p><strong>closure_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments passed to <cite>closure</cite>.</p></li>
<li><p><strong>method</strong> (<em>str</em>) – Solver type, passed along to scipy.minimize.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of solver options, passed along to scipy.minimize.</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Optional callback taking <cite>parameters</cite> and an OptimizationResult as its
sole arguments.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Timeout in seconds after which to terminate the fitting loop
(note that timing out can result in bad fits!).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The final OptimizationResult.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.fit.fit_gpytorch_mll_torch">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.fit.</span></span><span class="sig-name descname"><span class="pre">fit_gpytorch_mll_torch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">closure_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_limit=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criterion=&lt;class</span> <span class="pre">'botorch.utils.types.DEFAULT'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/fit.html#fit_gpytorch_mll_torch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.fit.fit_gpytorch_mll_torch" title="Link to this definition">¶</a></dt>
<dd><p>Generic torch.optim-based fitting routine for GPyTorch MLLs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – MarginalLogLikelihood to be maximized.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Optional dictionary of parameters to be optimized. Defaults
to all parameters of <cite>mll</cite> that require gradients.</p></li>
<li><p><strong>bounds</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>None</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A dictionary of user-specified bounds for <cite>parameters</cite>. Used to update
default parameter bounds obtained from <cite>mll</cite>.</p></li>
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em><em>] </em><em>| </em><em>None</em>) – Callable that returns a tensor and an iterable of gradient tensors.
Responsible for setting the <cite>grad</cite> attributes of <cite>parameters</cite>. If no closure
is provided, one will be obtained by calling <cite>get_loss_closure_with_grads</cite>.</p></li>
<li><p><strong>closure_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments passed to <cite>closure</cite>.</p></li>
<li><p><strong>step_limit</strong> (<em>int</em><em> | </em><em>None</em>) – Optional upper bound on the number of optimization steps.</p></li>
<li><p><strong>stopping_criterion</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>bool</em><em>] </em><em>| </em><em>None</em>) – A StoppingCriterion for the optimization loop.</p></li>
<li><p><strong>optimizer</strong> (<em>Optimizer</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>...</em><em>]</em><em>, </em><em>Optimizer</em><em>]</em>) – A <cite>torch.optim.Optimizer</cite> instance or a factory that takes
a list of parameters and returns an <cite>Optimizer</cite> instance.</p></li>
<li><p><strong>scheduler</strong> (<em>_LRScheduler</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>...</em><em>]</em><em>, </em><em>_LRScheduler</em><em>] </em><em>| </em><em>None</em>) – A <cite>torch.optim.lr_scheduler._LRScheduler</cite> instance or a factory
that takes an <cite>Optimizer</cite> instance and returns an <cite>_LRSchedule</cite>.</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em><em>, </em><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a><em>]</em><em>, </em><em>None</em><em>] </em><em>| </em><em>None</em>) – Optional callback taking <cite>parameters</cite> and an OptimizationResult as its
sole arguments.</p></li>
<li><p><strong>timeout_sec</strong> (<em>float</em><em> | </em><em>None</em>) – Timeout in seconds after which to terminate the fitting loop
(note that timing out can result in bad fits!).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The final OptimizationResult.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#botorch.optim.core.OptimizationResult" title="botorch.optim.core.OptimizationResult"><em>OptimizationResult</em></a></p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.initializers">
<span id="initialization-helpers"></span><h3>Initialization Helpers<a class="headerlink" href="#module-botorch.optim.initializers" title="Link to this heading">¶</a></h3>
<p>References</p>
<div class="citation-list" role="list">
<div class="citation" id="regis" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a href="#id1" role="doc-backlink">Regis</a><span class="fn-bracket">]</span></span>
<p>R. G. Regis, C. A. Shoemaker. Combining radial basis function
surrogates and dynamic coordinate search in high-dimensional
expensive black-box optimization, Engineering Optimization, 2013.</p>
</div>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.transform_constraints">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">transform_constraints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#transform_constraints"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.transform_constraints" title="Link to this definition">¶</a></dt>
<dd><p>Transform constraints to sample from a d*q-dimensional space instead of a
d-dimensional state.</p>
<p>This function assumes that constraints are the same for each input batch,
and broadcasts the constraints accordingly to the input batch shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs), with each tuple
encoding an (in-)equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) (&gt;)= rhs</cite>.
If <cite>indices</cite> is a 2-d Tensor, this supports specifying constraints across
the points in the <cite>q</cite>-batch (inter-point constraints). If <cite>None</cite>, this
function is a nullop and simply returns <cite>None</cite>.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – Size of the <cite>q</cite>-batch.</p></li>
<li><p><strong>d</strong> (<em>int</em>) – Dimensionality of the problem.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of transformed constraints.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[Tuple[Tensor, Tensor, float]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.transform_intra_point_constraint">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">transform_intra_point_constraint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constraint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#transform_intra_point_constraint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.transform_intra_point_constraint" title="Link to this definition">¶</a></dt>
<dd><p>Transforms an intra-point/pointwise constraint from
d-dimensional space to a d*q-dimesional space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs), with each tuple
encoding an (in-)equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) (&gt;)= rhs</cite>. Here <cite>indices</cite> must
be one-dimensional, and the constraint is applied to all points within the
<cite>q</cite>-batch.</p></li>
<li><p><strong>d</strong> (<em>int</em>) – Dimensionality of the problem.</p></li>
<li><p><strong>constraint</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>q</strong> (<em>int</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If indices in the constraints are larger than the
    dimensionality d of the problem.</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of transformed constraints.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[Tuple[Tensor, Tensor, float]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.transform_inter_point_constraint">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">transform_inter_point_constraint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">constraint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#transform_inter_point_constraint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.transform_inter_point_constraint" title="Link to this definition">¶</a></dt>
<dd><p>Transforms an inter-point constraint from
d-dimensional space to a d*q dimesional space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs), with each tuple
encoding an (in-)equality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) (&gt;)= rhs</cite>. <cite>indices</cite> must be a
2-d Tensor, where in each row <cite>indices[i] = (k_i, l_i)</cite> the first index
<cite>k_i</cite> corresponds to the <cite>k_i</cite>-th element of the <cite>q</cite>-batch and the second
index <cite>l_i</cite> corresponds to the <cite>l_i</cite>-th feature of that element.</p></li>
<li><p><strong>constraint</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>d</strong> (<em>int</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If indices in the constraints are larger than the
    dimensionality d of the problem.</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Transformed constraint.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List[Tuple[Tensor, Tensor, float]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.sample_q_batches_from_polytope">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">sample_q_batches_from_polytope</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_burnin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thinning</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#sample_q_batches_from_polytope"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.sample_q_batches_from_polytope" title="Link to this definition">¶</a></dt>
<dd><p>Samples <cite>n</cite> q-baches from a polytope of dimension <cite>d</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – Number of q-batches to sample.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – Number of samples per q-batch</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>n_burnin</strong> (<em>int</em>) – The number of burn-in samples for the Markov chain sampler.
thinning: The amount of thinning (number of steps to take between
returning samples).</p></li>
<li><p><strong>seed</strong> (<em>int</em>) – The random seed.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>.</p></li>
<li><p><strong>equality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>.</p></li>
<li><p><strong>thinning</strong> (<em>int</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n x q x d</cite>-dim tensor of samples.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_batch_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_batch_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_X_fantasies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_batch_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_batch_initial_conditions" title="Link to this definition">¶</a></dt>
<dd><p>Generate a batch of initial conditions for random-restart optimziation.</p>
<p>TODO: Support t-batches of initial conditions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – The acquisition function to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic. Note: if <cite>sample_around_best</cite> is True (the default is False),
then <cite>2 * raw_samples</cite> samples are used.</p></li>
<li><p><strong>fixed_features</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em>) – Options for initial condition generation. For valid options see
<cite>initialize_q_batch</cite> and <cite>initialize_q_batch_nonneg</cite>. If <cite>options</cite>
contains a <cite>nonnegative=True</cite> entry, then <cite>acq_function</cite> is
assumed to be non-negative (useful when using custom acquisition
functions). In addition, an “init_batch_limit” option can be passed
to specify the batch limit for the initialization. This is useful
for avoiding memory limits when computing the batch posterior over
raw samples.</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>.</p></li>
<li><p><strong>generator</strong> (<em>Callable</em><em>[</em><em>[</em><em>int</em><em>, </em><em>int</em><em>, </em><em>int</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Callable for generating samples that are then further
processed. It receives <cite>n</cite>, <cite>q</cite> and <cite>seed</cite> as arguments and
returns a tensor of shape <cite>n x q x d</cite>.</p></li>
<li><p><strong>fixed_X_fantasies</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A fixed set of fantasy points to concatenate to
the <cite>q</cite> candidates being initialized along the <cite>-2</cite> dimension. The
shape should be <cite>num_pseudo_points x d</cite>. E.g., this should be
<cite>num_fantasies x d</cite> for KG and <cite>num_fantasies*num_pareto x d</cite>
for HVKG.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x q x d</cite> tensor of initial conditions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_batch_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qEI</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">500</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_one_shot_kg_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_one_shot_kg_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_one_shot_kg_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_one_shot_kg_initial_conditions" title="Link to this definition">¶</a></dt>
<dd><p>Generate a batch of smart initializations for qKnowledgeGradient.</p>
<p>This function generates initial conditions for optimizing one-shot KG using
the maximizer of the posterior objective. Intutively, the maximizer of the
fantasized posterior will often be close to a maximizer of the current
posterior. This function uses that fact to generate the initial conditions
for the fantasy points. Specifically, a fraction of <cite>1 - frac_random</cite> (see
options) is generated by sampling from the set of maximizers of the
posterior objective (obtained via random restart optimization) according to
a softmax transformation of their respective values. This means that this
initialization strategy internally solves an acquisition function
maximization problem. The remaining <cite>frac_random</cite> fantasy points as well as
all <cite>q</cite> candidate points are chosen according to the standard initialization
strategy in <cite>gen_batch_initial_conditions</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.knowledge_gradient.qKnowledgeGradient" title="botorch.acquisition.knowledge_gradient.qKnowledgeGradient"><em>qKnowledgeGradient</em></a>) – The qHypervolumeKnowledgeGradient instance to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of
task features.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>fixed_features</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em>) – Options for initial condition generation. These contain all
settings for the standard heuristic initialization from
<cite>gen_batch_initial_conditions</cite>. In addition, they contain
<cite>frac_random</cite> (the fraction of fully random fantasy points),
<cite>num_inner_restarts</cite> and <cite>raw_inner_samples</cite> (the number of random
restarts and raw samples for solving the posterior objective
maximization problem, respectively) and <cite>eta</cite> (temperature parameter
for sampling heuristic from posterior objective maximizers).</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x q’ x d</cite> tensor that can be used as initial conditions
for <cite>optimize_acqf()</cite>. Here <cite>q’ = q + num_fantasies</cite> is the total number
of points (candidate points plus fantasy points).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qHVKG</span> <span class="o">=</span> <span class="n">qHypervolumeKnowledgeGradient</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ref_point</span><span class="o">=</span><span class="n">num_fantasies</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_one_shot_hvkg_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qHVKG</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">"frac_random"</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">},</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_one_shot_hvkg_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_one_shot_hvkg_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_one_shot_hvkg_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_one_shot_hvkg_initial_conditions" title="Link to this definition">¶</a></dt>
<dd><p>Generate a batch of smart initializations for qHypervolumeKnowledgeGradient.</p>
<p>This function generates initial conditions for optimizing one-shot HVKG using
the hypervolume maximizing set (of fixed size) under the posterior mean.
Intutively, the hypervolume maximizing set of the fantasized posterior mean
will often be close to a hypervolume maximizing set under the current posterior
mean. This function uses that fact to generate the initial conditions
for the fantasy points. Specifically, a fraction of <cite>1 - frac_random</cite> (see
options) of the restarts are generated by learning the hypervolume maximizing sets
under the current posterior mean, where each hypervolume maximizing set is
obtained from maximizing the hypervolume from a different starting point. Given
a hypervolume maximizing set, the <cite>q</cite> candidate points are selected using to the
standard initialization strategy in <cite>gen_batch_initial_conditions</cite>, with the fixed
hypervolume maximizing set. The remaining <cite>frac_random</cite> restarts fantasy points
as well as all <cite>q</cite> candidate points are chosen according to the standard
initialization strategy in <cite>gen_batch_initial_conditions</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<a class="reference internal" href="acquisition.html#botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient" title="botorch.acquisition.multi_objective.hypervolume_knowledge_gradient.qHypervolumeKnowledgeGradient"><em>qHypervolumeKnowledgeGradient</em></a>) – The qKnowledgeGradient instance to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of
task features.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates to consider.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>fixed_features</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em>) – Options for initial condition generation. These contain all
settings for the standard heuristic initialization from
<cite>gen_batch_initial_conditions</cite>. In addition, they contain
<cite>frac_random</cite> (the fraction of fully random fantasy points),
<cite>num_inner_restarts</cite> and <cite>raw_inner_samples</cite> (the number of random
restarts and raw samples for solving the posterior objective
maximization problem, respectively) and <cite>eta</cite> (temperature parameter
for sampling heuristic from posterior objective maximizers).</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) = rhs</cite>.</p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x q’ x d</cite> tensor that can be used as initial conditions
for <cite>optimize_acqf()</cite>. Here <cite>q’ = q + num_fantasies</cite> is the total number
of points (candidate points plus fantasy points).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qHVKG</span> <span class="o">=</span> <span class="n">qHypervolumeKnowledgeGradient</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ref_point</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_one_shot_hvkg_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">qHVKG</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">"frac_random"</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">},</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.gen_value_function_initial_conditions">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">gen_value_function_initial_conditions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#gen_value_function_initial_conditions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.gen_value_function_initial_conditions" title="Link to this definition">¶</a></dt>
<dd><p>Generate a batch of smart initializations for optimizing
the value function of qKnowledgeGradient.</p>
<p>This function generates initial conditions for optimizing the inner problem of
KG, i.e. its value function, using the maximizer of the posterior objective.
Intutively, the maximizer of the fantasized posterior will often be close to a
maximizer of the current posterior. This function uses that fact to generate the
initital conditions for the fantasy points. Specifically, a fraction of <cite>1 -
frac_random</cite> (see options) of raw samples is generated by sampling from the set of
maximizers of the posterior objective (obtained via random restart optimization)
according to a softmax transformation of their respective values. This means that
this initialization strategy internally solves an acquisition function
maximization problem. The remaining raw samples are generated using
<cite>draw_sobol_samples</cite>. All raw samples are then evaluated, and the initial
conditions are selected according to the standard initialization strategy in
‘initialize_q_batch’ individually for each inner problem.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – The value function instance to be optimized.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of
task features.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em>) – The number of raw samples to consider in the initialization
heuristic.</p></li>
<li><p><strong>current_model</strong> (<a class="reference internal" href="models.html#botorch.models.model.Model" title="botorch.models.model.Model"><em>Model</em></a>) – The model of the KG acquisition function that was used to
generate the fantasy model of the value function.</p></li>
<li><p><strong>fixed_features</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em>] </em><em>| </em><em>None</em>) – Options for initial condition generation. These contain all
settings for the standard heuristic initialization from
<cite>gen_batch_initial_conditions</cite>. In addition, they contain
<cite>frac_random</cite> (the fraction of fully random fantasy points),
<cite>num_inner_restarts</cite> and <cite>raw_inner_samples</cite> (the number of random
restarts and raw samples for solving the posterior objective
maximization problem, respectively) and <cite>eta</cite> (temperature parameter
for sampling heuristic from posterior objective maximizers).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>num_restarts x batch_shape x q x d</cite> tensor that can be used as initial
conditions for <cite>optimize_acqf()</cite>. Here <cite>batch_shape</cite> is the batch shape
of value function model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fant_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fantasy_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fantasize</span><span class="p">(</span><span class="n">fant_X</span><span class="p">,</span> <span class="n">SobolQMCNormalSampler</span><span class="p">(</span><span class="mi">16</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">value_function</span> <span class="o">=</span> <span class="n">PosteriorMean</span><span class="p">(</span><span class="n">fantasy_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">gen_value_function_initial_conditions</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">value_function</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">num_restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">raw_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">"frac_random"</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">},</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.initialize_q_batch">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">initialize_q_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#initialize_q_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.initialize_q_batch" title="Link to this definition">¶</a></dt>
<dd><p>Heuristic for selecting initial conditions for candidate generation.</p>
<p>This heuristic selects points from <cite>X</cite> (without replacement) with probability
proportional to <cite>exp(eta * Z)</cite>, where <cite>Z = (Y - mean(Y)) / std(Y)</cite> and <cite>eta</cite>
is a temperature parameter.</p>
<p>When using an acquisiton function that is non-negative and possibly zero
over large areas of the feature space (e.g. qEI), you should use
<cite>initialize_q_batch_nonneg</cite> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x batch_shape x q x d</cite> tensor of <cite>b</cite> - <cite>batch_shape</cite> samples of
<cite>q</cite>-batches from a d`-dim feature space. Typically, these are generated
using qMC sampling.</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A tensor of <cite>b x batch_shape</cite> outcomes associated with the samples.
Typically, this is the value of the batch acquisition function to be
maximized.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The number of initial condition to be generated. Must be less than <cite>b</cite>.</p></li>
<li><p><strong>eta</strong> (<em>float</em>) – Temperature parameter for weighting samples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n x batch_shape x q x d</cite> tensor of <cite>n</cite> - <cite>batch_shape</cite> <cite>q</cite>-batch initial
conditions, where each batch of <cite>n x q x d</cite> samples is selected independently.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To get `n=10` starting points of q-batch size `q=3`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for model with `d=6`:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qUCB</span> <span class="o">=</span> <span class="n">qUpperConfidenceBound</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xrnd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">initialize_q_batch</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">,</span> <span class="n">qUCB</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.initialize_q_batch_nonneg">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">initialize_q_batch_nonneg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#initialize_q_batch_nonneg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.initialize_q_batch_nonneg" title="Link to this definition">¶</a></dt>
<dd><p>Heuristic for selecting initial conditions for non-neg. acquisition functions.</p>
<p>This function is similar to <cite>initialize_q_batch</cite>, but designed specifically
for acquisition functions that are non-negative and possibly zero over
large areas of the feature space (e.g. qEI). All samples for which
<cite>Y &lt; alpha * max(Y)</cite> will be ignored (assuming that <cite>Y</cite> contains at least
one positive value).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>b x q x d</cite> tensor of <cite>b</cite> samples of <cite>q</cite>-batches from a <cite>d</cite>-dim.
feature space. Typically, these are generated using qMC.</p></li>
<li><p><strong>Y</strong> (<em>Tensor</em>) – A tensor of <cite>b</cite> outcomes associated with the samples. Typically, this
is the value of the batch acquisition function to be maximized.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – The number of initial condition to be generated. Must be less than <cite>b</cite>.</p></li>
<li><p><strong>eta</strong> (<em>float</em>) – Temperature parameter for weighting samples.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – The threshold (as a fraction of the maximum observed value) under
which to ignore samples. All input samples for which
<cite>Y &lt; alpha * max(Y)</cite> will be ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n x q x d</cite> tensor of <cite>n</cite> <cite>q</cite>-batch initial conditions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># To get `n=10` starting points of q-batch size `q=3`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for model with `d=6`:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xrnd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xinit</span> <span class="o">=</span> <span class="n">initialize_q_batch</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">,</span> <span class="n">qEI</span><span class="p">(</span><span class="n">Xrnd</span><span class="p">),</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.sample_points_around_best">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">sample_points_around_best</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_discrete_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_pct</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subset_sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob_perturb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#sample_points_around_best"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.sample_points_around_best" title="Link to this definition">¶</a></dt>
<dd><p>Find best points and sample nearby points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – The acquisition function.</p></li>
<li><p><strong>n_discrete_points</strong> (<em>int</em>) – The number of points to sample.</p></li>
<li><p><strong>sigma</strong> (<em>float</em>) – The standard deviation of the additive gaussian noise for
perturbing the best points.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite>-dim tensor containing the bounds.</p></li>
<li><p><strong>best_pct</strong> (<em>float</em>) – The percentage of best points to perturb.</p></li>
<li><p><strong>subset_sigma</strong> (<em>float</em>) – The standard deviation of the additive gaussian
noise for perturbing a subset of dimensions of the best points.</p></li>
<li><p><strong>prob_perturb</strong> (<em>float</em><em> | </em><em>None</em>) – The probability of perturbing each dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>An optional <cite>n_discrete_points x d</cite>-dim tensor containing the</dt><dd><p>sampled points. This is None if no baseline points are found.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | None</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.sample_truncated_normal_perturbations">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">sample_truncated_normal_perturbations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_discrete_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qmc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#sample_truncated_normal_perturbations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.sample_truncated_normal_perturbations" title="Link to this definition">¶</a></dt>
<dd><p>Sample points around <cite>X</cite>.</p>
<p>Sample perturbed points around <cite>X</cite> such that the added perturbations
are sampled from N(0, sigma^2 I) and truncated to be within [0,1]^d.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>n x d</cite>-dim tensor starting points.</p></li>
<li><p><strong>n_discrete_points</strong> (<em>int</em>) – The number of points to sample.</p></li>
<li><p><strong>sigma</strong> (<em>float</em>) – The standard deviation of the additive gaussian noise for
perturbing the points.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite>-dim tensor containing the bounds.</p></li>
<li><p><strong>qmc</strong> (<em>bool</em>) – A boolean indicating whether to use qmc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n_discrete_points x d</cite>-dim tensor containing the sampled points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.sample_perturbed_subset_dims">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">sample_perturbed_subset_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_discrete_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qmc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob_perturb</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#sample_perturbed_subset_dims"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.sample_perturbed_subset_dims" title="Link to this definition">¶</a></dt>
<dd><p>Sample around <cite>X</cite> by perturbing a subset of the dimensions.</p>
<p>By default, dimensions are perturbed with probability equal to
<cite>min(20 / d, 1)</cite>. As shown in <a class="reference internal" href="#regis" id="id1"><span>[Regis]</span></a>, perturbing a small number
of dimensions can be beneificial. The perturbations are sampled
from N(0, sigma^2 I) and truncated to be within [0,1]^d.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – A <cite>n x d</cite>-dim tensor starting points. <cite>X</cite>
must be normalized to be within <cite>[0, 1]^d</cite>.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – The bounds to sample perturbed values from</p></li>
<li><p><strong>n_discrete_points</strong> (<em>int</em>) – The number of points to sample.</p></li>
<li><p><strong>sigma</strong> (<em>float</em>) – The standard deviation of the additive gaussian noise for
perturbing the points.</p></li>
<li><p><strong>qmc</strong> (<em>bool</em>) – A boolean indicating whether to use qmc.</p></li>
<li><p><strong>prob_perturb</strong> (<em>float</em><em> | </em><em>None</em>) – The probability of perturbing each dimension. If omitted,
defaults to <cite>min(20 / d, 1)</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>n_discrete_points x d</cite>-dim tensor containing the sampled points.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.initializers.is_nonnegative">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.initializers.</span></span><span class="sig-name descname"><span class="pre">is_nonnegative</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/initializers.html#is_nonnegative"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.initializers.is_nonnegative" title="Link to this definition">¶</a></dt>
<dd><p>Determine whether a given acquisition function is non-negative.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – The <cite>AcquisitionFunction</cite> instance.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if <cite>acq_function</cite> is non-negative, False if not, or if the behavior
is unknown (for custom acquisition functions).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">qEI</span> <span class="o">=</span> <span class="n">qExpectedImprovement</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_f</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_nonnegative</span><span class="p">(</span><span class="n">qEI</span><span class="p">)</span>  <span class="c1"># returns True</span>
</pre></div>
</div>
</dd></dl>
</section>
<section id="module-botorch.optim.stopping">
<span id="stopping-criteria"></span><h3>Stopping Criteria<a class="headerlink" href="#module-botorch.optim.stopping" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.stopping.ExpMAStoppingCriterion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.stopping.</span></span><span class="sig-name descname"><span class="pre">ExpMAStoppingCriterion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_window</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rel_tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/stopping.html#ExpMAStoppingCriterion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.stopping.ExpMAStoppingCriterion" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">StoppingCriterion</span></code></p>
<p>Exponential moving average stopping criterion.</p>
<p>Computes an exponentially weighted moving average over window length <cite>n_window</cite>
and checks whether the relative decrease in this moving average between steps
is less than a provided tolerance level. That is, in iteration <cite>i</cite>, it computes</p>
<blockquote>
<div><p>v[i,j] := fvals[i - n_window + j] * w[j]</p>
</div></blockquote>
<p>for all <cite>j = 0, …, n_window</cite>, where <cite>w[j] = exp(-eta * (1 - j / n_window))</cite>.
Letting <cite>ma[i] := sum_j(v[i,j])</cite>, the criterion evaluates to <cite>True</cite> whenever</p>
<blockquote>
<div><p>(ma[i-1] - ma[i]) / abs(ma[i-1]) &lt; rel_tol (if minimize=True)
(ma[i] - ma[i-1]) / abs(ma[i-1]) &lt; rel_tol (if minimize=False)</p>
</div></blockquote>
<p>Exponential moving average stopping criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>maxiter</strong> (<em>int</em>) – Maximum number of iterations.</p></li>
<li><p><strong>minimize</strong> (<em>bool</em>) – If True, assume minimization.</p></li>
<li><p><strong>n_window</strong> (<em>int</em>) – The size of the exponential moving average window.</p></li>
<li><p><strong>eta</strong> (<em>float</em>) – The exponential decay factor in the weights.</p></li>
<li><p><strong>rel_tol</strong> (<em>float</em>) – Relative tolerance for termination.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.stopping.ExpMAStoppingCriterion.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fvals</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/stopping.html#ExpMAStoppingCriterion.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.stopping.ExpMAStoppingCriterion.evaluate" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the stopping criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>fvals</strong> (<em>Tensor</em>) – tensor containing function values for the current iteration. If
<cite>fvals</cite> contains more than one element, then the stopping criterion is
evaluated element-wise and True is returned if the stopping criterion is
true for all elements.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
<p>TODO: add support for utilizing gradient information</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Stopping indicator (if True, stop the optimziation).</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>fvals</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>
<section id="module-botorch.optim.optimize_homotopy">
<span id="acquisition-function-optimization-with-homotopy"></span><h3>Acquisition Function Optimization with Homotopy<a class="headerlink" href="#module-botorch.optim.optimize_homotopy" title="Link to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_homotopy.prune_candidates">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_homotopy.</span></span><span class="sig-name descname"><span class="pre">prune_candidates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acq_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_tolerance</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_homotopy.html#prune_candidates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_homotopy.prune_candidates" title="Link to this definition">¶</a></dt>
<dd><p>Prune candidates based on their distance to other candidates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>candidates</strong> (<em>Tensor</em>) – An <cite>n x d</cite> tensor of candidates.</p></li>
<li><p><strong>acq_values</strong> (<em>Tensor</em>) – An <cite>n</cite> tensor of candidate values.</p></li>
<li><p><strong>prune_tolerance</strong> (<em>float</em>) – The minimum distance to prune candidates.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An <cite>m x d</cite> tensor of pruned candidates.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.optimize_homotopy.optimize_acqf_homotopy">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.optimize_homotopy.</span></span><span class="sig-name descname"><span class="pre">optimize_acqf_homotopy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">homotopy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_restarts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_initial_conditions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_processing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_tolerance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/optimize_homotopy.html#optimize_acqf_homotopy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.optimize_homotopy.optimize_acqf_homotopy" title="Link to this definition">¶</a></dt>
<dd><p>Generate a set of candidates via multi-start optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – An AcquisitionFunction.</p></li>
<li><p><strong>bounds</strong> (<em>Tensor</em>) – A <cite>2 x d</cite> tensor of lower and upper bounds for each column of <cite>X</cite>.</p></li>
<li><p><strong>q</strong> (<em>int</em>) – The number of candidates.</p></li>
<li><p><strong>homotopy</strong> (<a class="reference internal" href="#botorch.optim.homotopy.Homotopy" title="botorch.optim.homotopy.Homotopy"><em>Homotopy</em></a>) – Homotopy object that will make the necessary modifications to the
problem when calling <cite>step()</cite>.</p></li>
<li><p><strong>num_restarts</strong> (<em>int</em>) – The number of starting points for multistart acquisition
function optimization.</p></li>
<li><p><strong>raw_samples</strong> (<em>int</em><em> | </em><em>None</em>) – The number of samples for initialization. This is required
if <cite>batch_initial_conditions</cite> is not specified.</p></li>
<li><p><strong>fixed_features</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em>] </em><em>| </em><em>None</em>) – A map <cite>{feature_index: value}</cite> for features that
should be fixed to a particular value during generation.</p></li>
<li><p><strong>options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation.</p></li>
<li><p><strong>final_options</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>float</em><em> | </em><em>int</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – Options for candidate generation in the last homotopy step.</p></li>
<li><p><strong>batch_initial_conditions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – A tensor to specify the initial conditions. Set
this if you do not want to use default initialization strategy.</p></li>
<li><p><strong>post_processing_func</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Post processing function (such as roundingor clamping)
that is applied before choosing the final candidate.</p></li>
<li><p><strong>prune_tolerance</strong> (<em>float</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
</section>
</section>
<section id="closures">
<h2>Closures<a class="headerlink" href="#closures" title="Link to this heading">¶</a></h2>
<section id="id2">
<h3>Core<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<p id="module-botorch.optim.closures.core">Core methods for building closures in torch and interfacing with numpy.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.closures.core.ForwardBackwardClosure">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.core.</span></span><span class="sig-name descname"><span class="pre">ForwardBackwardClosure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backward=&lt;function</span> <span class="pre">Tensor.backward&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reducer=&lt;built-in</span> <span class="pre">method</span> <span class="pre">sum</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_manager=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/core.html#ForwardBackwardClosure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.core.ForwardBackwardClosure" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Wrapper for fused forward and backward closures.</p>
<p>Initializes a ForwardBackwardClosure instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> – Callable that returns a tensor.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors whose <cite>grad</cite> fields are to be returned.</p></li>
<li><p><strong>backward</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>None</em><em>]</em>) – Callable that takes the (reduced) output of <cite>forward</cite> and sets the
<cite>grad</cite> attributes of tensors in <cite>parameters</cite>.</p></li>
<li><p><strong>reducer</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>]</em><em>]</em>) – Optional callable used to reduce the output of the forward pass.</p></li>
<li><p><strong>callback</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Optional</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em>) – Optional callable that takes the reduced output of <cite>forward</cite> and
the gradients of <cite>parameters</cite> as positional arguments.</p></li>
<li><p><strong>context_manager</strong> (<em>Callable</em>) – A ContextManager used to wrap each forward-backward call.
When passed as <cite>None</cite>, <cite>context_manager</cite> defaults to a <cite>zero_grad_ctx</cite>
that zeroes the gradients of <cite>parameters</cite> upon entry.</p></li>
<li><p><strong>forward</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.closures.core.NdarrayOptimizationClosure">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.core.</span></span><span class="sig-name descname"><span class="pre">NdarrayOptimizationClosure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_array=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_tensor=&lt;built-in</span> <span class="pre">method</span> <span class="pre">as_tensor</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_state=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">set_state=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill_value=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent=True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/core.html#NdarrayOptimizationClosure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.core.NdarrayOptimizationClosure" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Adds stateful behavior and a numpy.ndarray-typed API to a closure with an
expected return type Tuple[Tensor, Union[Tensor, Sequence[Optional[Tensor]]]].</p>
<p>Initializes a NdarrayOptimizationClosure instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>closure</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Sequence</em><em>[</em><em>Optional</em><em>[</em><em>Tensor</em><em>]</em><em>]</em><em>]</em><em>]</em>) – A ForwardBackwardClosure instance.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors representing the closure’s state.
Expected to correspond with the first <cite>len(parameters)</cite> optional
gradient tensors returned by <cite>closure</cite>.</p></li>
<li><p><strong>as_array</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>ndarray</em><em>]</em>) – Callable used to convert tensors to ndarrays.</p></li>
<li><p><strong>as_tensor</strong> (<em>Callable</em><em>[</em><em>[</em><em>ndarray</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>) – Callable used to convert ndarrays to tensors.</p></li>
<li><p><strong>get_state</strong> (<em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>ndarray</em><em>]</em>) – Callable that returns the closure’s state as an ndarray. When
passed as <cite>None</cite>, defaults to calling <cite>get_tensors_as_ndarray_1d</cite>
on <cite>closure.parameters</cite> while passing <cite>as_array</cite> (if given by the user).</p></li>
<li><p><strong>set_state</strong> (<em>Callable</em><em>[</em><em>[</em><em>ndarray</em><em>]</em><em>, </em><em>None</em><em>]</em>) – Callable that takes a 1-dimensional ndarray and sets the
closure’s state. When passed as <cite>None</cite>, <cite>set_state</cite> defaults to
calling <cite>set_tensors_from_ndarray_1d</cite> with <cite>closure.parameters</cite> and
a given ndarray while passing <cite>as_tensor</cite>.</p></li>
<li><p><strong>fill_value</strong> (<em>float</em>) – Fill value for parameters whose gradients are None. In most
cases, <cite>fill_value</cite> should either be zero or NaN.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>) – Boolean specifying whether an ndarray should be retained
as a persistent buffer for gradients.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.closures.core.NdarrayOptimizationClosure.state">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">state</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></em><a class="headerlink" href="#botorch.optim.closures.core.NdarrayOptimizationClosure.state" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
</section>
<section id="module-botorch.optim.closures.model_closures">
<span id="model-fitting-closures"></span><h3>Model Fitting Closures<a class="headerlink" href="#module-botorch.optim.closures.model_closures" title="Link to this heading">¶</a></h3>
<p>Utilities for building model-based closures.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.closures.model_closures.get_loss_closure">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.model_closures.</span></span><span class="sig-name descname"><span class="pre">get_loss_closure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/model_closures.html#get_loss_closure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.model_closures.get_loss_closure" title="Link to this definition">¶</a></dt>
<dd><p>Public API for GetLossClosure dispatcher.</p>
<p>This method, and the dispatcher that powers it, acts as a clearing house
for factory functions that define how <cite>mll</cite> is evaluated.</p>
<p>Users may specify custom evaluation routines by registering a factory function
with GetLossClosure. These factories should be registered using the type signature</p>
<blockquote>
<div><p><cite>Type[MarginalLogLikeLihood], Type[Likelihood], Type[Model], Type[DataLoader]</cite>.</p>
</div></blockquote>
<p>The final argument, Type[DataLoader], is optional. Evaluation routines that obtain
training data from, e.g., <cite>mll.model</cite> should register this argument as <cite>type(None)</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – A MarginalLogLikelihood instance whose negative defines the loss.</p></li>
<li><p><strong>data_loader</strong> (<em>DataLoader</em><em> | </em><em>None</em>) – An optional DataLoader instance for cases where training
data is passed in rather than obtained from <cite>mll.model</cite>.</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A closure that takes zero positional arguments and returns the negated
value of <cite>mll</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[], <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.closures.model_closures.get_loss_closure_with_grads">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.closures.model_closures.</span></span><span class="sig-name descname"><span class="pre">get_loss_closure_with_grads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mll</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backward=&lt;function</span> <span class="pre">Tensor.backward&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reducer=&lt;method</span> <span class="pre">'sum'</span> <span class="pre">of</span> <span class="pre">'torch._C.TensorBase'</span> <span class="pre">objects&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_manager=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/closures/model_closures.html#get_loss_closure_with_grads"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.closures.model_closures.get_loss_closure_with_grads" title="Link to this definition">¶</a></dt>
<dd><p>Public API for GetLossClosureWithGrads dispatcher.</p>
<p>In most cases, this method simply adds a backward pass to a loss closure obtained by
calling <cite>get_loss_closure</cite>. For further details, see <cite>get_loss_closure</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mll</strong> (<em>MarginalLogLikelihood</em>) – A MarginalLogLikelihood instance whose negative defines the loss.</p></li>
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of tensors whose <cite>grad</cite> fields are to be returned.</p></li>
<li><p><strong>reducer</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>Tensor</em><em>] </em><em>| </em><em>None</em>) – Optional callable used to reduce the output of the forward pass.</p></li>
<li><p><strong>data_loader</strong> (<em>DataLoader</em><em> | </em><em>None</em>) – An optional DataLoader instance for cases where training
data is passed in rather than obtained from <cite>mll.model</cite>.</p></li>
<li><p><strong>context_manager</strong> (<em>Callable</em><em> | </em><em>None</em>) – An optional ContextManager used to wrap each forward-backward
pass. Defaults to a <cite>zero_grad_ctx</cite> that zeroes the gradients of
<cite>parameters</cite> upon entry. None may be passed as an alias for <cite>nullcontext</cite>.</p></li>
<li><p><strong>backward</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>None</em><em>]</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A closure that takes zero positional arguments and returns the reduced and
negated value of <cite>mll</cite> along with the gradients of <cite>parameters</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[], <em>Tuple</em>[<em>Tensor</em>, <em>Tuple</em>[<em>Tensor</em>, …]]]</p>
</dd>
</dl>
</dd></dl>
</section>
</section>
<section id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Link to this heading">¶</a></h2>
<section id="module-botorch.optim.utils.common">
<span id="general-optimization-utilities"></span><h3>General Optimization Utilities<a class="headerlink" href="#module-botorch.optim.utils.common" title="Link to this heading">¶</a></h3>
<p>General-purpose optimization utilities.</p>
</section>
<section id="module-botorch.optim.utils.acquisition_utils">
<span id="acquisition-optimization-utilities"></span><h3>Acquisition Optimization Utilities<a class="headerlink" href="#module-botorch.optim.utils.acquisition_utils" title="Link to this heading">¶</a></h3>
<p>Utilities for maximizing acquisition functions.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.acquisition_utils.columnwise_clamp">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.acquisition_utils.</span></span><span class="sig-name descname"><span class="pre">columnwise_clamp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_on_violation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/acquisition_utils.html#columnwise_clamp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.acquisition_utils.columnwise_clamp" title="Link to this definition">¶</a></dt>
<dd><p>Clamp values of a Tensor in column-wise fashion (with support for t-batches).</p>
<p>This function is useful in conjunction with optimizers from the torch.optim
package, which don’t natively handle constraints. If you apply this after
a gradient step you can be fancy and call it “projected gradient descent”.
This funtion is also useful for post-processing candidates generated by the
scipy optimizer that satisfy bounds only up to numerical accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – The <cite>b x n x d</cite> input tensor. If 2-dimensional, <cite>b</cite> is assumed to be 1.</p></li>
<li><p><strong>lower</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – The column-wise lower bounds. If scalar, apply bound to all columns.</p></li>
<li><p><strong>upper</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – The column-wise upper bounds. If scalar, apply bound to all columns.</p></li>
<li><p><strong>raise_on_violation</strong> (<em>bool</em>) – If <cite>True</cite>, raise an exception when the elments in <cite>X</cite>
are out of the specified bounds (up to numerical accuracy). This is
useful for post-processing candidates generated by optimizers that
satisfy imposed bounds only up to numerical accuracy.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The clamped tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.acquisition_utils.fix_features">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.acquisition_utils.</span></span><span class="sig-name descname"><span class="pre">fix_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/acquisition_utils.html#fix_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.acquisition_utils.fix_features" title="Link to this definition">¶</a></dt>
<dd><p>Fix feature values in a Tensor.</p>
<p>The fixed features will have zero gradient in downstream calculations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – input Tensor with shape <cite>… x p</cite>, where <cite>p</cite> is the number of features</p></li>
<li><p><strong>fixed_features</strong> (<em>Dict</em><em>[</em><em>int</em><em>, </em><em>float</em><em> | </em><em>None</em><em>] </em><em>| </em><em>None</em>) – A dictionary with keys as column indices and values
equal to what the feature should be set to in <cite>X</cite>. If the value is
None, that column is just considered fixed. Keys should be in the
range <cite>[0, p - 1]</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The tensor X with fixed features.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.acquisition_utils.get_X_baseline">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.acquisition_utils.</span></span><span class="sig-name descname"><span class="pre">get_X_baseline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">acq_function</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/acquisition_utils.html#get_X_baseline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.acquisition_utils.get_X_baseline" title="Link to this definition">¶</a></dt>
<dd><p>Extract X_baseline from an acquisition function.</p>
<p>This tries to find the baseline set of points. First, this checks if the
acquisition function has an <cite>X_baseline</cite> attribute. If it does not,
then this method attempts to use the model’s <cite>train_inputs</cite> as <cite>X_baseline</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>acq_function</strong> (<em>AcquisitionFunction</em>) – The acquisition function.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em> | None</p>
</dd>
</dl>
<dl class="simple">
<dt>Returns</dt><dd><dl class="simple">
<dt>An optional <cite>n x d</cite>-dim tensor of baseline points. This is None if no</dt><dd><p>baseline points are found.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.utils.model_utils">
<span id="model-fitting-utilities"></span><h3>Model Fitting Utilities<a class="headerlink" href="#module-botorch.optim.utils.model_utils" title="Link to this heading">¶</a></h3>
<p>Utilities for fitting and manipulating models.</p>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">TorchAttr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#TorchAttr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">NamedTuple</span></code></p>
<p>Create new instance of TorchAttr(shape, dtype, device)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>Size</em>)</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em>)</p></li>
<li><p><strong>device</strong> (<em>device</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr.shape">
<span class="sig-name descname"><span class="pre">shape</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Size</span></em><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr.shape" title="Link to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr.dtype">
<span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dtype</span></em><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr.dtype" title="Link to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.TorchAttr.device">
<span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">device</span></em><a class="headerlink" href="#botorch.optim.utils.model_utils.TorchAttr.device" title="Link to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_data_loader">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_data_loader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_data_loader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_data_loader" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>GPyTorchModel</em>)</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>DataLoader</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_parameters">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_parameters" title="Link to this definition">¶</a></dt>
<dd><p>Helper method for obtaining a module’s parameters and their respective ranges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – The target module from which parameters are to be extracted.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em> | </em><em>None</em>) – Optional Boolean used to filter parameters based on whether
or not their require_grad attribute matches the user provided value.</p></li>
<li><p><strong>name_filter</strong> (<em>Callable</em><em>[</em><em>[</em><em>str</em><em>]</em><em>, </em><em>bool</em><em>] </em><em>| </em><em>None</em>) – Optional Boolean function used to filter parameters by name.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary of parameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[str, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_parameters_and_bounds">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_parameters_and_bounds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(-inf,</span> <span class="pre">inf)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_parameters_and_bounds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_parameters_and_bounds" title="Link to this definition">¶</a></dt>
<dd><p>Helper method for obtaining a module’s parameters and their respective ranges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – The target module from which parameters are to be extracted.</p></li>
<li><p><strong>name_filter</strong> (<em>Callable</em><em>[</em><em>[</em><em>str</em><em>]</em><em>, </em><em>bool</em><em>] </em><em>| </em><em>None</em>) – Optional Boolean function used to filter parameters by name.</p></li>
<li><p><strong>requires_grad</strong> (<em>bool</em><em> | </em><em>None</em>) – Optional Boolean used to filter parameters based on whether
or not their require_grad attribute matches the user provided value.</p></li>
<li><p><strong>default_bounds</strong> (<em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em>) – Default lower and upper bounds for constrained parameters
with <cite>None</cite> typed bounds.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary of parameters and a dictionary of parameter bounds.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Dict</em>[str, <em>Tensor</em>], <em>Dict</em>[str, <em>Tuple</em>[float | None, float | None]]]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.get_name_filter">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">get_name_filter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patterns</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#get_name_filter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.get_name_filter" title="Link to this definition">¶</a></dt>
<dd><p>Returns a binary function that filters strings (or iterables whose first
element is a string) according to a bank of excluded patterns. Typically, used
in conjunction with generators such as <cite>module.named_parameters()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>patterns</strong> (<em>Iterator</em><em>[</em><em>Union</em><em>[</em><em>Pattern</em><em>, </em><em>str</em><em>]</em><em>]</em>) – A collection of regular expressions or strings that
define the set of names to be excluded.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A binary function indicating whether or not an item should be filtered.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Callable[[Union[str, Tuple[str, Any, …]]], bool]</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.model_utils.sample_all_priors">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.model_utils.</span></span><span class="sig-name descname"><span class="pre">sample_all_priors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_retries</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/model_utils.html#sample_all_priors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.model_utils.sample_all_priors" title="Link to this definition">¶</a></dt>
<dd><p>Sample from hyperparameter priors (in-place).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>GPyTorchModel</em>) – A GPyTorchModel.</p></li>
<li><p><strong>max_retries</strong> (<em>int</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.utils.numpy_utils">
<span id="numpy-torch-conversion-tools"></span><h3>Numpy - Torch Conversion Tools<a class="headerlink" href="#module-botorch.optim.utils.numpy_utils" title="Link to this heading">¶</a></h3>
<p>Utilities for interfacing Numpy and Torch.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.as_ndarray">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">as_ndarray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#as_ndarray"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.as_ndarray" title="Link to this definition">¶</a></dt>
<dd><p>Helper for going from torch.Tensor to numpy.ndarray.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>Tensor</em>) – Tensor to be converted to ndarray.</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em><em> | </em><em>None</em>) – Optional numpy.dtype for the converted tensor.</p></li>
<li><p><strong>inplace</strong> (<em>bool</em>) – Boolean indicating whether memory should be shared if possible.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An ndarray with the same data as <cite>values</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.get_tensors_as_ndarray_1d">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">get_tensors_as_ndarray_1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_array=&lt;function</span> <span class="pre">as_ndarray&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#get_tensors_as_ndarray_1d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.get_tensors_as_ndarray_1d" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors</strong> (<em>Iterator</em><em>[</em><em>Tensor</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p></li>
<li><p><strong>out</strong> (<em>ndarray</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em><em> | </em><em>str</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>as_array</strong> (<em>Callable</em><em>[</em><em>[</em><em>Tensor</em><em>]</em><em>, </em><em>ndarray</em><em>]</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.set_tensors_from_ndarray_1d">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">set_tensors_from_ndarray_1d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">as_tensor=&lt;built-in</span> <span class="pre">method</span> <span class="pre">as_tensor</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#set_tensors_from_ndarray_1d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.set_tensors_from_ndarray_1d" title="Link to this definition">¶</a></dt>
<dd><p>Sets the values of one more tensors based off of a vector of assignments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors</strong> (<em>Iterator</em><em>[</em><em>Tensor</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>)</p></li>
<li><p><strong>array</strong> (<em>ndarray</em>)</p></li>
<li><p><strong>as_tensor</strong> (<em>Callable</em><em>[</em><em>[</em><em>ndarray</em><em>]</em><em>, </em><em>Tensor</em><em>]</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.numpy_utils.get_bounds_as_ndarray">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.numpy_utils.</span></span><span class="sig-name descname"><span class="pre">get_bounds_as_ndarray</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/numpy_utils.html#get_bounds_as_ndarray"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.numpy_utils.get_bounds_as_ndarray" title="Link to this definition">¶</a></dt>
<dd><p>Helper method for converting bounds into an ndarray.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – A dictionary of parameters.</p></li>
<li><p><strong>bounds</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em><em>, </em><em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em><em>]</em><em>]</em>) – A dictionary of (optional) lower and upper bounds.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An ndarray of bounds.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em> | None</p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.utils.timeout">
<span id="optimization-with-timeouts"></span><h3>Optimization with Timeouts<a class="headerlink" href="#module-botorch.optim.utils.timeout" title="Link to this heading">¶</a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.utils.timeout.minimize_with_timeout">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.utils.timeout.</span></span><span class="sig-name descname"><span class="pre">minimize_with_timeout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fun</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jac</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hessp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/utils/timeout.html#minimize_with_timeout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.utils.timeout.minimize_with_timeout" title="Link to this definition">¶</a></dt>
<dd><p>Wrapper around scipy.optimize.minimize to support timeout.</p>
<p>This method calls scipy.optimize.minimize with all arguments forwarded
verbatim. The only difference is that if provided a <cite>timeout_sec</cite> argument,
it will automatically stop the optimziation after the timeout is reached.</p>
<p>Internally, this is achieved by automatically constructing a wrapper callback
method that is injected to the scipy.optimize.minimize call and that keeps
track of the runtime and the optimization variables at the current iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fun</strong> (<em>Callable</em><em>[</em><em>[</em><em>np.ndarray</em><em>, </em><em>*Any</em><em>]</em><em>, </em><em>float</em><em>]</em>)</p></li>
<li><p><strong>x0</strong> (<em>np.ndarray</em>)</p></li>
<li><p><strong>args</strong> (<em>Tuple</em><em>[</em><em>Any</em><em>, </em><em>...</em><em>]</em>)</p></li>
<li><p><strong>method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>)</p></li>
<li><p><strong>jac</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>hess</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>, </em><em>optimize.HessianUpdateStrategy</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>hessp</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>]</em>)</p></li>
<li><p><strong>bounds</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Sequence</em><em>[</em><em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em><em>]</em><em>, </em><em>optimize.Bounds</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>tol</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>)</p></li>
<li><p><strong>callback</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>]</em>)</p></li>
<li><p><strong>options</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>)</p></li>
<li><p><strong>timeout_sec</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>optimize.OptimizeResult</p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.parameter_constraints">
<span id="parameter-constraint-utilities"></span><h3>Parameter Constraint Utilities<a class="headerlink" href="#module-botorch.optim.parameter_constraints" title="Link to this heading">¶</a></h3>
<p>Utility functions for constrained optimization.</p>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.make_scipy_bounds">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">make_scipy_bounds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper_bounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_bounds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_bounds" title="Link to this definition">¶</a></dt>
<dd><p>Creates a scipy Bounds object for optimziation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>Tensor</em>) – <cite>… x d</cite> tensor</p></li>
<li><p><strong>lower_bounds</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – Lower bounds on each column (last dimension) of <cite>X</cite>. If
this is a single float, then all columns have the same bound.</p></li>
<li><p><strong>upper_bounds</strong> (<em>float</em><em> | </em><em>Tensor</em><em> | </em><em>None</em>) – Lower bounds on each column (last dimension) of <cite>X</cite>. If
this is a single float, then all columns have the same bound.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A scipy <cite>Bounds</cite> object if either lower_bounds or upper_bounds is not
None, and None otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Bounds</em> | None</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scipy_bounds</span> <span class="o">=</span> <span class="n">make_scipy_bounds</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.make_scipy_linear_constraints">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">make_scipy_linear_constraints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shapeX</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inequality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equality_constraints</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_linear_constraints"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_linear_constraints" title="Link to this definition">¶</a></dt>
<dd><p>Generate scipy constraints from torch representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shapeX</strong> (<em>Size</em>) – The shape of the torch.Tensor to optimize over (i.e. <cite>(b) x q x d</cite>)</p></li>
<li><p><strong>constraints</strong> (<em>equality</em>) – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) &gt;= rhs</cite>, where
<cite>indices</cite> is a single-dimensional index tensor (long dtype) containing
indices into the last dimension of <cite>X</cite>, <cite>coefficients</cite> is a
single-dimensional tensor of coefficients of the same length, and
rhs is a scalar.</p></li>
<li><p><strong>constraints</strong> – A list of tuples (indices, coefficients, rhs),
with each tuple encoding an inequality constraint of the form
<cite>sum_i (X[indices[i]] * coefficients[i]) == rhs</cite> (with <cite>indices</cite>
and <cite>coefficients</cite> of the same form as in <cite>inequality_constraints</cite>).</p></li>
<li><p><strong>inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>equality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Tensor</em><em>, </em><em>Tensor</em><em>, </em><em>float</em><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of dictionaries containing callables for constraint function
values and Jacobians and a string indicating the associated constraint
type (“eq”, “ineq”), as expected by <cite>scipy.minimize</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>Dict</em>[str, str | <em>Callable</em>[[<em>ndarray</em>], float] | <em>Callable</em>[[<em>ndarray</em>], <em>ndarray</em>]]]</p>
</dd>
</dl>
<p>This function assumes that constraints are the same for each input batch,
and broadcasts the constraints accordingly to the input batch shape. This
function does support constraints across elements of a q-batch if the
indices are a 2-d Tensor.</p>
<p class="rubric">Example</p>
<p>The following will enforce that <cite>x[1] + 0.5 x[3] &gt;= -0.1</cite> for each <cite>x</cite>
in both elements of the q-batch, and each of the 3 t-batches:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">constraints</span> <span class="o">=</span> <span class="n">make_scipy_linear_constraints</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
<p>The following will enforce that <cite>x[0, 1] + 0.5 x[1, 3] &gt;= -0.1</cite> where
x[0, :] is the first element of the q-batch and x[1, :] is the second
element of the q-batch, for each of the 3 t-batches:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">constraints</span> <span class="o">=</span> <span class="n">make_scipy_linear_constraints</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">torch</span><span class="o">.</span><span class="n">size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">)],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.eval_lin_constraint">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">eval_lin_constraint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flat_idxr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeffs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rhs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#eval_lin_constraint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.eval_lin_constraint" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate a single linear constraint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The input array.</p></li>
<li><p><strong>flat_idxr</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The indices in <cite>x</cite> to consider.</p></li>
<li><p><strong>coeffs</strong> (<em>ndarray</em>) – The coefficients corresponding to the indices.</p></li>
<li><p><strong>rhs</strong> (<em>float</em>) – The right-hand-side of the constraint.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><cite>sum_i (coeffs[i] * x[i]) - rhs</cite></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>The evaluted constraint</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.lin_constraint_jac">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">lin_constraint_jac</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flat_idxr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coeffs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#lin_constraint_jac"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.lin_constraint_jac" title="Link to this definition">¶</a></dt>
<dd><p>Return the Jacobian associated with a linear constraint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>ndarray</em>) – The input array.</p></li>
<li><p><strong>flat_idxr</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – The indices for the elements of x that appear in the constraint.</p></li>
<li><p><strong>coeffs</strong> (<em>ndarray</em>) – The coefficients corresponding to the indices.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – number of elements</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Jacobian.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.nonlinear_constraint_is_feasible">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">nonlinear_constraint_is_feasible</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_intrapoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#nonlinear_constraint_is_feasible"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.nonlinear_constraint_is_feasible" title="Link to this definition">¶</a></dt>
<dd><p>Checks if a nonlinear inequality constraint is fulfilled.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nonlinear_inequality_constraint</strong> (<em>Callable</em>) – Callable to evaluate the
constraint.</p></li>
<li><p><strong>intra</strong> – If True, the constraint is an intra-point constraint that
is applied pointwise and is broadcasted over the q-batch. Else, the
constraint has to evaluated over the whole q-batch and is a an
inter-point constraint.</p></li>
<li><p><strong>x</strong> (<em>Tensor</em>) – Tensor of shape (b x q x d).</p></li>
<li><p><strong>is_intrapoint</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if the constraint is fulfilled, else False.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="botorch.optim.parameter_constraints.make_scipy_nonlinear_inequality_constraints">
<span class="sig-prename descclassname"><span class="pre">botorch.optim.parameter_constraints.</span></span><span class="sig-name descname"><span class="pre">make_scipy_nonlinear_inequality_constraints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nonlinear_inequality_constraints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f_np_wrapper</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shapeX</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/parameter_constraints.html#make_scipy_nonlinear_inequality_constraints"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.parameter_constraints.make_scipy_nonlinear_inequality_constraints" title="Link to this definition">¶</a></dt>
<dd><p>Generate Scipy nonlinear inequality constraints from callables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nonlinear_inequality_constraints</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>Callable</em><em>, </em><em>bool</em><em>]</em><em>]</em>) – A list of tuples representing the nonlinear
inequality constraints. The first element in the tuple is a callable
representing a constraint of the form <cite>callable(x) &gt;= 0</cite>. In case of an
intra-point constraint, <cite>callable()`takes in an one-dimensional tensor of
shape `d</cite> and returns a scalar. In case of an inter-point constraint,
<cite>callable()</cite> takes a two dimensional tensor of shape <cite>q x d</cite> and again
returns a scalar. The second element is a boolean, indicating if it is an
intra-point or inter-point constraint (<cite>True</cite> for intra-point. <cite>False</cite> for
inter-point). For more information on intra-point vs inter-point
constraints, see the docstring of the <cite>inequality_constraints</cite> argument to
<cite>optimize_acqf()</cite>. The constraints will later be passed to the scipy
solver.</p></li>
<li><p><strong>f_np_wrapper</strong> (<em>Callable</em>) – A wrapper function that given a constraint evaluates the value
and gradient (using autograd) of a numpy input and returns both the
objective and the gradient.</p></li>
<li><p><strong>x0</strong> (<em>Tensor</em>) – The starting point for SLSQP. We return this starting point in (rare)
cases where SLSQP fails and thus require it to be feasible.</p></li>
<li><p><strong>shapeX</strong> (<em>Size</em>) – Shape of the three-dimensional batch X, that should be optimized.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of dictionaries containing callables for constraint function
values and Jacobians and a string indicating the associated constraint
type (“eq”, “ineq”), as expected by <cite>scipy.minimize</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>
</section>
<section id="module-botorch.optim.homotopy">
<span id="homotopy-utilities"></span><h3>Homotopy Utilities<a class="headerlink" href="#module-botorch.optim.homotopy" title="Link to this heading">¶</a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopySchedule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">HomotopySchedule</span></span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#HomotopySchedule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.HomotopySchedule" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopySchedule.num_steps">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_steps</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.homotopy.HomotopySchedule.num_steps" title="Link to this definition">¶</a></dt>
<dd><p>Number of steps in the schedule.</p>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopySchedule.value">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">value</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Any</span></em><a class="headerlink" href="#botorch.optim.homotopy.HomotopySchedule.value" title="Link to this definition">¶</a></dt>
<dd><p>Current value in the schedule.</p>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopySchedule.should_stop">
<em class="property"><span class="pre">abstract</span><span class="w"> </span><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">should_stop</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.homotopy.HomotopySchedule.should_stop" title="Link to this definition">¶</a></dt>
<dd><p>Return true if we have incremented past the end of the schedule.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopySchedule.restart">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">restart</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#HomotopySchedule.restart"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.HomotopySchedule.restart" title="Link to this definition">¶</a></dt>
<dd><p>Restart the schedule to start from the beginning.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopySchedule.step">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#HomotopySchedule.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.HomotopySchedule.step" title="Link to this definition">¶</a></dt>
<dd><p>Move to solving the next problem.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">FixedHomotopySchedule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#FixedHomotopySchedule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.optim.homotopy.HomotopySchedule" title="botorch.optim.homotopy.HomotopySchedule"><code class="xref py py-class docutils literal notranslate"><span class="pre">HomotopySchedule</span></code></a></p>
<p>Homotopy schedule with a fixed list of values.</p>
<p>Initialize FixedHomotopySchedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>values</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – A list of values used in homotopy</p>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule.num_steps">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">num_steps</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule.num_steps" title="Link to this definition">¶</a></dt>
<dd><p>Number of steps in the schedule.</p>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule.value">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">value</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Any</span></em><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule.value" title="Link to this definition">¶</a></dt>
<dd><p>Current value in the schedule.</p>
</dd></dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule.should_stop">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">should_stop</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule.should_stop" title="Link to this definition">¶</a></dt>
<dd><p>Return true if we have incremented past the end of the schedule.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule.restart">
<span class="sig-name descname"><span class="pre">restart</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#FixedHomotopySchedule.restart"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule.restart" title="Link to this definition">¶</a></dt>
<dd><p>Restart the schedule to start from the beginning.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.FixedHomotopySchedule.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#FixedHomotopySchedule.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.FixedHomotopySchedule.step" title="Link to this definition">¶</a></dt>
<dd><p>Move to solving the next problem.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.LinearHomotopySchedule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">LinearHomotopySchedule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_steps</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#LinearHomotopySchedule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.LinearHomotopySchedule" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.optim.homotopy.FixedHomotopySchedule" title="botorch.optim.homotopy.FixedHomotopySchedule"><code class="xref py py-class docutils literal notranslate"><span class="pre">FixedHomotopySchedule</span></code></a></p>
<p>Linear homotopy schedule.</p>
<p>Initialize LinearHomotopySchedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start</strong> (<em>float</em>) – start value of homotopy</p></li>
<li><p><strong>end</strong> (<em>float</em>) – end value of homotopy</p></li>
<li><p><strong>num_steps</strong> (<em>int</em>) – number of steps in the homotopy schedule.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.LogLinearHomotopySchedule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">LogLinearHomotopySchedule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_steps</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#LogLinearHomotopySchedule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.LogLinearHomotopySchedule" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#botorch.optim.homotopy.FixedHomotopySchedule" title="botorch.optim.homotopy.FixedHomotopySchedule"><code class="xref py py-class docutils literal notranslate"><span class="pre">FixedHomotopySchedule</span></code></a></p>
<p>Log-linear homotopy schedule.</p>
<p>Initialize LogLinearHomotopySchedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start</strong> (<em>float</em>) – start value of homotopy</p></li>
<li><p><strong>end</strong> (<em>float</em>) – end value of homotopy</p></li>
<li><p><strong>num_steps</strong> (<em>int</em>) – number of steps in the homotopy schedule.</p></li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopyParameter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">HomotopyParameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schedule</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#HomotopyParameter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.HomotopyParameter" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Homotopy parameter.</p>
<p>The parameter is expected to either be a torch parameter or a torch tensor which may
correspond to a buffer of a module. The parameter has a corresponding schedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameter</strong> (<em>Parameter</em><em> | </em><em>Tensor</em>)</p></li>
<li><p><strong>schedule</strong> (<a class="reference internal" href="#botorch.optim.homotopy.HomotopySchedule" title="botorch.optim.homotopy.HomotopySchedule"><em>HomotopySchedule</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopyParameter.parameter">
<span class="sig-name descname"><span class="pre">parameter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Parameter</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#botorch.optim.homotopy.HomotopyParameter.parameter" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="botorch.optim.homotopy.HomotopyParameter.schedule">
<span class="sig-name descname"><span class="pre">schedule</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#botorch.optim.homotopy.HomotopySchedule" title="botorch.optim.homotopy.HomotopySchedule"><span class="pre">HomotopySchedule</span></a></em><a class="headerlink" href="#botorch.optim.homotopy.HomotopyParameter.schedule" title="Link to this definition">¶</a></dt>
<dd></dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="botorch.optim.homotopy.Homotopy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">botorch.optim.homotopy.</span></span><span class="sig-name descname"><span class="pre">Homotopy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">homotopy_parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#Homotopy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.Homotopy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Generic homotopy class.</p>
<p>This class is designed to be used in <cite>optimize_acqf_homotopy</cite>. Given a set of
homotopy parameters and corresponding schedules we step through the homotopies
until we have solved the final problem. We additionally support passing in a list
of callbacks that will be executed each time <cite>step</cite>, <cite>reset</cite>, and <cite>restart</cite> are
called.</p>
<p>Initialize the homotopy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>homotopy_parameters</strong> (<em>List</em><em>[</em><a class="reference internal" href="#botorch.optim.homotopy.HomotopyParameter" title="botorch.optim.homotopy.HomotopyParameter"><em>HomotopyParameter</em></a><em>]</em>) – List of homotopy parameters</p></li>
<li><p><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>List</em><em>[</em><em>Callable</em><em>]</em><em>]</em>) – Optional list of callbacks that are executed each time
<cite>restart</cite>, <cite>reset</cite>, or <cite>step</cite> are called. These may be used to, e.g.,
reinitialize the acquisition function which is needed when using qNEHVI.</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="botorch.optim.homotopy.Homotopy.should_stop">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">should_stop</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#botorch.optim.homotopy.Homotopy.should_stop" title="Link to this definition">¶</a></dt>
<dd><p>Returns true if all schedules have reached the end.</p>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.Homotopy.restart">
<span class="sig-name descname"><span class="pre">restart</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#Homotopy.restart"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.Homotopy.restart" title="Link to this definition">¶</a></dt>
<dd><p>Restart the homotopy to use the initial value in the schedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.Homotopy.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#Homotopy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.Homotopy.reset" title="Link to this definition">¶</a></dt>
<dd><p>Reset the homotopy parameter to their original values.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="botorch.optim.homotopy.Homotopy.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/botorch/optim/homotopy.html#Homotopy.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#botorch.optim.homotopy.Homotopy.step" title="Link to this definition">¶</a></dt>
<dd><p>Take a step according to the schedules.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>
</section>
</section>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">BoTorch</a></h1>
<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="acquisition.html">botorch.acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">botorch.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="generation.html">botorch.generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="posteriors.html">botorch.posteriors</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">botorch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="fit.html">botorch.fit</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">botorch.sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="cross_validation.html">botorch.cross_validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">botorch.settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">botorch.logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="test_functions.html">botorch.test_functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">botorch.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">botorch.utils</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="index.html">Documentation overview</a><ul>
<li>Previous: <a href="posteriors.html" title="previous chapter">botorch.posteriors</a></li>
<li>Next: <a href="fit.html" title="next chapter">botorch.fit</a></li>
</ul></li>
</ul>
</div>
<search id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="search.html" class="search" method="get">
<input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q" spellcheck="false" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/v/0.11.0/" class="nav-home"><img src="/v/0.11.0/img/botorch.png" alt="BoTorch" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/v/0.11.0/docs/introduction">Introduction</a><a href="/v/0.11.0/docs/getting_started">Getting Started</a><a href="/v/0.11.0/tutorials/">Tutorials</a><a href="/v/0.11.0/api/">API Reference</a><a href="https://arxiv.org/abs/1910.06403">Paper</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/botorch" data-count-href="https://github.com/pytorch/botorch/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star BoTorch on GitHub">botorch</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/v/0.11.0/img/oss_logo.png" alt="Meta Open Source" width="300" height="25"/></a><section class="copyright"> Copyright © 2024 Meta Platforms, Inc</section></footer></div></body></html>